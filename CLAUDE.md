# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Common Development Commands

### Environment Setup
```bash
# Install dependencies
pip install -r requirements.txt

# Copy environment template and configure API keys
cp .env.example .env
# Edit .env file to set:
# - GROQ_API_KEY (required for LLM)
# - GEMINI_API_KEY (optional for OCR)
```

### Running the Application
```bash
# Main application with modular UI components
streamlit run main_app.py
# or
python run.py

# Enhanced version with all features
streamlit run enhanced_app.py
# or
python run.py enhanced

# Basic version
streamlit run app.py

# Quick start for testing
python quick_start.py

# Ultra fast start (minimal setup)
python ultra_fast_start.py

# Graph RAG specific version
python run_graphrag.py
```

### Testing
```bash
# Run PDF discovery test
python test_pdf_discovery.py

# Benchmark startup performance
python benchmark_startup.py
```

### Docker Deployment
```bash
# Standard deployment
docker-compose up --build

# Light deployment (volume bind, faster builds)
docker-compose -f docker-compose.light.yml up --build

# Elasticsearch RAG deployment
docker-compose -f docker-compose.elasticsearch.yml up --build

# Shell scripts for deployment
./docker-run.sh        # Linux/Mac
./docker-deploy.sh     # Linux/Mac deployment
docker-run.bat         # Windows
docker-deploy.bat      # Windows deployment
```

### Performance Benchmarking
```bash
# Run RAG system performance comparison
streamlit run rag_system_benchmark.py

# Memory usage monitoring
python -c "from rag_system_benchmark import RAGSystemBenchmark; RAGSystemBenchmark().run_full_benchmark()"
```

## Architecture Overview

This is an **advanced RAG (Retrieval-Augmented Generation) system** built with **LlamaIndex** and **Streamlit**. The system supports multiple RAG approaches including traditional vector-based retrieval, enhanced RAG with conversation memory, and cutting-edge Graph RAG for knowledge graph construction and reasoning.

### Core Architecture
- **Frontend**: Modular Streamlit UI with component-based architecture
  - `main_app.py`: Main application with modular components
  - `enhanced_app.py`: Full-featured version with all capabilities
  - `app.py`: Basic version for simple use cases
- **RAG Engines**: Multiple RAG implementations
  - `rag_system.py`: Base RAG system
  - `enhanced_rag_system.py`: Enhanced with memory and file management
  - `graph_rag_system.py`: Graph RAG with knowledge graph construction
- **Document Processing**: Multi-format document handling
  - `enhanced_pdf_downloader.py`: Advanced PDF discovery and download
  - `user_file_manager.py`: User upload management
  - `gemini_ocr.py`: OCR processing for images
- **Storage Systems**: Multiple vector store options
  - `chroma_vector_store.py`: ChromaDB integration
  - Built-in SimpleVectorStore support
- **Memory & Context**: Conversation management
  - `conversation_memory.py`: Multi-turn conversation context
- **Configuration**: Centralized settings (`config.py`)
- **Utilities**: Helper functions (`utils.py`)

### Technology Stack
- **LLM**: Groq Llama3-70B-Versatile (`llama-3.3-70b-versatile`)
- **Embeddings**: HuggingFace Sentence Transformers (`all-MiniLM-L6-v2`)
- **Vector Stores**: 
  - ChromaDB (recommended for production)
  - SimpleVectorStore (file-based, good for development)
- **Graph Processing**: NetworkX, Python-Louvain for community detection
- **Document Processing**: 
  - PyMuPDF (primary PDF processor)
  - PyPDF2, pdfplumber (fallback options)
  - python-docx (Word documents)
  - Pillow (image processing)
- **OCR**: Google Gemini Vision API
- **UI Framework**: Streamlit with custom components
- **Visualization**: Pyvis for knowledge graph visualization

### Key Components

#### RAG System Hierarchy
1. **RAGSystem** (`rag_system.py`): Base class with core functionality
   - Model initialization (LLM + embeddings)
   - Document loading and indexing
   - Basic query interface

2. **EnhancedRAGSystem** (`enhanced_rag_system.py`): Extended capabilities
   - Conversation memory integration
   - Multi-format file processing (PDF, DOCX, images)
   - User file management
   - OCR processing via Gemini API
   - ChromaDB vector store support

3. **GraphRAGSystem** (`graph_rag_system.py`): Graph-based RAG
   - Knowledge graph construction from documents
   - Entity and relationship extraction
   - Community detection for knowledge clustering
   - Graph-based retrieval and reasoning
   - Interactive graph visualization
   - **Memory Usage**: High (requires significant RAM for graph processing)

4. **ElasticsearchRAGSystem** (`elasticsearch_rag_system.py`): Scalable RAG
   - High-performance vector storage with Elasticsearch
   - Horizontal scalability for large document collections
   - Advanced text search with Chinese analyzer support
   - Memory-efficient batch processing
   - Production-ready with monitoring and health checks
   - **Memory Usage**: Low to moderate (offloads storage to Elasticsearch)

#### RAG System Comparison

| Feature | Enhanced RAG | Graph RAG | Elasticsearch RAG |
|---------|--------------|-----------|-------------------|
| **Memory Usage** | ğŸŸ¢ Low-Moderate | ğŸ”´ High | ğŸŸ¢ Low-Moderate |
| **Processing Speed** | ğŸŸ¢ Fast | ğŸŸ¡ Moderate | ğŸŸ¢ Fast |
| **Scalability** | ğŸŸ¡ Medium | ğŸ”´ Limited | ğŸŸ¢ Excellent |
| **Complex Queries** | ğŸŸ¡ Good | ğŸŸ¢ Excellent | ğŸŸ¡ Good |
| **Setup Complexity** | ğŸŸ¢ Simple | ğŸŸ¡ Moderate | ğŸŸ¡ Moderate |
| **Production Ready** | ğŸŸ¢ Yes | ğŸŸ¡ Limited | ğŸŸ¢ Yes |
| **Document Size** | < 10k docs | < 1k docs | > 100k docs |

#### When to Use Each System

- **Enhanced RAG**: 
  - é©åˆä¸­å°å‹å°ˆæ¡ˆ (< 10,000 æ–‡æª”)
  - éœ€è¦å¿«é€ŸåŸå‹é–‹ç™¼
  - è¨˜æ†¶é«”è³‡æºæœ‰é™
  - å‚³çµ±å•ç­”æ‡‰ç”¨

- **Graph RAG**: 
  - éœ€è¦ç†è§£è¤‡é›œå¯¦é«”é—œä¿‚
  - çŸ¥è­˜æ¨ç†å’Œé€£æ¥ç™¼ç¾
  - å°åˆ°ä¸­å‹æ–‡æª”é›†åˆ (< 1,000 æ–‡æª”)
  - æœ‰å……è¶³è¨˜æ†¶é«”è³‡æº (>16GB RAM)

- **Elasticsearch RAG**:
  - å¤§å‹æ–‡æª”é›†åˆ (> 100,000 æ–‡æª”)
  - é«˜ä¸¦ç™¼æŸ¥è©¢éœ€æ±‚
  - éœ€è¦æ°´å¹³æ“´å±•
  - ç”Ÿç”¢ç’°å¢ƒéƒ¨ç½²
  - å¤šèªè¨€æ–‡æœ¬æœç´¢

#### Document Processing Pipeline
1. **Multi-Source Input**: 
   - Auto-discovery from web sources (Taiwan Tea Research Station)
   - User file uploads (PDF, DOCX, TXT, MD, images)
   - Batch processing with progress tracking

2. **Advanced Processing**:
   - Text extraction with fallback mechanisms
   - OCR for image-based content (via Gemini Vision)
   - Document chunking (configurable size)
   - Metadata preservation

3. **Knowledge Extraction** (Graph RAG only):
   - Entity extraction using LLM
   - Relationship identification
   - Triplet formation (subject-predicate-object)
   - Graph construction with NetworkX

4. **Vector Indexing**:
   - Multiple embedding strategies
   - ChromaDB or SimpleVectorStore backends
   - Persistent storage with automatic loading

#### UI Component System
Modular Streamlit components for clean separation of concerns:
- `MainLayout`: Overall page layout and navigation
- `ChatInterface`: Conversation management and display
- `UploadZone`: File upload handling with drag-and-drop
- `WelcomeFlow`: Onboarding and quick start guide
- `UserExperience`: User preference and state management

#### Memory & Context Management
- `ConversationMemory`: Multi-turn conversation context
- Configurable memory length (default: 5 turns)
- Context-aware query processing
- Automatic memory persistence

### Data Flow

#### Traditional RAG Flow
```
User Input â†’ UI â†’ Enhanced RAG â†’ Vector Search â†’ Context Retrieval â†’ LLM â†’ Response
```

#### Graph RAG Flow
```
User Input â†’ UI â†’ Graph RAG â†’ Knowledge Graph â†’ Entity/Relation Search â†’ 
Community Context â†’ LLM Reasoning â†’ Response
```

#### Detailed Processing Steps
1. **System Initialization**:
   - Model loading (LLM + embeddings)
   - Vector store initialization (Chroma/Simple)
   - Memory system setup
   - Component initialization

2. **Document Ingestion**:
   - Multi-source document collection
   - Format-specific processing
   - OCR for images (if enabled)
   - Text chunking and preprocessing

3. **Knowledge Representation**:
   - **Traditional**: Vector embeddings in high-dimensional space
   - **Graph RAG**: Entity-relationship graphs with community structure

4. **Query Processing**:
   - User input analysis
   - Context integration from conversation memory
   - **Traditional**: Semantic similarity search
   - **Graph RAG**: Graph traversal and community-based retrieval

5. **Response Generation**:
   - Context compilation from retrieved information
   - LLM reasoning with retrieved context
   - Response formatting and source attribution

### File Structure
```
â”œâ”€â”€ # Main Applications
â”œâ”€â”€ main_app.py                  # Primary modular application
â”œâ”€â”€ enhanced_app.py              # Full-featured application
â”œâ”€â”€ app.py                       # Basic application
â”œâ”€â”€ quick_start.py               # Quick testing version
â”œâ”€â”€ ultra_fast_start.py          # Minimal setup version
â”œâ”€â”€ run.py                       # Application launcher
â”œâ”€â”€ run_graphrag.py              # Graph RAG specific launcher
â”‚
â”œâ”€â”€ # RAG Systems
â”œâ”€â”€ rag_system.py                # Base RAG implementation
â”œâ”€â”€ enhanced_rag_system.py       # Enhanced RAG with memory
â”œâ”€â”€ graph_rag_system.py          # Graph RAG implementation
â”‚
â”œâ”€â”€ # Document Processing
â”œâ”€â”€ pdf_downloader.py            # Basic PDF processing
â”œâ”€â”€ enhanced_pdf_downloader.py   # Advanced PDF discovery
â”œâ”€â”€ user_file_manager.py         # User upload management
â”œâ”€â”€ gemini_ocr.py                # OCR processing
â”‚
â”œâ”€â”€ # Storage & Memory
â”œâ”€â”€ chroma_vector_store.py       # ChromaDB integration
â”œâ”€â”€ conversation_memory.py       # Conversation context
â”‚
â”œâ”€â”€ # UI Components
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ layout/
â”‚   â”‚   â””â”€â”€ main_layout.py       # Main layout manager
â”‚   â”œâ”€â”€ chat/
â”‚   â”‚   â””â”€â”€ chat_interface.py    # Chat UI component
â”‚   â”œâ”€â”€ knowledge_base/
â”‚   â”‚   â””â”€â”€ upload_zone.py       # File upload component
â”‚   â”œâ”€â”€ onboarding/
â”‚   â”‚   â””â”€â”€ welcome_flow.py      # Onboarding flow
â”‚   â”œâ”€â”€ upload/
â”‚   â”‚   â””â”€â”€ drag_drop_zone.py    # Drag-drop upload
â”‚   â””â”€â”€ user_experience.py       # User experience management
â”‚
â”œâ”€â”€ # Configuration & Utilities
â”œâ”€â”€ config.py                    # Configuration settings
â”œâ”€â”€ utils.py                     # Utility functions
â”‚
â”œâ”€â”€ # Testing & Benchmarking
â”œâ”€â”€ test_pdf_discovery.py        # PDF discovery tests
â”œâ”€â”€ benchmark_startup.py         # Performance benchmarking
â”‚
â”œâ”€â”€ # Data Storage
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ pdfs/                    # Downloaded PDF files
â”‚   â”œâ”€â”€ index/                   # SimpleVectorStore files
â”‚   â”œâ”€â”€ chroma_db/               # ChromaDB storage
â”‚   â”œâ”€â”€ user_uploads/            # User uploaded files
â”‚   â””â”€â”€ user_preferences.json   # User preferences
â”‚
â”œâ”€â”€ # Deployment
â”œâ”€â”€ docker-compose.yml           # Docker orchestration
â”œâ”€â”€ Dockerfile                   # Container definition
â”œâ”€â”€ docker-run.sh/.bat           # Run scripts
â”œâ”€â”€ docker-deploy.sh/.bat        # Deployment scripts
â”‚
â””â”€â”€ # Dependencies & Documentation
    â”œâ”€â”€ requirements.txt         # Python dependencies
    â”œâ”€â”€ CLAUDE.md                # Development guide
    â”œâ”€â”€ README.md                # Project overview
    â”œâ”€â”€ GEMINI.md                # Gemini API guide
    â”œâ”€â”€ SYSTEM_DOCUMENTATION.md  # System documentation
    â””â”€â”€ project_structure.md     # Project structure
```

### Configuration System

#### Environment Variables (.env)
```bash
# Required
GROQ_API_KEY=your_groq_api_key

# Optional
GEMINI_API_KEY=your_gemini_api_key  # For OCR functionality
ENABLE_OCR=true
ENABLE_GRAPH_RAG=true
ENABLE_CONVERSATION_MEMORY=true

# File Upload Limits
MAX_FILE_SIZE_MB=10
MAX_IMAGE_SIZE_MB=5
MAX_UPLOAD_FILES=50
SUPPORTED_FILE_TYPES=pdf,txt,docx,md,png,jpg,jpeg,webp,bmp

# Graph RAG Settings
MAX_TRIPLETS_PER_CHUNK=10
GRAPH_COMMUNITY_SIZE=5

# Memory Settings
CONVERSATION_MEMORY_STEPS=5
MAX_CONTEXT_LENGTH=4000
```

#### Configuration Sources
- **WEB_SOURCES**: URLs for automatic PDF discovery from Taiwan Tea Research Station
- **PDF_SOURCES**: Legacy predefined URLs (backup option)
- **Models**: Configurable LLM and embedding models
- **Storage**: Multiple backend options (ChromaDB, SimpleVectorStore)
- **Features**: Toggle-able capabilities (Graph RAG, OCR, Memory)

### System Modes

#### 1. Traditional RAG Mode
- Vector-based semantic search
- SimpleVectorStore or ChromaDB
- Fast and reliable
- Good for straightforward Q&A

#### 2. Enhanced RAG Mode
- Includes conversation memory
- Multi-format file support
- OCR capabilities
- User file management
- Improved context awareness

#### 3. Graph RAG Mode (Advanced)
- Knowledge graph construction
- Entity and relationship extraction
- Community-based retrieval
- Graph visualization
- Complex reasoning capabilities
- Best for understanding relationships and complex queries

## Development Notes

### Vector Storage Options

#### ChromaDB (Recommended)
- High-performance vector database
- Persistent storage with SQLite backend
- Supports filtering and metadata queries
- Better scalability for large document collections
- Automatic cleanup and optimization

#### SimpleVectorStore (Development)
- LlamaIndex built-in vector store
- Stores vectors as JSON files
- No external dependencies
- Good for development and small datasets
- Easy backup and version control

### Performance Optimizations

#### System Initialization
- Lazy loading of components
- Model caching to avoid reinitialization
- Session state persistence
- Background processing for file uploads

#### Memory Management
- Conversation context trimming
- Automatic cleanup of temporary files
- Efficient document chunking
- Resource monitoring and cleanup

#### Graph RAG Optimizations
- Community-based retrieval reduces search space
- Parallel processing for entity extraction
- Graph caching for repeated queries
- Incremental graph updates

### Error Handling & Resilience

#### Multi-level Fallbacks
- PDF processing: PyMuPDF â†’ PyPDF2 â†’ pdfplumber
- Vector storage: ChromaDB â†’ SimpleVectorStore
- OCR processing: Gemini Vision â†’ skip OCR
- Model initialization with retry mechanisms

#### User Experience
- Graceful degradation when features are unavailable
- Clear error messages and recovery suggestions
- Progress indicators for long-running operations
- Automatic retry for transient failures

#### API Error Handling
- Rate limiting awareness
- API key validation
- Timeout handling
- Fallback responses for service unavailability

### Development Best Practices

#### Code Organization
- Modular component architecture
- Clear separation of concerns
- Dependency injection for testability
- Configuration-driven behavior

#### Testing Strategy
- Unit tests for core functionality
- Integration tests for end-to-end workflows
- Performance benchmarking
- Error condition testing

#### Deployment Considerations
- Docker containerization for consistency
- Environment-specific configurations
- Resource requirement documentation
- Monitoring and logging setup

### Extending the System

#### Adding New RAG Methods
1. Inherit from `RAGSystem` base class
2. Implement required abstract methods
3. Add configuration options in `config.py`
4. Update UI components as needed

#### Custom Document Processors
1. Implement document loading interface
2. Add to `UserFileManager` supported types
3. Update file validation logic
4. Test with various document formats

#### New Vector Store Backends
1. Create manager class (similar to `ChromaVectorStoreManager`)
2. Implement LlamaIndex vector store interface
3. Add configuration options
4. Update system initialization logic

---
## å°ˆæ¡ˆç¾æ³åˆ†æèˆ‡æ”¹å–„å»ºè­° (2025-08-17)

### å°ˆæ¡ˆç¾æ³åˆ†æ

é€™æ˜¯ä¸€å€‹åŸºæ–¼ LlamaIndex å’Œ Streamlit çš„å¤šæ¨¡æ…‹ã€å¤šå¾Œç«¯ RAG æ™ºèƒ½å•ç­”ç³»çµ±ã€‚

*   **æ ¸å¿ƒç›®æ¨™**ï¼šæä¾›ä¸€å€‹èƒ½å¤ è™•ç†å¤šç¨®æ–‡ä»¶æ ¼å¼ï¼ˆPDF, DOCX, åœ–ç‰‡ç­‰ï¼‰ï¼Œä¸¦é€éå…ˆé€²çš„ RAG æŠ€è¡“ï¼ˆåŒ…æ‹¬å‚³çµ±å‘é‡æª¢ç´¢ã€çŸ¥è­˜åœ–è­œ Graph RAGã€Elasticsearchï¼‰ä¾†å›ç­”ä½¿ç”¨è€…å•é¡Œçš„æ™ºèƒ½åŠ©ç†ã€‚
*   **æŠ€è¡“å †ç–Š**ï¼š
    *   **å‰ç«¯**ï¼šStreamlitï¼Œä¸¦æœ‰æ¨¡çµ„åŒ–çš„ UI å…ƒä»¶ã€‚
    *   **AI æ¡†æ¶**ï¼šLlamaIndexã€‚
    *   **LLM**ï¼šGroq ä¸Šçš„ Llama 3.3ã€‚
    *   **åµŒå…¥æ¨¡å‹**ï¼šHuggingFace `all-MiniLM-L6-v2`ã€‚
    *   **å‘é‡å„²å­˜**ï¼šæ”¯æ´å¤šç¨®å¾Œç«¯ï¼ŒåŒ…æ‹¬ LlamaIndex å…§å»ºçš„ `SimpleVectorStore`ï¼ˆæª”æ¡ˆå‹ï¼‰ã€`ChromaDB` ï¿½ï¿½ `Elasticsearch`ã€‚
    *   **OCR**ï¼šä½¿ç”¨ Google Gemini API é€²è¡Œåœ–ç‰‡æ–‡å­—è­˜åˆ¥ã€‚
    *   **éƒ¨ç½²**ï¼šæä¾›å®Œæ•´çš„ Docker å’Œ Docker Compose è¨­å®šï¼Œæ”¯æ´å¤šç¨®éƒ¨ç½²æ¨¡å¼ï¼ˆæ¨™æº–ã€è¼•é‡ã€Elasticsearchï¼‰ã€‚
*   **ä¸»è¦åŠŸèƒ½**ï¼š
    *   **å¤š RAG å¼•æ“**ï¼š`enhanced_rag_system`ï¼ˆåŸºç¤åŠŸèƒ½+å°è©±è¨˜æ†¶+OCRï¼‰ã€`graph_rag_system`ï¼ˆçŸ¥è­˜åœ–è­œï¼‰ã€`elasticsearch_rag_system`ï¼ˆå¯æ“´å±•çš„ç”Ÿç”¢ç´šæª¢ç´¢ï¼‰ã€‚
    *   **è‡ªå‹•åŒ–è³‡æ–™è™•ç†**ï¼šèƒ½è‡ªå‹•å¾æŒ‡å®šç¶²ç«™çˆ¬å–ä¸¦ä¸‹è¼‰ PDF æ–‡ä»¶ã€‚
    *   **å¤šæ¨¡æ…‹è¼¸å…¥**ï¼šæ”¯æ´ä½¿ç”¨è€…ä¸Šå‚³æ–‡ä»¶ï¼ˆPDF, DOCX, TXT, MDï¼‰å’Œåœ–ç‰‡ã€‚
    *   **å°è©±è¨˜æ†¶**ï¼šèƒ½å¤ è¨˜ä½ä¸Šä¸‹æ–‡ï¼Œé€²è¡Œå¤šè¼ªå°è©±ã€‚
    *   **çŸ¥è­˜åœ–è­œ**ï¼šèƒ½å¤ å¾æ–‡ä»¶ä¸­æå–å¯¦é«”å’Œé—œä¿‚ï¼Œå»ºç«‹çŸ¥è­˜åœ–è­œä¸¦é€²è¡Œè¦–è¦ºåŒ–å±•ç¤ºã€‚
*   **å°ˆæ¡ˆçµæ§‹**ï¼š
    *   çµæ§‹æ¸…æ™°ï¼ŒæŒ‰åŠŸèƒ½æ¨¡çµ„åŒ–ï¼ˆ`components`, `config`, `utils` ç­‰ï¼‰ã€‚
    *   å­˜åœ¨å¤šå€‹æ‡‰ç”¨ç¨‹å¼å…¥å£é»ï¼ˆ`app.py`, `main_app.py`, `enhanced_app.py`, `quick_start.py` ç­‰ï¼‰ï¼Œå¯èƒ½æ˜¯ç‚ºäº†ä¸åŒçš„å•Ÿå‹•æ¨¡å¼æˆ–é–‹ç™¼éšæ®µã€‚

ç¸½é«”ä¾†èªªï¼Œé€™æ˜¯ä¸€å€‹éå¸¸å®Œæ•´ä¸”å¼·å¤§çš„ POC å°ˆæ¡ˆï¼Œä¸åƒ…å¯¦ç¾äº†æ ¸å¿ƒåŠŸï¿½ï¿½ï¿½ï¼Œé‚„è€ƒæ…®äº†éƒ¨ç½²ã€æ“´å±•æ€§å’Œå¤šç¨®ä½¿ç”¨å ´æ™¯ã€‚

---

### æ½›åœ¨å•é¡Œèˆ‡å»ºè­°

#### 1. ç¨‹å¼ç¢¼é‡è¤‡èˆ‡æª”æ¡ˆçµæ§‹æ··äº‚

*   **å•é¡Œæè¿°**ï¼š
    *   å­˜åœ¨å¤šå€‹åŠŸèƒ½é¡ä¼¼çš„æ‡‰ç”¨ç¨‹å¼å…¥å£æª”æ¡ˆï¼Œä¾‹å¦‚ `app.py`, `enhanced_app.py`, `main_app.py`ã€‚é€™æœƒè®“æ–°æ¥æ‰‹çš„é–‹ç™¼è€…æ„Ÿåˆ°å›°æƒ‘ï¼Œä¸ç¢ºå®šæ‡‰è©²å¾å“ªå€‹æª”æ¡ˆå•Ÿå‹•ï¼Œä¹Ÿå¢åŠ äº†ç¶­è­·æˆæœ¬ã€‚
    *   `rag_system.py` å’Œ `enhanced_rag_system.py` å­˜åœ¨ç¹¼æ‰¿é—œä¿‚ï¼Œä½† `app.py` å»ç›´æ¥ä½¿ç”¨äº† `EnhancedRAGSystem`ï¼Œä½¿å¾— `rag_system.py` çš„å®šä½è®Šå¾—æ¨¡ç³Šï¼Œä¼¼ä¹æœ‰äº›åŠŸèƒ½è¢«é‡è¤‡å¯¦ç¾ã€‚
*   **æ½›åœ¨é¢¨éšª**ï¼šç¶­è­·å›°é›£ã€ç¨‹å¼ç¢¼ä¸ä¸€è‡´ã€æ–°äººä¸Šæ‰‹é–€æª»é«˜ã€‚
*   **ä¿®æ”¹å»ºè­°**ï¼š
    *   **åˆä½µæ‡‰ç”¨å…¥å£**ï¼šå°‡ `app.py`, `enhanced_app.py`, `main_app.py` çš„åŠŸèƒ½åˆä½µåˆ°ä¸€å€‹ä¸»è¦çš„ `app.py` æˆ– `main.py` ä¸­ã€‚ä½¿ç”¨ `config.py` æˆ–ç’°å¢ƒè®Šæ•¸ä¾†æ§åˆ¶è¦å•Ÿç”¨å“ªäº›åŠŸèƒ½ï¼ˆä¾‹å¦‚ï¼Œæ˜¯å¦å•Ÿç”¨ Graph RAGã€æ˜¯å¦ä½¿ç”¨å°è©±è¨˜æ†¶ç­‰ï¼‰ã€‚é€™æ¨£å¯ä»¥ç°¡åŒ–å°ˆæ¡ˆçµæ§‹ï¼Œä½¿å…¥å£å”¯ä¸€ã€‚
    *   **æ¸…æ™°åŒ– RAG ç³»çµ±ç¹¼æ‰¿éˆ**ï¼šæ˜ç¢º `RAGSystem` ç‚ºåŸºåº•é¡åˆ¥ï¼Œ`EnhancedRAGSystem` ç‚ºæ“´å±•é¡åˆ¥ã€‚ç¢ºä¿åŸºç¤åŠŸèƒ½éƒ½åœ¨åŸºåº•é¡åˆ¥ä¸­å¯¦ç¾ï¼Œæ“´å±•é¡åˆ¥åªæ·»åŠ æ–°åŠŸèƒ½ï¼Œé¿å…åŠŸèƒ½è¦†è“‹æˆ–æ··äº‚ã€‚

#### 2. Elasticsearch æ•´åˆå•é¡Œ

*   **å•é¡Œæè¿°**ï¼š
    *   åœ¨ `elasticsearch_rag_system.py` ä¸­ï¼Œ`create_index` æ–¹æ³•çš„é‚è¼¯éå¸¸è¤‡é›œï¼ŒåŒ…å«äº† `try-except` åµŒå¥—å’Œå…©ç¨®ä¸åŒçš„ç´¢å¼•å»ºç«‹æ–¹æ³•ï¼ˆ`from_documents` å’Œé€å€‹ `insert`ï¼‰ã€‚é€™é€šå¸¸æ„å‘³è‘—ä¸»è¦çš„ `from_documents` æ–¹æ³•å¯èƒ½å­˜åœ¨ä¸ç©©å®šæˆ–å¤±æ•—çš„æƒ…æ³ã€‚
    *   ç¨‹å¼ç¢¼ä¸­ä½¿ç”¨äº† `custom_elasticsearch_store.py`ï¼Œä½†é€™å€‹æª”æ¡ˆä¸¦æœªæä¾›ï¼Œæˆ‘ç„¡æ³•æª¢è¦–å…¶å…§å®¹ã€‚å¦‚æœé€™å€‹è‡ªå®šç¾©å­˜å„²æœ‰å•é¡Œï¼Œæœƒç›´æ¥å½±éŸ¿ Elasticsearch çš„åŠŸèƒ½ã€‚
    *   åœ¨ `search_documents` æ–¹æ³•ä¸­ï¼Œæ–‡æœ¬æœç´¢çš„åˆ†æå™¨è¢«ç¡¬ç·¨ç¢¼ç‚º `"chinese_analyzer"`ï¼Œä½†é€™å€‹åˆ†æå™¨åœ¨ `_create_elasticsearch_index` æ–¹æ³•ä¸­ä¸¦æœªè¢«å®šç¾©ï¼ˆå®šç¾©çš„æ˜¯ `text_analyzer`ï¼‰ã€‚é€™æœƒå°è‡´æœç´¢æ™‚å‡ºéŒ¯ã€‚
*   **æ½›åœ¨é¢¨éšª**ï¼šElasticsearch ç´¢å¼•å»ºç«‹å¤±æ•—ã€æœç´¢åŠŸèƒ½ç•°å¸¸ã€ç³»çµ±ä¸ç©©å®šã€‚
*   **ä¿®æ”¹å»ºè­°**ï¼š
    *   **ç°¡åŒ–ç´¢å¼•å»ºç«‹é‚è¼¯**ï¼šæ·±å…¥æ’æŸ¥ `VectorStoreIndex.from_documents` å¤±æ•—çš„åŸå› ï¼Œä¸¦å˜—è©¦ä¿®å¾©å®ƒï¼Œè€Œä¸æ˜¯ä¾è³´å‚™ç”¨æ–¹æ¡ˆã€‚å¯èƒ½æ˜¯ LlamaIndex ç‰ˆæœ¬èˆ‡ Elasticsearch Store çš„å…¼å®¹æ€§å•é¡Œã€‚
    *   **çµ±ä¸€åˆ†æå™¨åç¨±**ï¼šå°‡ `search_documents` ä¸­ä½¿ç”¨çš„åˆ†æå™¨åç¨±å¾ `"chinese_analyzer"` æ”¹ç‚º `_create_elasticsearch_index` ä¸­å®šç¾©çš„ `"text_analyzer"`ï¼Œæˆ–æ˜¯åœ¨ç´¢å¼•å»ºç«‹æ™‚å°±å®šç¾©å¥½ `chinese_analyzer`ã€‚
    *   **æä¾›è‡ªå®šç¾©æ¨¡çµ„**ï¼šç¢ºä¿ `custom_elasticsearch_store.py` æª”æ¡ˆå­˜åœ¨ä¸”åŠŸèƒ½æ­£ç¢ºã€‚

#### 3. ç›¸ä¾æ€§ç®¡ç† (requirements.txt)

*   **å•é¡Œæè¿°**ï¼š
    *   `requirements.txt` ä¸­åŒ…å«äº†ä¸€äº›è¢«è¨»è§£æ‰çš„å¥—ä»¶ï¼Œå¦‚ `streamlit-agraph` å’Œ `streamlit-elements`ï¼Œä¸¦è¨»æ˜ã€Œå¯èƒ½ä¸å­˜åœ¨ã€ã€‚é€™è¡¨ç¤ºé€™äº› UI åŠŸèƒ½å¯èƒ½ç„¡æ³•æ­£å¸¸é‹ä½œã€‚
    *   åŒæ¨£ï¼Œä¸€äº›æ•ˆèƒ½æˆ–ç¤¾ç¾¤æª¢æ¸¬ç›¸é—œçš„å¥—ä»¶ä¹Ÿè¢«è¨»è§£ï¼Œå¦‚ `graspologic` å’Œ `gc3pie`ã€‚
*   **æ½›åœ¨é¢¨éšª**ï¼šåŠŸèƒ½ä¸å®Œæ•´ã€éƒ¨ç½²æ™‚å¯èƒ½å› ç¼ºå°‘å¥—ä»¶è€Œå¤±æ•—ã€‚
*   **ä¿®æ”¹å»ºè­°**ï¼š
    *   **ç¢ºèªä¸¦æ¸…ç†ç›¸ä¾æ€§**ï¼šæ‰¾åˆ°è¢«è¨»è§£å¥—ä»¶çš„æ›¿ä»£æ–¹æ¡ˆï¼Œæˆ–è€…å¦‚æœåŠŸèƒ½ä¸å†éœ€è¦ï¼Œå°±å¾ç¨‹å¼ç¢¼ä¸­ç§»é™¤ç›¸é—œçš„ import å’Œå‘¼å«ï¼Œä¸¦æ¸…ç† `requirements.txt`ã€‚
    *   **ç‰ˆæœ¬é–å®š**ï¼šå»ºè­°ä½¿ç”¨ `pip freeze > requirements.txt` ä¾†ç”¢ç”Ÿä¸€ï¿½ï¿½åŒ…å«æ‰€æœ‰å­ç›¸ä¾æ€§ä¸”ç‰ˆæœ¬è¢«é–å®šçš„æª”æ¡ˆï¼Œæˆ–ä½¿ç”¨ `poetry`, `pipenv` ç­‰å·¥å…·ä¾†æ›´å¥½åœ°ç®¡ç†ç›¸ä¾æ€§ï¼Œä»¥ç¢ºä¿ç’°å¢ƒçš„ä¸€è‡´æ€§ã€‚

#### 4. è¨­å®šç®¡ç† (config.py)

*   **å•é¡Œæè¿°**ï¼š
    *   `config.py` ä¸­æœ‰ä¸€å€‹ `RAG_SYSTEM_TYPE` çš„ç’°å¢ƒè®Šæ•¸ï¼Œç”¨æ–¼åœ¨ `enhanced`, `graph`, `elasticsearch` ä¹‹é–“åˆ‡æ›ã€‚ä½†åœ¨ä»»ä½•ä¸€å€‹æ‡‰ç”¨ç¨‹å¼å…¥å£ï¼ˆå¦‚ `app.py`ï¼‰ä¸­ï¼Œéƒ½æ²’æœ‰çœ‹åˆ°è®€å–é€™å€‹è®Šæ•¸ä¾†å‹•æ…‹è¼‰å…¥å°æ‡‰ RAG ç³»çµ±çš„é‚è¼¯ã€‚ç›®å‰ä¼¼ä¹æ˜¯å¯«æ­»çš„ã€‚
*   **æ½›åœ¨é¢¨éšª**ï¼šè¨­å®šèˆ‡å¯¦éš›è¡Œç‚ºä¸ç¬¦ï¼Œä½¿ç”¨è€…ç„¡æ³•é€éç’°å¢ƒè®Šæ•¸åˆ‡æ› RAG æ¨¡å¼ã€‚
*   **ä¿®æ”¹å»ºè­°**ï¼š
    *   åœ¨æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚ï¼Œå¢åŠ ä¸€å€‹å·¥å» å‡½å¼ (factory function) æˆ–åˆ¤æ–·é‚è¼¯ï¼Œæ ¹æ“š `RAG_SYSTEM_TYPE` çš„å€¼ä¾†å¯¦ä¾‹åŒ–å°æ‡‰çš„ RAG ç³»çµ±é¡åˆ¥ã€‚
