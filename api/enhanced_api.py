"""
å¢å¼·å‹ RAG ç³»çµ± API
æä¾›å®Œæ•´çš„ RAG åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- æ™ºèƒ½å•ç­”ï¼ˆå¸¶å‰å¾Œæ–‡è¨˜æ†¶ï¼‰
- çŸ¥è­˜åº«ç®¡ç†
- æ–‡ä»¶ä¸Šå‚³è™•ç†
- å°è©±è¨˜éŒ„ç®¡ç†
- ç³»çµ±ç‹€æ…‹ç›£æ§
- ç°¡æ˜“èªè­‰æ©Ÿåˆ¶
"""

from fastapi import FastAPI, HTTPException, Depends, UploadFile, File, BackgroundTasks, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from fastapi.responses import FileResponse, JSONResponse
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Union
import sys
import os
import uuid
import hashlib
import time
from datetime import datetime, timedelta
import tempfile
from pathlib import Path
import traceback
import jwt
from functools import wraps
from urllib.parse import unquote

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# è¨­ç½®è©³ç´°æ—¥èªŒ
from src.utils.logging_config import setup_logging, get_api_logger, log_exception, log_performance
import logging

# åˆå§‹åŒ–æ—¥èªŒç³»çµ±
setup_logging(
    app_name="enhanced_api",
    log_level=os.getenv("LOG_LEVEL", "INFO"),
    log_dir="/app/logs",
    enable_console=True,
    enable_file=True,
    enable_json=True
)

# ç²å–APIå°ˆç”¨æ—¥èªŒå™¨
api_logger = get_api_logger()
api_logger.info("ğŸš€ Enhanced RAG API æ­£åœ¨å•Ÿå‹•...")

from src.rag_system.enhanced_rag_system_v2 import EnhancedRAGSystemV2
from src.processors.user_file_manager import UserFileManager
from config.config import GROQ_API_KEY, GEMINI_API_KEY

# FastAPI å¯¦ä¾‹
app = FastAPI(
    title="Enhanced RAG API",
    description="""
## å®Œæ•´çš„ RAG ç³»çµ± API

é€™æ˜¯ä¸€å€‹åŠŸèƒ½å®Œæ•´çš„ RAG (Retrieval-Augmented Generation) ç³»çµ± APIï¼Œæä¾›ï¼š

### ğŸ§  æ™ºèƒ½åŠŸèƒ½
- **æ™ºèƒ½å•ç­”**ï¼šå¸¶å‰å¾Œæ–‡è¨˜æ†¶çš„å°è©±ç³»çµ±
- **çŸ¥è­˜åº«ç®¡ç†**ï¼šæ–‡ä»¶ä¸Šå‚³ã€è™•ç†ã€ç®¡ç†
- **å°è©±è¨˜éŒ„**ï¼šå®Œæ•´çš„å°è©±æ­·å²è¿½è¹¤

### ğŸ” å®‰å…¨ç‰¹æ€§  
- **å¤šå±¤èªè­‰**ï¼šAPI Key + JWT Token
- **æ¬Šé™æ§åˆ¶**ï¼šåˆ†ç´šè¨ªå•æ¬Šé™
- **æœƒè©±ç®¡ç†**ï¼šå®‰å…¨çš„ç”¨æˆ¶æœƒè©±

### ğŸ“š æ”¯æ´æ ¼å¼
- **æ–‡æª”**ï¼šPDFã€Wordã€Markdownã€TXT
- **åœ–ç‰‡**ï¼šPNGã€JPGã€JPEGã€WebPã€BMP
- **æ‰¹é‡è™•ç†**ï¼šå¤šæ–‡ä»¶åŒæ™‚ä¸Šå‚³

### ğŸš€ é–‹å§‹ä½¿ç”¨
1. ä½¿ç”¨é è¨­ API Key ç²å– Tokenï¼š`demo-api-key-123`
2. åœ¨å³ä¸Šè§’ "Authorize" æŒ‰éˆ•è¼¸å…¥ Token
3. é–‹å§‹æ¸¬è©¦å„ç¨® API åŠŸèƒ½ï¼

### ğŸ”— ç›¸é—œéˆæ¥
- **GitHub**: [RAG System Repository](https://github.com/your-repo)
- **æ–‡æª”**: [å®Œæ•´ API æ–‡æª”](./docs)
- **æ”¯æ´**: [Issues & Support](./support)
    """,
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    contact={
        "name": "RAG API Support",
        "email": "support@example.com",
    },
    license_info={
        "name": "MIT License",
        "url": "https://opensource.org/licenses/MIT",
    },
    servers=[
        {
            "url": "http://localhost:8003",
            "description": "æœ¬åœ°é–‹ç™¼ç’°å¢ƒ"
        },
        {
            "url": "http://localhost:8000", 
            "description": "ç›´æ¥è¨ªå•ï¼ˆä¸ç¶“é Docker ç«¯å£æ˜ å°„ï¼‰"
        }
    ],
    tags_metadata=[
        {
            "name": "èªè­‰",
            "description": "ç”¨æˆ¶èªè­‰å’Œæˆæ¬Šç›¸é—œ API",
        },
        {
            "name": "æ™ºèƒ½å•ç­”",
            "description": "å¸¶å‰å¾Œæ–‡è¨˜æ†¶çš„æ™ºèƒ½å°è©± API",
        },
        {
            "name": "çŸ¥è­˜åº«ç®¡ç†", 
            "description": "æ–‡ä»¶ä¸Šå‚³ã€è™•ç†å’Œç®¡ç† API",
        },
        {
            "name": "å°è©±è¨˜éŒ„",
            "description": "å°è©±æ­·å²å’Œçµ±è¨ˆ API",
        },
        {
            "name": "ç³»çµ±ç›£æ§",
            "description": "ç³»çµ±å¥åº·æª¢æŸ¥å’Œç‹€æ…‹ç›£æ§ API",
        },
    ]
)

# CORS è¨­ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿç”¢ç’°å¢ƒä¸­æ‡‰è©²é™åˆ¶ç‚ºç‰¹å®šåŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# éœæ…‹æ–‡ä»¶æœå‹™ï¼ˆç”¨æ–¼æ¼”ç¤ºé é¢ï¼‰
app.mount("/static", StaticFiles(directory="api"), name="static")

# ç°¡æ˜“èªè­‰é…ç½®
SECRET_KEY = os.getenv("API_SECRET_KEY", "your-secret-key-change-in-production")
API_KEYS = {
    "demo": "demo-api-key-123",
    "admin": "admin-api-key-456",
    "user": "user-api-key-789"
}

# å®‰å…¨é…ç½®
security = HTTPBearer()

# å…¨å±€å¯¦ä¾‹
rag_system = None
file_manager = None

# ================== æ•¸æ“šæ¨¡å‹ ==================

class APIKeyAuth(BaseModel):
    api_key: str = Field(..., 
                         description="API é‡‘é‘°",
                         example="demo-api-key-123")
    
    class Config:
        schema_extra = {
            "example": {
                "api_key": "demo-api-key-123"
            }
        }

class UserContext(BaseModel):
    user_id: str
    permissions: List[str] = ["read", "write"]
    session_id: Optional[str] = None

class ConversationMessage(BaseModel):
    role: str = Field(..., description="æ¶ˆæ¯è§’è‰²: user æˆ– assistant")
    content: str = Field(..., description="æ¶ˆæ¯å…§å®¹")
    timestamp: Optional[datetime] = None
    metadata: Optional[Dict[str, Any]] = {}

class ConversationContext(BaseModel):
    conversation_id: Optional[str] = None
    messages: List[ConversationMessage] = []
    max_history: int = Field(default=10, description="ä¿ç•™çš„æœ€å¤§æ¶ˆæ¯æ•¸")

class ChatRequest(BaseModel):
    question: str = Field(..., 
                          description="ç”¨æˆ¶å•é¡Œ", 
                          example="ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿè«‹è©³ç´°ä»‹ç´¹ä¸€ä¸‹ã€‚")
    conversation_context: Optional[ConversationContext] = Field(
        None,
        description="å°è©±ä¸Šä¸‹æ–‡ï¼ˆå¯é¸ï¼‰ï¼Œç”¨æ–¼ç¶­æŒå¤šè¼ªå°è©±è¨˜æ†¶"
    )
    user_id: Optional[str] = Field(
        "anonymous", 
        description="ç”¨æˆ¶IDï¼Œç”¨æ–¼è¿½è¹¤å’Œæ¬Šé™æ§åˆ¶"
    )
    session_id: Optional[str] = Field(
        None, 
        description="æœƒè©±IDï¼Œç”¨æ–¼å°è©±è¨˜éŒ„åˆ†çµ„"
    )
    include_sources: bool = Field(
        True, 
        description="æ˜¯å¦åœ¨å›æ‡‰ä¸­åŒ…å«åƒè€ƒä¾†æº"
    )
    max_sources: int = Field(
        3, 
        description="æœ€å¤§è¿”å›çš„åƒè€ƒä¾†æºæ•¸é‡",
        ge=1, le=10
    )
    temperature: Optional[float] = Field(
        0.7, 
        description="å›æ‡‰å‰µé€ æ€§åƒæ•¸ (0.0-1.0)",
        ge=0.0, le=1.0
    )
    
    class Config:
        schema_extra = {
            "example": {
                "question": "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿè«‹è©³ç´°ä»‹ç´¹ä¸€ä¸‹ã€‚",
                "include_sources": True,
                "max_sources": 3,
                "user_id": "demo_user",
                "temperature": 0.7
            }
        }

class SourceInfo(BaseModel):
    source: str
    file_path: str
    score: float
    content: str
    page: Optional[str] = None
    type: str = "document"

class ChatResponse(BaseModel):
    answer: str
    sources: List[SourceInfo] = []
    conversation_id: str
    metadata: Dict[str, Any] = {}
    context: ConversationContext
    response_time_ms: int
    timestamp: str

class FileUploadResponse(BaseModel):
    file_id: str
    filename: str
    size_bytes: int
    status: str
    chunks_created: int
    processing_time_ms: int

class KnowledgeBaseFile(BaseModel):
    id: str
    name: str
    size_mb: float
    type: str
    upload_time: str
    chunk_count: int
    status: str

class KnowledgeBaseStatus(BaseModel):
    total_files: int
    total_chunks: int
    total_size_mb: float
    files: List[KnowledgeBaseFile]

class SystemHealthCheck(BaseModel):
    status: str
    elasticsearch_connected: bool
    api_version: str
    uptime_seconds: int
    total_documents: int
    total_conversations: int
    system_info: Dict[str, Any]
    timestamp: str

class ConversationHistory(BaseModel):
    conversations: List[Dict[str, Any]]
    total_count: int
    page: int
    page_size: int

class ErrorResponse(BaseModel):
    error: str
    detail: str
    timestamp: str
    request_id: str

# ================== èªè­‰èˆ‡æˆæ¬Š ==================

def verify_api_key(credentials: HTTPAuthorizationCredentials = Depends(security)) -> UserContext:
    """é©—è­‰ API é‡‘é‘°"""
    token = credentials.credentials
    
    # æª¢æŸ¥æ˜¯å¦ç‚ºé è¨­ç¾©çš„ API é‡‘é‘°
    for user_type, api_key in API_KEYS.items():
        if token == api_key:
            permissions = ["read", "write"] if user_type in ["admin", "demo"] else ["read"]
            return UserContext(
                user_id=user_type,
                permissions=permissions,
                session_id=str(uuid.uuid4())
            )
    
    # å˜—è©¦è§£æ JWT Token
    try:
        payload = jwt.decode(token, SECRET_KEY, algorithms=["HS256"])
        return UserContext(
            user_id=payload.get("user_id", "unknown"),
            permissions=payload.get("permissions", ["read"]),
            session_id=payload.get("session_id")
        )
    except jwt.InvalidTokenError:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid API key or token",
            headers={"WWW-Authenticate": "Bearer"},
        )

def require_permission(permission: str):
    """æª¢æŸ¥ç”¨æˆ¶æ¬Šé™è£é£¾å™¨"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            user_context = kwargs.get('user_context')
            if user_context and permission in user_context.permissions:
                return await func(*args, **kwargs)
            raise HTTPException(
                status_code=status.HTTP_403_FORBIDDEN,
                detail=f"Permission '{permission}' required"
            )
        return wrapper
    return decorator

# ================== è¼”åŠ©å‡½æ•¸ ==================

def generate_request_id() -> str:
    """ç”Ÿæˆè«‹æ±‚ID"""
    return str(uuid.uuid4())[:8]

def build_conversation_context(messages: List[ConversationMessage], question: str) -> str:
    """æ§‹å»ºå°è©±ä¸Šä¸‹æ–‡"""
    if not messages:
        return question
    
    # æ§‹å»ºå°è©±æ­·å²
    context_parts = []
    for msg in messages[-5:]:  # åªä¿ç•™æœ€è¿‘5æ¢æ¶ˆæ¯
        role_prefix = "ç”¨æˆ¶" if msg.role == "user" else "åŠ©ç†"
        context_parts.append(f"{role_prefix}: {msg.content}")
    
    # æ·»åŠ ç•¶å‰å•é¡Œ
    context_parts.append(f"ç”¨æˆ¶: {question}")
    
    return "\n".join(context_parts)

def update_conversation_context(context: ConversationContext, question: str, answer: str) -> ConversationContext:
    """æ›´æ–°å°è©±ä¸Šä¸‹æ–‡"""
    now = datetime.now()
    
    # æ·»åŠ ç”¨æˆ¶æ¶ˆæ¯
    context.messages.append(ConversationMessage(
        role="user",
        content=question,
        timestamp=now
    ))
    
    # æ·»åŠ åŠ©ç†å›æ‡‰
    context.messages.append(ConversationMessage(
        role="assistant", 
        content=answer,
        timestamp=now
    ))
    
    # ä¿æŒæ¶ˆæ¯æ•¸é‡åœ¨é™åˆ¶å…§
    if len(context.messages) > context.max_history * 2:
        context.messages = context.messages[-(context.max_history * 2):]
    
    return context

# ================== å•Ÿå‹•äº‹ä»¶ ==================

@app.on_event("startup")
async def startup_event():
    """å•Ÿå‹•æ™‚åˆå§‹åŒ–ç³»çµ±"""
    global rag_system, file_manager
    
    try:
        print("ğŸš€ æ­£åœ¨åˆå§‹åŒ– Enhanced RAG API...")
        
        # åˆå§‹åŒ– RAG ç³»çµ±
        rag_system = EnhancedRAGSystemV2()
        if rag_system._initialize_elasticsearch():
            print("âœ… Elasticsearch RAG ç³»çµ±åˆå§‹åŒ–æˆåŠŸ")
        else:
            print("âŒ Elasticsearch RAG ç³»çµ±åˆå§‹åŒ–å¤±æ•—")
        
        # åˆå§‹åŒ–æ–‡ä»¶ç®¡ç†å™¨
        file_manager = UserFileManager()
        print("âœ… æ–‡ä»¶ç®¡ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
        
        print("ğŸ‰ Enhanced RAG API å•Ÿå‹•å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ ç³»çµ±åˆå§‹åŒ–éŒ¯èª¤: {str(e)}")
        print(traceback.format_exc())

# ================== API ç«¯é» ==================

@app.get("/", 
         summary="API æ ¹ç«¯é»", 
         description="ç²å– API åŸºæœ¬ä¿¡æ¯å’Œç‹€æ…‹",
         tags=["ç³»çµ±ç›£æ§"],
         response_description="API åŸºæœ¬ä¿¡æ¯")
async def root():
    """
    ## API æ ¹ç«¯é»
    
    è¿”å› Enhanced RAG API çš„åŸºæœ¬ä¿¡æ¯ï¼ŒåŒ…æ‹¬ï¼š
    - API ç‰ˆæœ¬ä¿¡æ¯
    - æ–‡æª”éˆæ¥
    - ç•¶å‰é‹è¡Œç‹€æ…‹
    - æ™‚é–“æˆ³
    
    **ç„¡éœ€èªè­‰**
    """
    return {
        "message": "Enhanced RAG API",
        "version": "2.0.0",
        "docs": "/docs",
        "redoc": "/redoc",
        "status": "running",
        "features": [
            "æ™ºèƒ½å•ç­”ï¼ˆå¸¶å°è©±è¨˜æ†¶ï¼‰",
            "çŸ¥è­˜åº«ç®¡ç†",
            "å¤šæ ¼å¼æ–‡ä»¶æ”¯æŒ", 
            "å®‰å…¨èªè­‰æ©Ÿåˆ¶",
            "å°è©±è¨˜éŒ„è¿½è¹¤"
        ],
        "demo_credentials": {
            "api_key": "demo-api-key-123",
            "note": "ä½¿ç”¨æ­¤ API Key ç²å–è¨ªå•ä»¤ç‰Œé€²è¡Œæ¸¬è©¦"
        },
        "timestamp": datetime.now().isoformat()
    }

@app.get("/health", 
         response_model=SystemHealthCheck, 
         summary="ç³»çµ±å¥åº·æª¢æŸ¥",
         description="æª¢æŸ¥ç³»çµ±å„çµ„ä»¶çš„é‹è¡Œç‹€æ…‹",
         tags=["ç³»çµ±ç›£æ§"],
         responses={
             200: {
                 "description": "ç³»çµ±å¥åº·ç‹€æ…‹",
                 "content": {
                     "application/json": {
                         "example": {
                             "status": "healthy",
                             "elasticsearch_connected": True,
                             "api_version": "2.0.0",
                             "uptime_seconds": 3600,
                             "total_documents": 42,
                             "total_conversations": 128,
                             "system_info": {
                                 "groq_configured": True,
                                 "gemini_configured": True
                             },
                             "timestamp": "2025-08-22T12:00:00"
                         }
                     }
                 }
             },
             500: {"description": "ç³»çµ±å¥åº·æª¢æŸ¥å¤±æ•—"}
         })
async def health_check():
    """
    ## ç³»çµ±å¥åº·æª¢æŸ¥
    
    æª¢æŸ¥ç³»çµ±å„å€‹çµ„ä»¶çš„é‹è¡Œç‹€æ…‹ï¼ŒåŒ…æ‹¬ï¼š
    - **Elasticsearch é€£æ¥ç‹€æ…‹**
    - **ç³»çµ±é‹è¡Œæ™‚é–“**
    - **æ–‡æª”å’Œå°è©±çµ±è¨ˆ**
    - **API é…ç½®ç‹€æ…‹**
    
    **ç„¡éœ€èªè­‰**
    
    ### å›æ‡‰ç‹€æ…‹
    - `healthy`: æ‰€æœ‰çµ„ä»¶æ­£å¸¸é‹è¡Œ
    - `degraded`: éƒ¨åˆ†çµ„ä»¶ç•°å¸¸ä½†æœå‹™å¯ç”¨
    - `unhealthy`: ç³»çµ±ç•°å¸¸
    """
    start_time = time.time()
    
    try:
        # æª¢æŸ¥ Elasticsearch é€£æ¥
        es_connected = False
        total_docs = 0
        total_conversations = 0
        
        if rag_system and rag_system.elasticsearch_client:
            es_connected = rag_system.elasticsearch_client.ping()
            if es_connected:
                stats = rag_system.get_document_statistics()
                total_docs = stats.get('total_documents', 0)
                
                if hasattr(rag_system, 'get_conversation_statistics'):
                    conv_stats = rag_system.get_conversation_statistics()
                    total_conversations = conv_stats.get('total_conversations', 0)
        
        return SystemHealthCheck(
            status="healthy" if es_connected else "degraded",
            elasticsearch_connected=es_connected,
            api_version="2.0.0",
            uptime_seconds=int(time.time() - start_time),
            total_documents=total_docs,
            total_conversations=total_conversations,
            system_info={
                "groq_configured": bool(GROQ_API_KEY),
                "gemini_configured": bool(GEMINI_API_KEY)
            },
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Health check failed: {str(e)}"
        )

@app.post("/auth/token", 
          summary="ç”Ÿæˆè¨ªå•ä»¤ç‰Œ",
          description="ä½¿ç”¨ API Key ç”Ÿæˆ JWT è¨ªå•ä»¤ç‰Œ",
          tags=["èªè­‰"],
          responses={
              200: {
                  "description": "æˆåŠŸç”Ÿæˆè¨ªå•ä»¤ç‰Œ",
                  "content": {
                      "application/json": {
                          "example": {
                              "access_token": "eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9...",
                              "token_type": "bearer",
                              "expires_in": 86400,
                              "user_id": "demo",
                              "permissions": ["read", "write"]
                          }
                      }
                  }
              },
              401: {"description": "ç„¡æ•ˆçš„ API Key"}
          })
async def generate_token(auth: APIKeyAuth):
    """ç”Ÿæˆ JWT è¨ªå•ä»¤ç‰Œ"""
    
    # é©—è­‰ API é‡‘é‘°
    user_type = None
    for utype, api_key in API_KEYS.items():
        if auth.api_key == api_key:
            user_type = utype
            break
    
    if not user_type:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid API key"
        )
    
    # ç”Ÿæˆ JWT Token
    permissions = ["read", "write"] if user_type in ["admin", "demo"] else ["read"]
    payload = {
        "user_id": user_type,
        "permissions": permissions,
        "session_id": str(uuid.uuid4()),
        "exp": datetime.utcnow() + timedelta(hours=24)
    }
    
    token = jwt.encode(payload, SECRET_KEY, algorithm="HS256")
    
    return {
        "access_token": token,
        "token_type": "bearer",
        "expires_in": 86400,  # 24 hours
        "user_id": user_type,
        "permissions": permissions
    }

@app.post("/chat", 
          response_model=ChatResponse, 
          summary="æ™ºèƒ½å•ç­”ï¼ˆå¸¶å°è©±è¨˜æ†¶ï¼‰",
          description="åŸ·è¡Œæ™ºèƒ½å•ç­”ï¼Œæ”¯æ´å‰å¾Œæ–‡å°è©±è¨˜æ†¶å’Œå¤šè¼ªå°è©±ç†è§£",
          tags=["æ™ºèƒ½å•ç­”"],
          responses={
              200: {
                  "description": "æˆåŠŸç²å¾—æ™ºèƒ½å›ç­”",
                  "content": {
                      "application/json": {
                          "example": {
                              "answer": "æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€å€‹é‡è¦åˆ†æ”¯ï¼Œå®ƒæ˜¯ä¸€ç¨®è®“è¨ˆç®—æ©Ÿç³»çµ±èƒ½å¤ å¾æ•¸æ“šä¸­è‡ªå‹•å­¸ç¿’å’Œæ”¹é€²çš„æŠ€è¡“...",
                              "sources": [
                                  {
                                      "source": "ml_guide.pdf",
                                      "file_path": "/docs/ml_guide.pdf", 
                                      "score": 0.95,
                                      "content": "æ©Ÿå™¨å­¸ç¿’çš„å®šç¾©å’ŒåŸºæœ¬æ¦‚å¿µ...",
                                      "page": "ç¬¬1é ",
                                      "type": "document"
                                  }
                              ],
                              "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
                              "metadata": {
                                  "request_id": "req-123",
                                  "user_id": "demo_user",
                                  "contextual_query": True
                              },
                              "context": {
                                  "conversation_id": "550e8400-e29b-41d4-a716-446655440000",
                                  "messages": [
                                      {
                                          "role": "user",
                                          "content": "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
                                          "timestamp": "2025-08-22T12:00:00"
                                      },
                                      {
                                          "role": "assistant",
                                          "content": "æ©Ÿå™¨å­¸ç¿’æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€å€‹é‡è¦åˆ†æ”¯...",
                                          "timestamp": "2025-08-22T12:00:01"
                                      }
                                  ],
                                  "max_history": 10
                              },
                              "response_time_ms": 1250,
                              "timestamp": "2025-08-22T12:00:01"
                          }
                      }
                  }
              },
              401: {"description": "èªè­‰å¤±æ•—"},
              403: {"description": "æ¬Šé™ä¸è¶³"},
              500: {"description": "æœå‹™å™¨å…§éƒ¨éŒ¯èª¤"}
          })
async def chat_with_memory(
    request: ChatRequest,
    user_context: UserContext = Depends(verify_api_key)
):
    """
    ## æ™ºèƒ½å•ç­”ï¼ˆå¸¶å°è©±è¨˜æ†¶ï¼‰
    
    é€™æ˜¯ç³»çµ±çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œæä¾›æ™ºèƒ½å•ç­”æœå‹™ä¸¦æ”¯æ´å¤šè¼ªå°è©±è¨˜æ†¶ã€‚
    
    ### ğŸ§  æ ¸å¿ƒç‰¹æ€§
    - **ä¸Šä¸‹æ–‡ç†è§£**ï¼šè‡ªå‹•ç†è§£å‰å¾Œæ–‡é—œä¿‚
    - **å°è©±è¨˜æ†¶**ï¼šç¶­æŒå¤šè¼ªå°è©±çš„é€£è²«æ€§  
    - **æ™ºèƒ½æª¢ç´¢**ï¼šå¾çŸ¥è­˜åº«ä¸­æ‰¾åˆ°æœ€ç›¸é—œçš„ä¿¡æ¯
    - **ä¾†æºè¿½è¹¤**ï¼šæä¾›å›ç­”çš„åƒè€ƒä¾†æº
    
    ### ğŸ’¡ ä½¿ç”¨æŠ€å·§
    1. **é¦–æ¬¡å°è©±**ï¼šç›´æ¥æå•ï¼Œç³»çµ±æœƒæä¾›åŸºç¤å›ç­”
    2. **å¾ŒçºŒå°è©±**ï¼šå‚³å…¥ `conversation_context` å¯¦ç¾é€£çºŒå°è©±
    3. **èª¿æ•´åƒæ•¸**ï¼šä½¿ç”¨ `temperature` æ§åˆ¶å›ç­”çš„å‰µé€ æ€§
    4. **æ§åˆ¶ä¾†æº**ï¼šé€šé `max_sources` é™åˆ¶è¿”å›çš„åƒè€ƒè³‡æ–™æ•¸é‡
    
    ### ğŸ“ å°è©±è¨˜æ†¶å·¥ä½œåŸç†
    ç³»çµ±æœƒè‡ªå‹•ï¼š
    - ä¿å­˜æ¯è¼ªå°è©±çš„å•é¡Œå’Œå›ç­”
    - å°‡æ­·å²å°è©±è½‰æ›ç‚ºæŸ¥è©¢ä¸Šä¸‹æ–‡
    - æ™ºèƒ½æˆªæ–·éé•·çš„å°è©±æ­·å²
    - éš”é›¢ä¸åŒ conversation_id çš„å°è©±
    
    ### ğŸ”‘ æ¬Šé™è¦æ±‚
    éœ€è¦æœ‰æ•ˆçš„ JWT Tokenï¼ˆread æ¬Šé™å³å¯ï¼‰
    """
    start_time = time.time()
    request_id = generate_request_id()
    
    if not rag_system:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="RAG system not initialized"
        )
    
    try:
        # åˆå§‹åŒ–å°è©±ä¸Šä¸‹æ–‡
        context = request.conversation_context or ConversationContext()
        if not context.conversation_id:
            context.conversation_id = str(uuid.uuid4())
        
        # æ§‹å»ºå¸¶ä¸Šä¸‹æ–‡çš„æŸ¥è©¢
        contextual_question = build_conversation_context(context.messages, request.question)
        
        # åŸ·è¡Œ RAG V2.0 æŸ¥è©¢
        conversation_history = [
            {"role": msg.role, "content": msg.content} 
            for msg in context.messages
        ]
        
        user_preferences = {
            "content_types": ["title", "paragraph"],
            "topics": [],
            "preferred_length": "medium"
        }
        
        result = rag_system.query_with_sources_v2(
            question=contextual_question,
            conversation_history=conversation_history,
            user_preferences=user_preferences,
            max_sources=request.max_sources
        )
        
        # æ›´æ–°å°è©±ä¸Šä¸‹æ–‡
        context = update_conversation_context(context, request.question, result['answer'])
        
        # è™•ç†ä¾†æºä¿¡æ¯
        sources = []
        if request.include_sources and 'sources' in result:
            for source in result['sources'][:request.max_sources]:
                sources.append(SourceInfo(
                    source=source.get('source', ''),
                    file_path=source.get('file_path', ''),
                    score=source.get('score', 0.0),
                    content=source.get('content', ''),
                    page=source.get('page'),
                    type=source.get('type', 'document')
                ))
        
        response_time_ms = int((time.time() - start_time) * 1000)
        
        return ChatResponse(
            answer=result['answer'],
            sources=sources,
            conversation_id=context.conversation_id,
            metadata={
                **result.get('metadata', {}),
                'request_id': request_id,
                'user_id': request.user_id or user_context.user_id,
                'contextual_query': len(context.messages) > 0
            },
            context=context,
            response_time_ms=response_time_ms,
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Chat request failed: {str(e)}"
        )

@app.post("/upload", 
          response_model=FileUploadResponse, 
          summary="ä¸Šå‚³æ–‡ä»¶åˆ°çŸ¥è­˜åº«",
          description="ä¸Šå‚³æ–‡ä»¶ä¸¦è‡ªå‹•è™•ç†æˆå¯æœç´¢çš„çŸ¥è­˜åº«å…§å®¹",
          tags=["çŸ¥è­˜åº«ç®¡ç†"],
          responses={
              200: {
                  "description": "æ–‡ä»¶ä¸Šå‚³å’Œè™•ç†æˆåŠŸ",
                  "content": {
                      "application/json": {
                          "example": {
                              "file_id": "550e8400-e29b-41d4-a716-446655440000",
                              "filename": "machine_learning_guide.pdf",
                              "size_bytes": 1024000,
                              "status": "processed",
                              "chunks_created": 25,
                              "processing_time_ms": 3000
                          }
                      }
                  }
              },
              400: {"description": "ç„¡æ•ˆçš„æ–‡ä»¶æ ¼å¼"},
              403: {"description": "æ¬Šé™ä¸è¶³ï¼ˆéœ€è¦ write æ¬Šé™ï¼‰"},
              500: {"description": "æ–‡ä»¶è™•ç†å¤±æ•—"}
          })
async def upload_file(
    file: UploadFile = File(..., description="è¦ä¸Šå‚³çš„æ–‡ä»¶ï¼ˆæ”¯æ´ PDFã€Wordã€Markdownã€åœ–ç‰‡ç­‰æ ¼å¼ï¼‰"),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    user_context: UserContext = Depends(verify_api_key)
):
    """
    ## ä¸Šå‚³æ–‡ä»¶åˆ°çŸ¥è­˜åº«
    
    å°‡æ–‡ä»¶ä¸Šå‚³åˆ°ç³»çµ±ä¸¦è‡ªå‹•è™•ç†æˆå¯æœç´¢çš„çŸ¥è­˜åº«å…§å®¹ã€‚
    
    ### ğŸ“ æ”¯æ´æ ¼å¼
    - **æ–‡æª”**ï¼šPDFã€Word (.docx)ã€Markdown (.md)ã€ç´”æ–‡å­— (.txt)
    - **åœ–ç‰‡**ï¼šPNGã€JPGã€JPEGã€WebPã€BMPï¼ˆå°‡é€²è¡Œ OCR æ–‡å­—è­˜åˆ¥ï¼‰
    
    ### âš™ï¸ è™•ç†æµç¨‹
    1. **æ–‡ä»¶é©—è­‰**ï¼šæª¢æŸ¥æ ¼å¼å’Œå¤§å°
    2. **å…§å®¹æå–**ï¼šå¾æ–‡ä»¶ä¸­æå–æ–‡å­—å…§å®¹
    3. **æ–‡æœ¬åˆ†å¡Š**ï¼šå°‡é•·æ–‡æœ¬åˆ†å‰²æˆé©ç•¶å¤§å°çš„å¡Š
    4. **å‘é‡åŒ–**ï¼šç‚ºæ¯å€‹æ–‡æœ¬å¡Šç”Ÿæˆå‘é‡åµŒå…¥
    5. **ç´¢å¼•å­˜å„²**ï¼šå­˜å„²åˆ° Elasticsearch ä¸­ä¾›æœç´¢ä½¿ç”¨
    
    ### ğŸ“Š è™•ç†çµæœ
    - `file_id`ï¼šæ–‡ä»¶çš„å”¯ä¸€æ¨™è­˜ç¬¦
    - `chunks_created`ï¼šå‰µå»ºçš„æ–‡æœ¬å¡Šæ•¸é‡
    - `processing_time_ms`ï¼šè™•ç†è€—æ™‚ï¼ˆæ¯«ç§’ï¼‰
    
    ### ğŸ”‘ æ¬Šé™è¦æ±‚
    éœ€è¦ **write** æ¬Šé™çš„ JWT Token
    """
    
    # è¨˜éŒ„ä¸Šå‚³è«‹æ±‚é–‹å§‹
    api_logger.info(f"ğŸ“¤ æ–‡ä»¶ä¸Šå‚³è«‹æ±‚é–‹å§‹")
    api_logger.info(f"   - æ–‡ä»¶å: {file.filename}")
    api_logger.info(f"   - æ–‡ä»¶å¤§å°: {file.size} bytes")
    api_logger.info(f"   - å…§å®¹é¡å‹: {file.content_type}")
    api_logger.info(f"   - ç”¨æˆ¶: {user_context.user_id}")
    
    if "write" not in user_context.permissions:
        api_logger.warning(f"âŒ æ¬Šé™ä¸è¶³: ç”¨æˆ¶ {user_context.user_id} æ²’æœ‰å¯«å…¥æ¬Šé™")
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Write permission required for file upload"
        )
    
    if not rag_system or not file_manager:
        api_logger.error("âŒ ç³»çµ±æœªåˆå§‹åŒ–: RAGç³»çµ±æˆ–æ–‡ä»¶ç®¡ç†å™¨ä¸å¯ç”¨")
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="File processing system not initialized"
        )
    
    start_time = time.time()
    file_id = str(uuid.uuid4())
    api_logger.info(f"ğŸ†” åˆ†é…æ–‡ä»¶ID: {file_id}")
    
    try:
        # é©—è­‰æ–‡ä»¶
        api_logger.info("ğŸ” é–‹å§‹é©—è­‰æ–‡ä»¶...")
        validation_start = time.time()
        if not file_manager.validate_file(file):
            api_logger.error(f"âŒ æ–‡ä»¶é©—è­‰å¤±æ•—: {file.filename}")
            raise HTTPException(
                status_code=status.HTTP_400_BAD_REQUEST,
                detail="Invalid file type or format"
            )
        validation_time = time.time() - validation_start
        api_logger.info(f"âœ… æ–‡ä»¶é©—è­‰é€šéï¼Œè€—æ™‚: {validation_time:.3f}ç§’")
        
        # ä¿å­˜è‡¨æ™‚æ–‡ä»¶
        api_logger.info("ğŸ’¾ é–‹å§‹ä¿å­˜è‡¨æ™‚æ–‡ä»¶...")
        save_start = time.time()
        temp_dir = tempfile.mkdtemp()
        temp_file_path = os.path.join(temp_dir, file.filename)
        api_logger.info(f"   - è‡¨æ™‚ç›®éŒ„: {temp_dir}")
        api_logger.info(f"   - è‡¨æ™‚æ–‡ä»¶è·¯å¾‘: {temp_file_path}")
        
        with open(temp_file_path, "wb") as buffer:
            content = await file.read()
            buffer.write(content)
        
        save_time = time.time() - save_start
        api_logger.info(f"âœ… è‡¨æ™‚æ–‡ä»¶ä¿å­˜å®Œæˆï¼Œè€—æ™‚: {save_time:.3f}ç§’")
        
        # ä½¿ç”¨V2.0è™•ç†æ–‡ä»¶
        api_logger.info("ğŸ”„ é–‹å§‹V2.0æ–‡ä»¶è™•ç†...")
        process_start = time.time()
        
        try:
            processing_stats = rag_system.process_uploaded_file_v2(file, file_manager)
            process_time = time.time() - process_start
            api_logger.info(f"âœ… V2.0æ–‡ä»¶è™•ç†å®Œæˆï¼Œè€—æ™‚: {process_time:.3f}ç§’")
            api_logger.info(f"   - è™•ç†çµ±è¨ˆ: {processing_stats}")
            
        except Exception as process_error:
            process_time = time.time() - process_start
            api_logger.error(f"âŒ V2.0æ–‡ä»¶è™•ç†å¤±æ•—ï¼Œè€—æ™‚: {process_time:.3f}ç§’")
            log_exception(api_logger, f"V2.0è™•ç†ç•°å¸¸è©³æƒ…", sys.exc_info())
            raise process_error
        
        chunks_created = processing_stats.get("chunks_created", 0)
        optimization_used = processing_stats.get("optimization_used", [])
        
        api_logger.info(f"ğŸ“Š è™•ç†çµæœ:")
        api_logger.info(f"   - å‰µå»ºchunks: {chunks_created}")
        api_logger.info(f"   - ä½¿ç”¨å„ªåŒ–: {optimization_used}")
        
        # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
        api_logger.info("ğŸ§¹ æ¸…ç†è‡¨æ™‚æ–‡ä»¶...")
        try:
            os.unlink(temp_file_path)
            os.rmdir(temp_dir)
            api_logger.info("âœ… è‡¨æ™‚æ–‡ä»¶æ¸…ç†å®Œæˆ")
        except Exception as cleanup_error:
            api_logger.warning(f"âš ï¸ è‡¨æ™‚æ–‡ä»¶æ¸…ç†å¤±æ•—: {cleanup_error}")
        
        processing_time_ms = int((time.time() - start_time) * 1000)
        final_status = "processed" if chunks_created > 0 else "failed"
        
        api_logger.info(f"ğŸ‰ æ–‡ä»¶ä¸Šå‚³è™•ç†å®Œæˆ:")
        api_logger.info(f"   - æ–‡ä»¶ID: {file_id}")
        api_logger.info(f"   - ç‹€æ…‹: {final_status}")
        api_logger.info(f"   - ç¸½è€—æ™‚: {processing_time_ms}ms")
        
        # è¨˜éŒ„æ€§èƒ½æŒ‡æ¨™
        log_performance(api_logger, f"æ–‡ä»¶ä¸Šå‚³[{file.filename}]", processing_time_ms/1000, 
                       f"chunks={chunks_created}, size={file.size}bytes")
        
        return FileUploadResponse(
            file_id=file_id,
            filename=file.filename,
            size_bytes=file.size,
            status=final_status,
            chunks_created=chunks_created,
            processing_time_ms=processing_time_ms
        )
        
    except HTTPException:
        # HTTPç•°å¸¸ç›´æ¥é‡æ–°æ‹‹å‡ºï¼Œä¸éœ€è¦é¡å¤–è™•ç†
        raise
    except Exception as e:
        total_time = time.time() - start_time
        api_logger.error(f"ğŸ’¥ æ–‡ä»¶ä¸Šå‚³è™•ç†ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤ï¼Œç¸½è€—æ™‚: {total_time:.3f}ç§’")
        api_logger.error(f"   - æ–‡ä»¶: {file.filename}")
        api_logger.error(f"   - æ–‡ä»¶ID: {file_id}")
        log_exception(api_logger, f"æ–‡ä»¶ä¸Šå‚³ç•°å¸¸è©³æƒ…", sys.exc_info())
        
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"File upload failed: {str(e)}"
        )

@app.get("/knowledge-base", 
         response_model=KnowledgeBaseStatus, 
         summary="ç²å–çŸ¥è­˜åº«ç‹€æ…‹",
         description="æŸ¥çœ‹çŸ¥è­˜åº«ä¸­æ‰€æœ‰æ–‡ä»¶çš„ç‹€æ…‹å’Œçµ±è¨ˆä¿¡æ¯",
         tags=["çŸ¥è­˜åº«ç®¡ç†"])
async def get_knowledge_base_status(
    user_context: UserContext = Depends(verify_api_key)
):
    """ç²å–çŸ¥è­˜åº«æ–‡ä»¶å’Œçµ±è¨ˆä¿¡æ¯"""
    
    if not rag_system:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="RAG system not initialized"
        )
    
    try:
        # ç²å–çµ±è¨ˆä¿¡æ¯
        stats = rag_system.get_document_statistics()
        
        # ç²å–æ–‡ä»¶åˆ—è¡¨
        files = []
        if hasattr(rag_system, 'get_indexed_files'):
            indexed_files = rag_system.get_indexed_files()
            for file_info in indexed_files:
                files.append(KnowledgeBaseFile(
                    id=file_info.get('id', str(uuid.uuid4())),
                    name=file_info.get('name', 'Unknown'),
                    size_mb=file_info.get('size_mb', 0.0),
                    type=file_info.get('type', 'unknown'),
                    upload_time=file_info.get('upload_time', ''),
                    chunk_count=file_info.get('node_count', 0),
                    status=file_info.get('status', 'active')
                ))
        
        return KnowledgeBaseStatus(
            total_files=stats.get('total_files', len(files)),
            total_chunks=stats.get('total_documents', 0),
            total_size_mb=stats.get('total_size_mb', 0.0),
            files=files
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get knowledge base status: {str(e)}"
        )

@app.delete("/knowledge-base/files/{file_id:path}", 
            summary="åˆªé™¤çŸ¥è­˜åº«æ–‡ä»¶",
            description="å¾çŸ¥è­˜åº«ä¸­æ°¸ä¹…åˆªé™¤æŒ‡å®šçš„æ–‡ä»¶",
            tags=["çŸ¥è­˜åº«ç®¡ç†"])
async def delete_knowledge_base_file(
    file_id: str,
    user_context: UserContext = Depends(verify_api_key)
):
    """å¾çŸ¥è­˜åº«ä¸­åˆªé™¤æŒ‡å®šæ–‡ä»¶"""
    
    if "write" not in user_context.permissions:
        raise HTTPException(
            status_code=status.HTTP_403_FORBIDDEN,
            detail="Write permission required for file deletion"
        )
    
    if not rag_system:
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="RAG system not initialized"
        )
    
    try:
        # URL è§£ç¢¼æ–‡ä»¶ ID
        decoded_file_id = unquote(file_id)
        api_logger.info(f"ğŸ—‘ï¸ å˜—è©¦åˆªé™¤æ–‡ä»¶: {decoded_file_id}")
        
        success = rag_system.delete_file_from_knowledge_base(decoded_file_id)
        
        if success:
            api_logger.info(f"âœ… æ–‡ä»¶åˆªé™¤æˆåŠŸ: {decoded_file_id}")
            return {"message": f"File {file_id} deleted successfully"}
        else:
            api_logger.warning(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°æˆ–åˆªé™¤å¤±æ•—: {decoded_file_id}")
            raise HTTPException(
                status_code=status.HTTP_404_NOT_FOUND,
                detail=f"File '{file_id}' not found in knowledge base. The file may have been already deleted or never existed."
            )
            
    except HTTPException as http_exc:
        raise http_exc
    except Exception as e:
        # Log the actual error for debugging
        api_logger.error(f"ğŸ’¥ æ–‡ä»¶åˆªé™¤ç•°å¸¸ - æ–‡ä»¶ID: {file_id}, éŒ¯èª¤: {str(e)}")
        api_logger.error(f"   - åŸå§‹æ–‡ä»¶ID: {file_id}")
        api_logger.error(f"   - è§£ç¢¼å¾ŒID: {unquote(file_id) if file_id else 'None'}")
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"File deletion failed due to internal error. Please check server logs."
        )

@app.get("/conversations", 
         response_model=ConversationHistory, 
         summary="ç²å–å°è©±è¨˜éŒ„",
         description="åˆ†é ç²å–ç”¨æˆ¶çš„å°è©±æ­·å²è¨˜éŒ„",
         tags=["å°è©±è¨˜éŒ„"])
async def get_conversation_history(
    page: int = 1,
    page_size: int = 20,
    user_id: Optional[str] = None,
    session_id: Optional[str] = None,
    user_context: UserContext = Depends(verify_api_key)
):
    """ç²å–å°è©±è¨˜éŒ„åˆ—è¡¨"""
    
    if not rag_system or not hasattr(rag_system, 'get_conversation_history'):
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Conversation history not available"
        )
    
    try:
        # å¦‚æœä¸æ˜¯ admin ç”¨æˆ¶ï¼Œåªèƒ½æŸ¥çœ‹è‡ªå·±çš„å°è©±
        if user_context.user_id != "admin":
            user_id = user_context.user_id
        
        conversations = rag_system.get_conversation_history(
            session_id=session_id,
            limit=page_size
        )
        
        # ç°¡å–®åˆ†é è™•ç†
        start_idx = (page - 1) * page_size
        end_idx = start_idx + page_size
        paginated_conversations = conversations[start_idx:end_idx]
        
        return ConversationHistory(
            conversations=paginated_conversations,
            total_count=len(conversations),
            page=page,
            page_size=page_size
        )
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get conversation history: {str(e)}"
        )

@app.get("/conversations/stats", 
         summary="ç²å–å°è©±çµ±è¨ˆ",
         description="ç²å–å°è©±ç³»çµ±çš„çµ±è¨ˆä¿¡æ¯å’Œåˆ†ææ•¸æ“š",
         tags=["å°è©±è¨˜éŒ„"])
async def get_conversation_stats(
    user_context: UserContext = Depends(verify_api_key)
):
    """ç²å–å°è©±çµ±è¨ˆä¿¡æ¯"""
    
    if not rag_system or not hasattr(rag_system, 'get_conversation_statistics'):
        raise HTTPException(
            status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
            detail="Conversation statistics not available"
        )
    
    try:
        stats = rag_system.get_conversation_statistics()
        return stats
        
    except Exception as e:
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"Failed to get conversation statistics: {str(e)}"
        )

# ================== éŒ¯èª¤è™•ç† ==================

@app.exception_handler(HTTPException)
async def http_exception_handler(request, exc):
    """HTTP ç•°å¸¸è™•ç†å™¨"""
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "error": exc.detail,
            "status_code": exc.status_code,
            "timestamp": datetime.now().isoformat(),
            "request_id": generate_request_id()
        }
    )

@app.exception_handler(Exception)
async def general_exception_handler(request, exc):
    """é€šç”¨ç•°å¸¸è™•ç†å™¨"""
    return JSONResponse(
        status_code=500,
        content={
            "error": "Internal server error",
            "detail": str(exc),
            "timestamp": datetime.now().isoformat(),
            "request_id": generate_request_id()
        }
    )

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)