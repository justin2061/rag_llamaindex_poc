import os
from dotenv import load_dotenv

# è¼‰å…¥ç’°å¢ƒè®Šæ•¸
load_dotenv()

# API è¨­å®š
GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")  # å¯é¸ï¼Œç”¨æ–¼ OCR åŠŸèƒ½
JINA_API_KEY = os.getenv("JINA_API_KEY")      # å¯é¸ï¼Œç”¨æ–¼å„ªåŒ– embedding æ•ˆæœ

# UI/UX è¨­å®š
SHOW_TECHNICAL_MESSAGES = os.getenv("SHOW_TECHNICAL_MESSAGES", "false").lower() == "true"  # æ˜¯å¦é¡¯ç¤ºæŠ€è¡“è¨Šæ¯
DEBUG_MODE = os.getenv("DEBUG_MODE", "false").lower() == "true"  # é™¤éŒ¯æ¨¡å¼

# æ¨¡å‹è¨­å®š
LLM_MODEL = "llama-3.3-70b-versatile"  # Groq æ¨¡å‹

# PDF ä¾†æºç¶²å€
PDF_SOURCES = {
    "èŒ¶æ¥­ç ”ç©¶å½™å ±": [
        "https://www.tbrs.gov.tw/files/tbrs/web_structure/4399/A01_1.pdf",  # ç¬¬1æœŸ
        "https://www.tbrs.gov.tw/files/tbrs/web_structure/4410/A01_1.pdf",  # ç¬¬2æœŸ
        "https://www.tbrs.gov.tw/files/tbrs/web_structure/4427/A01_1.pdf",  # ç¬¬3æœŸ
    ],
    "èŒ¶æ¥­å°ˆè¨Šèˆ‡å…¶ä»–æ–‡ä»¶": [
        # é€™è£¡å¯ä»¥åŠ å…¥æ›´å¤šå¾ç¶²é ä¸Šæ‰¾åˆ°çš„PDFé€£çµ
    ]
}

# ç¶²é ä¾†æº - ç”¨æ–¼è‡ªå‹•ç™¼ç¾PDFé€£çµ
WEB_SOURCES = [
    "https://www.tbrs.gov.tw/ws.php?id=4189",  # å°ç£èŒ¶æ¥­ç ”ç©¶å½™å ±æ‘˜è¦
    "https://www.tbrs.gov.tw/ws.php?id=1569",  # å…¶ä»–èŒ¶æ¥­ç›¸é—œé é¢
]

# æ¨¡å‹è¨­å®š
EMBEDDING_PROVIDER = os.getenv("EMBEDDING_PROVIDER", "jina").lower() # 'jina' or 'local'
EMBEDDING_MODEL = "jina-embeddings-v3"
LLM_MODEL = "llama-3.3-70b-versatile"  # Groq æ¨¡å‹

# æª”æ¡ˆè·¯å¾‘è¨­å®š
DATA_DIR = "data"
PDF_DIR = os.path.join(DATA_DIR, "pdfs")
INDEX_DIR = os.path.join(DATA_DIR, "index")

# å»ºç«‹ç›®éŒ„
os.makedirs(PDF_DIR, exist_ok=True)
os.makedirs(INDEX_DIR, exist_ok=True)

# Google Geminiè¨­å®š
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
ENABLE_OCR = os.getenv("ENABLE_OCR", "true").lower() == "true"

# æª”æ¡ˆä¸Šå‚³è¨­å®š
MAX_FILE_SIZE_MB = int(os.getenv("MAX_FILE_SIZE_MB", 10))
MAX_IMAGE_SIZE_MB = int(os.getenv("MAX_IMAGE_SIZE_MB", 5))
SUPPORTED_FILE_TYPES = os.getenv("SUPPORTED_FILE_TYPES", "pdf,txt,docx,md,png,jpg,jpeg,webp,bmp").split(',')
MAX_UPLOAD_FILES = int(os.getenv("MAX_UPLOAD_FILES", 50))

# Graph RAG è¨­å®š
ENABLE_GRAPH_RAG = os.getenv("ENABLE_GRAPH_RAG", "true").lower() == "true"
MAX_TRIPLETS_PER_CHUNK = int(os.getenv("MAX_TRIPLETS_PER_CHUNK", 10))
GRAPH_COMMUNITY_SIZE = int(os.getenv("GRAPH_COMMUNITY_SIZE", 5))

# å°è©±è¨˜æ†¶è¨­å®š
CONVERSATION_MEMORY_STEPS = int(os.getenv("CONVERSATION_MEMORY_STEPS", 5))
MAX_CONTEXT_LENGTH = int(os.getenv("MAX_CONTEXT_LENGTH", 4000))
ENABLE_CONVERSATION_MEMORY = os.getenv("ENABLE_CONVERSATION_MEMORY", "true").lower() == "true"

# æª”æ¡ˆè·¯å¾‘è¨­å®š
USER_UPLOADS_DIR = os.path.join(DATA_DIR, "user_uploads")

# å»ºç«‹ç›®éŒ„
os.makedirs(USER_UPLOADS_DIR, exist_ok=True)

# Streamlit è¨­å®š
PAGE_TITLE = "RAGæ™ºèƒ½å•ç­”ç³»çµ±"
PAGE_ICON = "ğŸ¤–"

# Elasticsearch è¨­å®š
ELASTICSEARCH_HOST = os.getenv("ELASTICSEARCH_HOST", "localhost")
ELASTICSEARCH_PORT = int(os.getenv("ELASTICSEARCH_PORT", 9200))
ELASTICSEARCH_SCHEME = os.getenv("ELASTICSEARCH_SCHEME", "http")  # http or https
ELASTICSEARCH_INDEX_NAME = os.getenv("ELASTICSEARCH_INDEX_NAME", "rag_intelligent_assistant")
ELASTICSEARCH_USERNAME = os.getenv("ELASTICSEARCH_USERNAME")
ELASTICSEARCH_PASSWORD = os.getenv("ELASTICSEARCH_PASSWORD")
ELASTICSEARCH_TIMEOUT = int(os.getenv("ELASTICSEARCH_TIMEOUT", 30))
ELASTICSEARCH_MAX_RETRIES = int(os.getenv("ELASTICSEARCH_MAX_RETRIES", 3))
ELASTICSEARCH_VERIFY_CERTS = os.getenv("ELASTICSEARCH_VERIFY_CERTS", "false").lower() == "true"

# Elasticsearch ç´¢å¼•è¨­å®š
ELASTICSEARCH_SHARDS = int(os.getenv("ELASTICSEARCH_SHARDS", 1))
ELASTICSEARCH_REPLICAS = int(os.getenv("ELASTICSEARCH_REPLICAS", 0))
ELASTICSEARCH_VECTOR_DIMENSION = int(os.getenv("ELASTICSEARCH_VECTOR_DIMENSION", 512))  # Enhanced dimension for better semantic representation
ELASTICSEARCH_SIMILARITY = os.getenv("ELASTICSEARCH_SIMILARITY", "cosine")

# å‘é‡å­˜å„²å„ªå…ˆé †åºè¨­å®š
ENABLE_ELASTICSEARCH = os.getenv("ENABLE_ELASTICSEARCH", "true").lower() == "true"  # é è¨­å•Ÿç”¨
VECTOR_STORE_PRIORITY = os.getenv("VECTOR_STORE_PRIORITY", "elasticsearch,simple").split(",")  # å„ªå…ˆé †åº

# Phase 1 å„ªåŒ–è¨­å®š - æ™ºèƒ½åˆ‡å‰²èˆ‡çµæ§‹è­˜åˆ¥
CHUNK_SIZE = int(os.getenv("CHUNK_SIZE", 1024))  # åŸºç¤åˆ‡å‰²å¤§å°
CHUNK_OVERLAP = int(os.getenv("CHUNK_OVERLAP", 200))  # é‡ç–Šå­—ç¬¦æ•¸
ENABLE_HIERARCHICAL_CHUNKING = os.getenv("ENABLE_HIERARCHICAL_CHUNKING", "false").lower() == "true"
ENABLE_DOCUMENT_STRUCTURE_DETECTION = os.getenv("ENABLE_DOCUMENT_STRUCTURE_DETECTION", "false").lower() == "true"

# Phase 2 å„ªåŒ–è¨­å®š - æ··åˆæª¢ç´¢
ENABLE_HYBRID_SEARCH = os.getenv("ENABLE_HYBRID_SEARCH", "false").lower() == "true"
ENABLE_QUERY_REWRITING = os.getenv("ENABLE_QUERY_REWRITING", "false").lower() == "true"
HYBRID_SEARCH_WEIGHTS = {
    "vector": float(os.getenv("VECTOR_SEARCH_WEIGHT", 0.6)),
    "keyword": float(os.getenv("KEYWORD_SEARCH_WEIGHT", 0.3)),
    "semantic": float(os.getenv("SEMANTIC_SEARCH_WEIGHT", 0.1))
}

# Phase 3 å„ªåŒ–è¨­å®š - å¤šæ¨¡å‹ç­–ç•¥
ENABLE_MULTI_EMBEDDING = os.getenv("ENABLE_MULTI_EMBEDDING", "false").lower() == "true"
ENABLE_CONTEXTUAL_RERANKING = os.getenv("ENABLE_CONTEXTUAL_RERANKING", "false").lower() == "true"
RERANKING_MODEL = os.getenv("RERANKING_MODEL", "bge-reranker-base")

# å¤šç²’åº¦åˆ‡å‰²é…ç½®
CHUNK_STRATEGIES = {
    "short": {"size": 512, "overlap": 100},   # çŸ­æ–‡æœ¬ç²¾ç¢ºæœç´¢
    "medium": {"size": 1024, "overlap": 200}, # ä¸­ç­‰æ–‡æœ¬ä¸Šä¸‹æ–‡  
    "long": {"size": 2048, "overlap": 400}    # é•·æ–‡æœ¬æ•´é«”ç†è§£
}

# RAG ç³»çµ±é¸æ“‡
RAG_SYSTEM_TYPE = os.getenv("RAG_SYSTEM_TYPE", "enhanced").lower()  # enhanced, graph, elasticsearch

# æ‡‰ç”¨ç¨‹å¼æ¨¡å¼
APP_MODE = os.getenv("APP_MODE", "full").lower() # full, quick, ultra_fast
