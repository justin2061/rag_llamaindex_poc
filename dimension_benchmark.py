#!/usr/bin/env python3
"""
Elasticsearch å‘é‡ç¶­åº¦åŸºæº–æ¸¬è©¦
æ¸¬è©¦ä¸åŒç¶­åº¦ä¸‹çš„æŸ¥è©¢é€Ÿåº¦å’Œæº–ç¢ºæ€§
"""

import sys
import os
import time
import json
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent
sys.path.append(str(project_root))

def test_dimension_performance(dimensions: List[int], test_queries: List[str]) -> Dict[str, Any]:
    """æ¸¬è©¦ä¸åŒç¶­åº¦ä¸‹çš„æ€§èƒ½
    
    Args:
        dimensions: è¦æ¸¬è©¦çš„ç¶­åº¦åˆ—è¡¨
        test_queries: æ¸¬è©¦æŸ¥è©¢åˆ—è¡¨
        
    Returns:
        Dict: æ€§èƒ½æ¸¬è©¦çµæœ
    """
    results = {
        'timestamp': datetime.now().isoformat(),
        'test_queries': test_queries,
        'dimension_results': {}
    }
    
    for dim in dimensions:
        print(f"\nğŸ”§ æ¸¬è©¦ç¶­åº¦: {dim}")
        
        try:
            # è¨­ç½®æ¸¬è©¦ç¶­åº¦
            os.environ['ELASTICSEARCH_VECTOR_DIMENSION'] = str(dim)
            
            # é‡æ–°åŠ è¼‰é…ç½®
            import importlib
            import config.config
            importlib.reload(config.config)
            
            # å‰µå»ºæ¸¬è©¦ç´¢å¼•åç¨±
            test_index = f"dimension_test_{dim}"
            
            # æ¸¬è©¦åµŒå…¥ç”Ÿæˆé€Ÿåº¦
            embed_start = time.time()
            from src.utils.embedding_fix import setup_safe_embedding
            embedding_model = setup_safe_embedding()
            
            # ç”Ÿæˆæ¸¬è©¦åµŒå…¥
            test_embeddings = []
            for query in test_queries:
                embed = embedding_model.get_text_embedding(query)
                test_embeddings.append(embed)
            
            embed_time = time.time() - embed_start
            
            # é©—è­‰ç¶­åº¦
            actual_dim = len(test_embeddings[0]) if test_embeddings else 0
            
            print(f"âœ… åµŒå…¥ç”Ÿæˆå®Œæˆ: {len(test_queries)} æŸ¥è©¢, å¯¦éš›ç¶­åº¦: {actual_dim}")
            print(f"â±ï¸ åµŒå…¥ç”Ÿæˆæ™‚é–“: {embed_time:.3f}s ({embed_time/len(test_queries):.3f}s/query)")
            
            # æ¸¬è©¦ Elasticsearch ç´¢å¼•å‰µå»º
            from elasticsearch import Elasticsearch
            es_client = Elasticsearch([{'host': 'elasticsearch', 'port': 9200, 'scheme': 'http'}])
            
            if not es_client.ping():
                print(f"âŒ ç„¡æ³•é€£æ¥åˆ° Elasticsearch")
                continue
            
            # å‰µå»ºæ¸¬è©¦ç´¢å¼•çš„ mapping
            from config.elasticsearch.mapping_loader import ElasticsearchMappingLoader
            loader = ElasticsearchMappingLoader()
            
            variables = {
                'SHARDS': 1,
                'REPLICAS': 0,
                'DIMENSION': dim,
                'SIMILARITY': 'cosine'
            }
            
            mapping = loader.load_mapping(**variables)
            
            # åˆªé™¤èˆŠæ¸¬è©¦ç´¢å¼•ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            if es_client.indices.exists(index=test_index):
                es_client.indices.delete(index=test_index)
            
            # å‰µå»ºæ¸¬è©¦ç´¢å¼•
            index_start = time.time()
            es_client.indices.create(index=test_index, body=mapping)
            index_time = time.time() - index_start
            
            print(f"â±ï¸ ç´¢å¼•å‰µå»ºæ™‚é–“: {index_time:.3f}s")
            
            # ç´¢å¼•ä¸€äº›æ¸¬è©¦æ–‡æª”
            docs_start = time.time()
            for i, (query, embedding) in enumerate(zip(test_queries, test_embeddings)):
                doc = {
                    'content': f"æ¸¬è©¦æ–‡æª” {i+1}: {query}",
                    'embedding': embedding,
                    'metadata': {
                        'source': f'test_doc_{i+1}',
                        'timestamp': datetime.now().isoformat()
                    }
                }
                es_client.index(index=test_index, document=doc)
            
            # åˆ·æ–°ç´¢å¼•
            es_client.indices.refresh(index=test_index)
            docs_time = time.time() - docs_start
            
            print(f"â±ï¸ æ–‡æª”ç´¢å¼•æ™‚é–“: {docs_time:.3f}s ({docs_time/len(test_queries):.3f}s/doc)")
            
            # æ¸¬è©¦æŸ¥è©¢æ€§èƒ½
            query_times = []
            for query, query_embedding in zip(test_queries, test_embeddings):
                query_start = time.time()
                
                search_query = {
                    "size": 5,
                    "query": {
                        "script_score": {
                            "query": {"match_all": {}},
                            "script": {
                                "source": "cosineSimilarity(params.query_vector, 'embedding') + 1.0",
                                "params": {"query_vector": query_embedding}
                            }
                        }
                    }
                }
                
                response = es_client.search(index=test_index, body=search_query)
                query_time = time.time() - query_start
                query_times.append(query_time)
            
            avg_query_time = sum(query_times) / len(query_times)
            print(f"â±ï¸ å¹³å‡æŸ¥è©¢æ™‚é–“: {avg_query_time:.3f}s")
            
            # ç²å–ç´¢å¼•çµ±è¨ˆ
            stats = es_client.indices.stats(index=test_index)
            index_size = stats['indices'][test_index]['total']['store']['size_in_bytes']
            
            print(f"ğŸ“Š ç´¢å¼•å¤§å°: {index_size / 1024:.2f} KB")
            
            # è¨˜éŒ„çµæœ
            results['dimension_results'][dim] = {
                'actual_dimension': actual_dim,
                'embedding_time_total': embed_time,
                'embedding_time_per_query': embed_time / len(test_queries),
                'index_creation_time': index_time,
                'document_indexing_time': docs_time,
                'document_indexing_time_per_doc': docs_time / len(test_queries),
                'average_query_time': avg_query_time,
                'index_size_bytes': index_size,
                'index_size_kb': index_size / 1024
            }
            
            # æ¸…ç†æ¸¬è©¦ç´¢å¼•
            es_client.indices.delete(index=test_index)
            print(f"ğŸ—‘ï¸ å·²æ¸…ç†æ¸¬è©¦ç´¢å¼•: {test_index}")
            
        except Exception as e:
            print(f"âŒ ç¶­åº¦ {dim} æ¸¬è©¦å¤±æ•—: {str(e)}")
            results['dimension_results'][dim] = {
                'error': str(e)
            }
    
    return results

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸš€ é–‹å§‹ Elasticsearch å‘é‡ç¶­åº¦æ€§èƒ½åŸºæº–æ¸¬è©¦")
    
    # æ¸¬è©¦ç¶­åº¦ï¼ˆæ ¹æ“š Jina v3 çš„ MRL æ”¯æŒï¼‰
    test_dimensions = [128, 256, 384, 512, 768, 1024]
    
    # æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ",
        "å¦‚ä½•å„ªåŒ–æ•¸æ“šåº«æ€§èƒ½ï¼Ÿ",
        "Python ç¨‹å¼è¨­è¨ˆæœ€ä½³å¯¦è¸",
        "é›²ç«¯é‹ç®—çš„å„ªå‹¢å’ŒæŒ‘æˆ°",
        "äººå·¥æ™ºèƒ½åœ¨é†«ç™‚é ˜åŸŸçš„æ‡‰ç”¨"
    ]
    
    print(f"ğŸ“‹ æ¸¬è©¦ç¶­åº¦: {test_dimensions}")
    print(f"ğŸ“‹ æ¸¬è©¦æŸ¥è©¢æ•¸é‡: {len(test_queries)}")
    
    # åŸ·è¡Œæ¸¬è©¦
    results = test_dimension_performance(test_dimensions, test_queries)
    
    # ä¿å­˜çµæœ
    results_file = "data/dimension_benchmark_results.json"
    os.makedirs("data", exist_ok=True)
    
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ æ¸¬è©¦çµæœå·²ä¿å­˜åˆ°: {results_file}")
    
    # åˆ†æçµæœ
    print("\nğŸ“Š æ€§èƒ½åˆ†ææ‘˜è¦:")
    print("ç¶­åº¦\tåµŒå…¥æ™‚é–“\tæŸ¥è©¢æ™‚é–“\tç´¢å¼•å¤§å°")
    print("-" * 50)
    
    for dim, result in results['dimension_results'].items():
        if 'error' not in result:
            embed_time = result['embedding_time_per_query'] * 1000  # è½‰æ›ç‚ºæ¯«ç§’
            query_time = result['average_query_time'] * 1000        # è½‰æ›ç‚ºæ¯«ç§’
            index_size = result['index_size_kb']
            
            print(f"{dim}\t{embed_time:.1f}ms\t\t{query_time:.1f}ms\t\t{index_size:.1f}KB")
        else:
            print(f"{dim}\téŒ¯èª¤: {result['error']}")
    
    # æ¨è–¦æœ€ä½³ç¶­åº¦
    print("\nğŸ’¡ åŸºæ–¼æ¸¬è©¦çµæœçš„å»ºè­°:")
    
    valid_results = {dim: result for dim, result in results['dimension_results'].items() 
                    if 'error' not in result}
    
    if valid_results:
        # æ‰¾å‡ºæŸ¥è©¢é€Ÿåº¦æœ€å¿«çš„ç¶­åº¦
        fastest_query = min(valid_results.items(), 
                          key=lambda x: x[1]['average_query_time'])
        
        # æ‰¾å‡ºç´¢å¼•å¤§å°æœ€å°çš„ç¶­åº¦
        smallest_index = min(valid_results.items(), 
                           key=lambda x: x[1]['index_size_bytes'])
        
        print(f"ğŸš€ æŸ¥è©¢é€Ÿåº¦æœ€å¿«: {fastest_query[0]} ç¶­åº¦ ({fastest_query[1]['average_query_time']*1000:.1f}ms)")
        print(f"ğŸ’¾ å­˜å„²æ•ˆç‡æœ€ä½³: {smallest_index[0]} ç¶­åº¦ ({smallest_index[1]['index_size_kb']:.1f}KB)")
        
        # å¹³è¡¡å»ºè­°
        if len(valid_results) >= 3:
            # é¸æ“‡ä¸­ç­‰ç¶­åº¦ä½œç‚ºå¹³è¡¡æ¨è–¦
            dimensions_sorted = sorted(valid_results.keys())
            balanced_dim = dimensions_sorted[len(dimensions_sorted)//2]
            print(f"âš–ï¸ å¹³è¡¡æ¨è–¦: {balanced_dim} ç¶­åº¦ï¼ˆæ€§èƒ½èˆ‡å­˜å„²çš„å¹³è¡¡ï¼‰")

if __name__ == "__main__":
    main()