import os
from typing import List, Optional, Dict, Any
import streamlit as st
from llama_index.core import VectorStoreIndex, Document

from rag_system import RAGSystem
from conversation_memory import ConversationMemory
from user_file_manager import UserFileManager
from gemini_ocr import GeminiOCRProcessor
from chroma_vector_store import ChromaVectorStoreManager

class EnhancedRAGSystem(RAGSystem):
    def __init__(self, use_chroma: bool = True):
        super().__init__()
        
        # åˆå§‹åŒ–æ–°åŠŸèƒ½æ¨¡çµ„
        self.memory = ConversationMemory()
        self.file_manager = UserFileManager()
        self.ocr_processor = GeminiOCRProcessor()
        self.chroma_manager = ChromaVectorStoreManager() if use_chroma else None
        self.use_chroma = use_chroma
        
    def query_with_context(self, question: str) -> str:
        """å¸¶ä¸Šä¸‹æ–‡è¨˜æ†¶çš„æŸ¥è©¢"""
        if not self.query_engine:
            return "ç³»çµ±å°šæœªåˆå§‹åŒ–ï¼Œè«‹å…ˆè¼‰å…¥æ–‡ä»¶ã€‚"
        
        try:
            # å»ºæ§‹åŒ…å«æ­·å²å°è©±çš„å®Œæ•´æŸ¥è©¢
            context_prompt = self.memory.get_context_prompt()
            
            if context_prompt and self.memory.is_enabled():
                enhanced_question = f"""
{context_prompt}

ç•¶å‰å•é¡Œ: {question}

è«‹åŸºæ–¼ä»¥ä¸Šå°è©±æ­·å²å’ŒçŸ¥è­˜åº«å…§å®¹å›žç­”ç•¶å‰å•é¡Œã€‚å¦‚æžœç•¶å‰å•é¡Œèˆ‡ä¹‹å‰çš„å°è©±ç›¸é—œï¼Œè«‹è€ƒæ…®ä¸Šä¸‹æ–‡èªžå¢ƒã€‚
"""
            else:
                enhanced_question = question
            
            with st.spinner("æ­£åœ¨æ€è€ƒæ‚¨çš„å•é¡Œ..."):
                response = self.query_engine.query(enhanced_question)
                response_str = str(response)
                
                # å°‡é€™è¼ªå°è©±åŠ å…¥è¨˜æ†¶
                self.memory.add_exchange(question, response_str)
                
                return response_str
                
        except Exception as e:
            st.error(f"æŸ¥è©¢æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return "æŠ±æ­‰ï¼Œè™•ç†æ‚¨çš„å•é¡Œæ™‚ç™¼ç”ŸéŒ¯èª¤ã€‚"
    
    def process_uploaded_files(self, uploaded_files) -> List[Document]:
        """è™•ç†ä¸Šå‚³çš„æª”æ¡ˆ"""
        if not uploaded_files:
            return []
        
        documents = []
        
        for uploaded_file in uploaded_files:
            try:
                # å„²å­˜æª”æ¡ˆ
                file_path = self.file_manager.save_uploaded_file(uploaded_file)
                if not file_path:
                    continue
                
                # æ ¹æ“šæª”æ¡ˆé¡žåž‹è™•ç†
                if self.file_manager.is_image_file(uploaded_file.name):
                    # åœ–ç‰‡OCRè™•ç†
                    doc = self._process_image_file(uploaded_file, file_path)
                elif self.file_manager.is_document_file(uploaded_file.name):
                    # æ–‡æª”è™•ç†
                    doc = self._process_document_file(uploaded_file, file_path)
                else:
                    st.warning(f"ä¸æ”¯æ´çš„æª”æ¡ˆé¡žåž‹: {uploaded_file.name}")
                    continue
                
                if doc:
                    documents.append(doc)
                    
            except Exception as e:
                st.error(f"è™•ç†æª”æ¡ˆ {uploaded_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
                continue
        
        return documents
    
    def _process_image_file(self, uploaded_file, file_path: str) -> Optional[Document]:
        """è™•ç†åœ–ç‰‡æª”æ¡ˆ"""
        if not self.ocr_processor.is_available():
            st.warning(f"OCRæœå‹™ä¸å¯ç”¨ï¼Œè·³éŽåœ–ç‰‡æª”æ¡ˆ: {uploaded_file.name}")
            return None
        
        try:
            # è®€å–åœ–ç‰‡æ•¸æ“š
            image_data = self.file_manager.get_file_content(os.path.basename(file_path))
            if not image_data:
                return None
            
            # å–å¾—æª”æ¡ˆæ“´å±•å
            file_ext = os.path.splitext(uploaded_file.name)[1].lower().lstrip('.')
            
            # OCRè™•ç†
            with st.spinner(f"æ­£åœ¨é€²è¡ŒOCRè™•ç†: {uploaded_file.name}"):
                ocr_result = self.ocr_processor.extract_text_from_image(image_data, file_ext)
            
            if ocr_result['success']:
                # å»ºç«‹æ–‡æª”
                document = Document(
                    text=ocr_result['text'],
                    metadata={
                        "source": uploaded_file.name,
                        "type": "image_ocr",
                        "original_format": file_ext,
                        "file_size": uploaded_file.size,
                        "ocr_confidence": ocr_result.get('confidence', 'unknown'),
                        "processed_at": st.session_state.get('current_time', 'unknown')
                    }
                )
                
                st.success(f"âœ… OCRè™•ç†æˆåŠŸ: {uploaded_file.name}")
                return document
            else:
                st.error(f"âŒ OCRè™•ç†å¤±æ•—: {uploaded_file.name} - {ocr_result['error']}")
                return None
                
        except Exception as e:
            st.error(f"è™•ç†åœ–ç‰‡æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None
    
    def _process_document_file(self, uploaded_file, file_path: str) -> Optional[Document]:
        """è™•ç†æ–‡æª”æª”æ¡ˆ"""
        try:
            file_ext = os.path.splitext(uploaded_file.name)[1].lower()
            
            if file_ext == '.pdf':
                # PDFè™•ç†
                docs = self.load_pdfs([file_path])
                if docs:
                    doc = docs[0]
                    # æ›´æ–°å…ƒæ•¸æ“š
                    doc.metadata.update({
                        "type": "user_document",
                        "file_size": uploaded_file.size,
                        "uploaded_at": st.session_state.get('current_time', 'unknown')
                    })
                    return doc
            
            elif file_ext == '.txt':
                # æ–‡å­—æª”è™•ç†
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
                
                document = Document(
                    text=text,
                    metadata={
                        "source": uploaded_file.name,
                        "type": "user_document",
                        "original_format": "txt",
                        "file_size": uploaded_file.size,
                        "uploaded_at": st.session_state.get('current_time', 'unknown')
                    }
                )
                return document
            
            elif file_ext in ['.md', '.markdown']:
                # Markdownæª”è™•ç†
                with open(file_path, 'r', encoding='utf-8') as f:
                    text = f.read()
                
                document = Document(
                    text=text,
                    metadata={
                        "source": uploaded_file.name,
                        "type": "user_document",
                        "original_format": "markdown",
                        "file_size": uploaded_file.size,
                        "uploaded_at": st.session_state.get('current_time', 'unknown')
                    }
                )
                return document
            
            else:
                st.warning(f"æš«ä¸æ”¯æ´çš„æ–‡æª”æ ¼å¼: {file_ext}")
                return None
                
        except Exception as e:
            st.error(f"è™•ç†æ–‡æª”æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return None
    
    def create_index(self, documents: List[Document]) -> VectorStoreIndex:
        """å»ºç«‹æ–°çš„å‘é‡ç´¢å¼• (æ”¯æ´ ChromaDB)"""
        with st.spinner("æ­£åœ¨å»ºç«‹å‘é‡ç´¢å¼•..."):
            chroma_success = False
            index = None
            
            try:
                if self.use_chroma and self.chroma_manager:
                    # å˜—è©¦ä½¿ç”¨ ChromaDB
                    st.info("å˜—è©¦ä½¿ç”¨ ChromaDB å‘é‡å„²å­˜...")
                    try:
                        # åˆå§‹åŒ– ChromaDB å®¢æˆ¶ç«¯
                        if self.chroma_manager.initialize_client():
                            # ç²å– ChromaDB å„²å­˜ä¸Šä¸‹æ–‡
                            storage_context = self.chroma_manager.get_storage_context()
                            if storage_context:
                                # å‰µå»ºç´¢å¼•
                                index = VectorStoreIndex.from_documents(
                                    documents, 
                                    storage_context=storage_context
                                )
                                st.success("âœ… æˆåŠŸä½¿ç”¨ ChromaDB å»ºç«‹ç´¢å¼•")
                                chroma_success = True
                            else:
                                st.warning("ç„¡æ³•ç²å– ChromaDB å„²å­˜ä¸Šä¸‹æ–‡ï¼Œå›žé€€åˆ° SimpleVectorStore")
                        else:
                            st.warning("ChromaDB å®¢æˆ¶ç«¯åˆå§‹åŒ–å¤±æ•—ï¼Œå›žé€€åˆ° SimpleVectorStore")
                    except Exception as e:
                        st.warning(f"ChromaDB ç´¢å¼•å‰µå»ºå¤±æ•—: {str(e)}")
                        st.info("æ­£åœ¨å›žé€€åˆ° SimpleVectorStore...")
                
                # å¦‚æžœ ChromaDB å¤±æ•—æˆ–æœªå•Ÿç”¨ï¼Œä½¿ç”¨ SimpleVectorStore
                if not chroma_success:
                    try:
                        st.info("ä½¿ç”¨ SimpleVectorStore å»ºç«‹ç´¢å¼•...")
                        index = VectorStoreIndex.from_documents(documents)
                        st.success("âœ… æˆåŠŸä½¿ç”¨ SimpleVectorStore å»ºç«‹ç´¢å¼•")
                        # åœç”¨ ChromaDB é¿å…å¾ŒçºŒè¡çª
                        self.use_chroma = False
                    except Exception as e:
                        st.error(f"SimpleVectorStore ç´¢å¼•å‰µå»ºä¹Ÿå¤±æ•—: {str(e)}")
                        return None
                
                if index:
                    # æŒä¹…åŒ–ç´¢å¼•
                    from config import INDEX_DIR
                    index.storage_context.persist(persist_dir=INDEX_DIR)
                    st.success("âœ… ç´¢å¼•å·²æŒä¹…åŒ–ä¿å­˜")
                    
                    self.index = index
                    return index
                else:
                    st.error("ç´¢å¼•å‰µå»ºå¤±æ•—")
                    return None
                    
            except Exception as e:
                st.error(f"å»ºç«‹ç´¢å¼•æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {str(e)}")
                return None
    
    def load_existing_index(self) -> bool:
        """è¼‰å…¥ç¾æœ‰çš„å‘é‡ç´¢å¼• (æ”¯æ´ ChromaDB æ™ºèƒ½é·ç§»)"""
        try:
            from config import INDEX_DIR
            if os.path.exists(INDEX_DIR) and os.listdir(INDEX_DIR):
                with st.spinner("æ­£åœ¨è¼‰å…¥ç¾æœ‰ç´¢å¼•..."):
                    
                    if self.use_chroma and self.chroma_manager:
                        # æª¢æŸ¥ ChromaDB æ˜¯å¦æœ‰è³‡æ–™
                        if self.chroma_manager.has_data():
                            # ChromaDB æœ‰è³‡æ–™ï¼Œç›´æŽ¥è¼‰å…¥
                            st.info("ç™¼ç¾ ChromaDB è³‡æ–™ï¼Œæ­£åœ¨è¼‰å…¥...")
                            return self._load_chromadb_index()
                        else:
                            # ChromaDB æ˜¯ç©ºçš„ï¼Œå˜—è©¦å¾ž SimpleVectorStore é·ç§»
                            st.info("ChromaDB æ˜¯ç©ºçš„ï¼Œå˜—è©¦å¾ž SimpleVectorStore é·ç§»...")
                            return self._load_and_migrate_from_simple()
                    else:
                        # ç›´æŽ¥è¼‰å…¥ SimpleVectorStore
                        return self._load_simple_vector_store()
            else:
                st.info("æ²’æœ‰æ‰¾åˆ°ç¾æœ‰ç´¢å¼•æª”æ¡ˆ")
                return False
        except Exception as e:
            st.error(f"è¼‰å…¥ç´¢å¼•æ™‚ç™¼ç”Ÿæœªé æœŸéŒ¯èª¤: {str(e)}")
            return False
    
    def _load_chromadb_index(self) -> bool:
        """è¼‰å…¥ ChromaDB ç´¢å¼•"""
        try:
            storage_context = self.chroma_manager.get_storage_context()
            if storage_context:
                from llama_index.core import load_index_from_storage
                self.index = load_index_from_storage(storage_context)
                self.setup_query_engine()
                st.success("âœ… æˆåŠŸè¼‰å…¥ ChromaDB ç´¢å¼•")
                return True
            else:
                st.warning("ç„¡æ³•ç²å– ChromaDB å„²å­˜ä¸Šä¸‹æ–‡")
                return False
        except Exception as e:
            st.warning(f"è¼‰å…¥ ChromaDB ç´¢å¼•å¤±æ•—: {str(e)}")
            return False
    
    def _load_and_migrate_from_simple(self) -> bool:
        """å¾ž SimpleVectorStore è¼‰å…¥ä¸¦é·ç§»åˆ° ChromaDB"""
        try:
            # å…ˆå˜—è©¦è¼‰å…¥ SimpleVectorStore
            if self._load_simple_vector_store(migrate_to_chroma=False):
                st.info("SimpleVectorStore è¼‰å…¥æˆåŠŸï¼Œé–‹å§‹é·ç§»åˆ° ChromaDB...")
                
                # å–å¾—ç•¶å‰çš„æ–‡æª”
                documents = []
                if hasattr(self.index, 'docstore') and self.index.docstore.docs:
                    for node_id, node in self.index.docstore.docs.items():
                        documents.append(node)
                
                if documents:
                    # ä½¿ç”¨ ChromaDB é‡å»ºç´¢å¼•
                    storage_context = self.chroma_manager.get_storage_context()
                    if storage_context:
                        new_index = VectorStoreIndex.from_documents(
                            documents, 
                            storage_context=storage_context
                        )
                        
                        # æŒä¹…åŒ–åˆ° INDEX_DIR
                        from config import INDEX_DIR
                        new_index.storage_context.persist(persist_dir=INDEX_DIR)
                        
                        # æ›´æ–°ç´¢å¼•å’ŒæŸ¥è©¢å¼•æ“Ž
                        self.index = new_index
                        self.setup_query_engine()
                        
                        st.success(f"âœ… æˆåŠŸé·ç§» {len(documents)} å€‹æ–‡æª”åˆ° ChromaDB")
                        return True
                    else:
                        st.error("ç„¡æ³•ç²å– ChromaDB å„²å­˜ä¸Šä¸‹æ–‡é€²è¡Œé·ç§»")
                        # ä¿æŒ SimpleVectorStore
                        self.use_chroma = False
                        return True
                else:
                    st.warning("æ²’æœ‰æ‰¾åˆ°å¯é·ç§»çš„æ–‡æª”")
                    return True
            else:
                st.warning("ç„¡æ³•è¼‰å…¥ SimpleVectorStore é€²è¡Œé·ç§»")
                return False
                
        except Exception as e:
            st.error(f"é·ç§»éŽç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            # å˜—è©¦å›žé€€åˆ° SimpleVectorStore
            return self._load_simple_vector_store(migrate_to_chroma=False)
    
    def _load_simple_vector_store(self, migrate_to_chroma: bool = True) -> bool:
        """è¼‰å…¥ SimpleVectorStore"""
        try:
            st.info("è¼‰å…¥ SimpleVectorStore ç´¢å¼•...")
            from llama_index.core import load_index_from_storage
            from llama_index.core.storage.storage_context import StorageContext
            from config import INDEX_DIR
            
            storage_context = StorageContext.from_defaults(persist_dir=INDEX_DIR)
            self.index = load_index_from_storage(storage_context)
            self.setup_query_engine()
            
            if migrate_to_chroma:
                st.success("âœ… æˆåŠŸè¼‰å…¥ç¾æœ‰ç´¢å¼• (SimpleVectorStore)")
                # æš«æ™‚åœç”¨ ChromaDB ä»¥é¿å…å¾ŒçºŒè¡çª
                self.use_chroma = False
            
            return True
            
        except Exception as e:
            st.error(f"è¼‰å…¥ SimpleVectorStore å¤±æ•—: {str(e)}")
            return False

    def rebuild_index_with_user_files(self) -> bool:
        """é‡å»ºç´¢å¼•ï¼ŒåŒ…å«ç”¨æˆ¶ä¸Šå‚³çš„æª”æ¡ˆ"""
        try:
            all_documents = []
            
            # è¼‰å…¥å®˜æ–¹èŒ¶è‘‰è³‡æ–™
            from enhanced_pdf_downloader import EnhancedPDFDownloader
            downloader = EnhancedPDFDownloader()
            official_pdfs = downloader.get_existing_pdfs()
            
            if official_pdfs:
                st.info("è¼‰å…¥å®˜æ–¹èŒ¶è‘‰è³‡æ–™...")
                official_docs = self.load_pdfs(official_pdfs)
                # æ¨™è¨˜ç‚ºå®˜æ–¹è³‡æ–™
                for doc in official_docs:
                    doc.metadata["data_source"] = "official"
                all_documents.extend(official_docs)
            
            # è¼‰å…¥ç”¨æˆ¶ä¸Šå‚³çš„æª”æ¡ˆ
            user_files = self.file_manager.get_uploaded_files()
            if user_files:
                st.info("è¼‰å…¥ç”¨æˆ¶ä¸Šå‚³çš„æª”æ¡ˆ...")
                
                # æ¨¡æ“¬uploaded_fileå°è±¡ä¾†é‡ç”¨ç¾æœ‰é‚è¼¯
                class MockUploadedFile:
                    def __init__(self, file_info):
                        self.name = file_info['name']
                        self.size = file_info['size']
                
                mock_files = [MockUploadedFile(f) for f in user_files]
                user_docs = []
                
                for i, file_info in enumerate(user_files):
                    if file_info['type'] == 'image':
                        doc = self._process_image_file(mock_files[i], file_info['path'])
                    else:
                        doc = self._process_document_file(mock_files[i], file_info['path'])
                    
                    if doc:
                        doc.metadata["data_source"] = "user_upload"
                        user_docs.append(doc)
                
                all_documents.extend(user_docs)
            
            if all_documents:
                # é‡å»ºç´¢å¼•
                st.info("é‡å»ºå‘é‡ç´¢å¼•...")
                index = self.create_index(all_documents)
                
                if index:
                    self.setup_query_engine()
                    return True
            
            return False
            
        except Exception as e:
            st.error(f"é‡å»ºç´¢å¼•æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
            return False
    
    def get_document_statistics(self) -> dict:
        """å–å¾—æ–‡ä»¶çµ±è¨ˆè³‡è¨Š (æ”¯æ´ ChromaDB)"""
        if not self.index:
            return {}
        
        stats = {
            "total_documents": 0,
            "total_nodes": 0,
            "document_details": [],
            "total_pages": 0
        }
        
        try:
            if self.use_chroma and self.chroma_manager and self.chroma_manager.has_data():
                # ä½¿ç”¨ ChromaDB çµ±è¨ˆ
                chroma_stats = self.chroma_manager.get_collection_stats()
                if chroma_stats:
                    stats["total_documents"] = chroma_stats.get("total_documents", 0)
                    stats["total_nodes"] = chroma_stats.get("total_documents", 0)  # ChromaDB ä¸­æ¯å€‹æ–‡æª”å°æ‡‰ä¸€å€‹ç¯€é»ž
                    
                    # å¾ž ChromaDB å…ƒæ•¸æ“šçµ±è¨ˆæ–‡æª”è©³æƒ…
                    source_types = chroma_stats.get("source_types", {})
                    for doc_type, count in source_types.items():
                        stats["document_details"].append({
                            "name": f"{doc_type} æ–‡æª”",
                            "pages": count,  # æš«æ™‚ç”¨æ–‡æª”æ•¸é‡ä»£æ›¿é æ•¸
                            "node_count": count
                        })
                    
                    st.info(f"ðŸ“Š å¾ž ChromaDB ç²å–çµ±è¨ˆ: {stats['total_documents']} å€‹æ–‡æª”")
                else:
                    st.warning("ç„¡æ³•å¾ž ChromaDB ç²å–çµ±è¨ˆè³‡è¨Š")
            else:
                # ä½¿ç”¨ SimpleVectorStore çµ±è¨ˆï¼ˆåŽŸæœ‰é‚è¼¯ï¼‰
                doc_info = {}
                if hasattr(self.index, 'docstore') and self.index.docstore.docs:
                    for node in self.index.docstore.docs.values():
                        source = node.metadata.get("source", "æœªçŸ¥")
                        pages = node.metadata.get("pages", 1)
                        
                        if source not in doc_info:
                            doc_info[source] = {
                                "name": source,
                                "pages": pages,
                                "node_count": 0
                            }
                        doc_info[source]["node_count"] += 1
                    
                    stats["total_documents"] = len(doc_info)
                    stats["total_nodes"] = len(self.index.docstore.docs)
                    stats["document_details"] = list(doc_info.values())
                    stats["total_pages"] = sum(doc["pages"] for doc in doc_info.values())
                    
                    st.info(f"ðŸ“Š å¾ž SimpleVectorStore ç²å–çµ±è¨ˆ: {stats['total_documents']} å€‹æ–‡æª”")
                else:
                    st.warning("ç´¢å¼•ä¸­æ²’æœ‰æ‰¾åˆ°æ–‡æª”è³‡æ–™")
            
        except Exception as e:
            st.error(f"ç²å–æ–‡æª”çµ±è¨ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        
        return stats
    
    def get_enhanced_statistics(self) -> Dict[str, Any]:
        """å–å¾—å¢žå¼·çš„çµ±è¨ˆè³‡è¨Š"""
        base_stats = self.get_document_statistics()
        
        # ç”¨æˆ¶æª”æ¡ˆçµ±è¨ˆ
        file_stats = self.file_manager.get_file_stats()
        
        # å°è©±è¨˜æ†¶çµ±è¨ˆ
        memory_stats = self.memory.get_memory_stats()
        
        # OCRå¯ç”¨æ€§
        ocr_available = self.ocr_processor.is_available()
        
        return {
            "base_statistics": base_stats,
            "user_files": file_stats,
            "conversation_memory": memory_stats,
            "ocr_available": ocr_available,
            "total_data_sources": {
                "official_documents": base_stats.get("total_documents", 0) - file_stats.get("total_files", 0),
                "user_documents": file_stats.get("document_count", 0),
                "user_images": file_stats.get("image_count", 0)
            }
        }
    
    def clear_conversation_memory(self):
        """æ¸…é™¤å°è©±è¨˜æ†¶"""
        self.memory.clear_memory()
    
    def get_memory_for_display(self):
        """å–å¾—ç”¨æ–¼é¡¯ç¤ºçš„è¨˜æ†¶å…§å®¹"""
        return self.memory.get_memory_for_display()
    
    def delete_user_file(self, filename: str) -> bool:
        """åˆªé™¤ç”¨æˆ¶æª”æ¡ˆ"""
        return self.file_manager.delete_file(filename)
