#!/usr/bin/env python3
"""
æœ€çµ‚ç¶­åº¦æ¨è–¦å ±å‘Š
åŸºæ–¼å®Œæ•´æ¸¬è©¦æ•¸æ“šçš„è©³ç´°åˆ†æ
"""

import json

def load_test_results():
    """è¼‰å…¥æ¸¬è©¦çµæœ"""
    with open('data/dimension_benchmark_results.json', 'r', encoding='utf-8') as f:
        return json.load(f)

def analyze_complete_results():
    """åˆ†æå®Œæ•´æ¸¬è©¦çµæœ"""
    
    print("ğŸ¯ Elasticsearch å‘é‡ç¶­åº¦æœ€çµ‚æ¨è–¦å ±å‘Š")
    print("=" * 60)
    
    # è¼‰å…¥æˆ‘å€‘çš„æ¸¬è©¦æ•¸æ“š
    results = load_test_results()
    test_data = results['dimension_results']
    
    # Jina v3 è«–æ–‡æ•¸æ“š
    jina_data = {
        128: {'retrieval_retention': 97.3, 'sts_retention': 99.8},
        256: {'retrieval_retention': 99.0, 'sts_retention': 99.97},
        384: {'retrieval_retention': 99.4, 'sts_retention': 99.98},
        512: {'retrieval_retention': 99.7, 'sts_retention': 100.0},
        768: {'retrieval_retention': 99.8, 'sts_retention': 100.0},
        1024: {'retrieval_retention': 100.0, 'sts_retention': 100.0}
    }
    
    print(f"\nğŸ“Š å®Œæ•´æ¸¬è©¦çµæœå°æ¯”:")
    print("ç¶­åº¦\tæŸ¥è©¢æ™‚é–“\tåµŒå…¥æ™‚é–“\tç´¢å¼•å¤§å°\tæª¢ç´¢æ€§èƒ½\tå­˜å„²æ•ˆç‡")
    print("-" * 75)
    
    performance_analysis = {}
    
    for dim_str, data in test_data.items():
        if 'error' in data:
            continue
            
        dim = int(dim_str)
        query_time = data['average_query_time'] * 1000  # è½‰ç‚º ms
        embed_time = data['embedding_time_per_query']   # å·²æ˜¯ s
        index_size = data['index_size_kb']
        
        # è¨ˆç®—å­˜å„²æ•ˆç‡ (ç›¸å°æ–¼1024ç¶­åº¦)
        storage_efficiency = (1 - index_size / test_data['1024']['index_size_kb']) * 100
        
        # ç²å–æº–ç¢ºæ€§æ•¸æ“š
        accuracy = jina_data.get(dim, {}).get('retrieval_retention', 0)
        
        print(f"{dim}\t{query_time:.1f}ms\t\t{embed_time:.1f}s\t\t{index_size:.1f}KB\t\t{accuracy:.1f}%\t\t{storage_efficiency:.1f}%")
        
        # è¨ˆç®—ç¶œåˆåˆ†æ•¸
        # æ¬Šé‡ï¼šæº–ç¢ºæ€§(40%) + æŸ¥è©¢é€Ÿåº¦(30%) + å­˜å„²æ•ˆç‡(20%) + åµŒå…¥é€Ÿåº¦(10%)
        speed_score = max(0, 100 - (query_time - 3) * 10)  # ä»¥3msç‚ºåŸºæº–
        embed_speed_score = max(0, 100 - (embed_time - 3) * 5)  # ä»¥3sç‚ºåŸºæº–
        
        total_score = (accuracy * 0.4) + (speed_score * 0.3) + (storage_efficiency * 0.2) + (embed_speed_score * 0.1)
        
        performance_analysis[dim] = {
            'query_time': query_time,
            'embed_time': embed_time,
            'index_size': index_size,
            'accuracy': accuracy,
            'storage_efficiency': storage_efficiency,
            'total_score': total_score
        }
    
    # æ’åºåˆ†æ
    sorted_performance = sorted(performance_analysis.items(), key=lambda x: x[1]['total_score'], reverse=True)
    
    print(f"\nğŸ† ç¶œåˆæ’å:")
    print("æ’å\tç¶­åº¦\tç¶œåˆåˆ†æ•¸\tä¸»è¦å„ªå‹¢")
    print("-" * 50)
    
    advantages = {
        128: "å­˜å„²æœ€å°, æŸ¥è©¢ç•¥æ…¢",
        256: "å­˜å„²æ•ˆç‡é«˜, æ€§èƒ½å‡è¡¡", 
        384: "ç•¶å‰é…ç½®, å¹³è¡¡æ¨è–¦",
        512: "é«˜æº–ç¢ºæ€§, é©ä¸­å­˜å„²",
        768: "æ¥è¿‘å®Œç¾æº–ç¢ºæ€§",
        1024: "æœ€é«˜æº–ç¢ºæ€§, å­˜å„²æœ€å¤§"
    }
    
    for i, (dim, perf) in enumerate(sorted_performance, 1):
        advantage = advantages.get(dim, "")
        print(f"{i}\t{dim}\t{perf['total_score']:.1f}\t\t{advantage}")
    
    # è©³ç´°å»ºè­°
    print(f"\nğŸ’¡ è©³ç´°ä½¿ç”¨å ´æ™¯å»ºè­°:")
    print("-" * 40)
    
    # æ‰¾å‡ºæœ€ä½³æ€§èƒ½çš„ç¶­åº¦
    best_overall = sorted_performance[0][0]
    best_query_speed = min(performance_analysis.items(), key=lambda x: x[1]['query_time'])[0]
    best_storage = max(performance_analysis.items(), key=lambda x: x[1]['storage_efficiency'])[0]
    best_accuracy = max(performance_analysis.items(), key=lambda x: x[1]['accuracy'])[0]
    
    print(f"\n1. ğŸš€ æœ€ä½³æ•´é«”æ€§èƒ½: {best_overall} ç¶­åº¦")
    print(f"   - ç¶œåˆåˆ†æ•¸: {performance_analysis[best_overall]['total_score']:.1f}")
    print(f"   - æŸ¥è©¢æ™‚é–“: {performance_analysis[best_overall]['query_time']:.1f}ms")
    print(f"   - æº–ç¢ºæ€§: {performance_analysis[best_overall]['accuracy']:.1f}%")
    
    print(f"\n2. âš¡ æœ€å¿«æŸ¥è©¢é€Ÿåº¦: {best_query_speed} ç¶­åº¦")
    print(f"   - æŸ¥è©¢æ™‚é–“: {performance_analysis[best_query_speed]['query_time']:.1f}ms")
    
    print(f"\n3. ğŸ’¾ æœ€ä½³å­˜å„²æ•ˆç‡: {best_storage} ç¶­åº¦")
    print(f"   - å­˜å„²ç¯€çœ: {performance_analysis[best_storage]['storage_efficiency']:.1f}%")
    print(f"   - ç´¢å¼•å¤§å°: {performance_analysis[best_storage]['index_size']:.1f}KB")
    
    print(f"\n4. ğŸ¯ æœ€é«˜æº–ç¢ºæ€§: {best_accuracy} ç¶­åº¦")
    print(f"   - æª¢ç´¢æ€§èƒ½: {performance_analysis[best_accuracy]['accuracy']:.1f}%")
    
    print(f"\nğŸ“‹ å¯¦éš›éƒ¨ç½²å»ºè­°:")
    print("-" * 25)
    
    print(f"\nğŸ¯ æ¨è–¦é…ç½®å„ªå…ˆé †åº:")
    
    # åŸºæ–¼ä¸åŒéœ€æ±‚çš„æ¨è–¦
    recommendations = [
        (256, "å­˜å„²æˆæœ¬æ•æ„Ÿç’°å¢ƒ", "75%å­˜å„²ç¯€çœï¼Œåƒ…1%æ€§èƒ½æå¤±"),
        (384, "å¹³è¡¡ç”Ÿç”¢ç’°å¢ƒï¼ˆç•¶å‰ï¼‰", "62.5%å­˜å„²ç¯€çœï¼Œé«˜æ€§èƒ½ä¿ç•™"),
        (512, "é«˜æº–ç¢ºæ€§è¦æ±‚", "50%å­˜å„²ç¯€çœï¼Œæ¥è¿‘å®Œç¾æ€§èƒ½"),
        (1024, "æ¥µé«˜æº–ç¢ºæ€§è¦æ±‚", "å®Œç¾æ€§èƒ½ï¼Œå­˜å„²æˆæœ¬è¼ƒé«˜")
    ]
    
    for i, (dim, scenario, desc) in enumerate(recommendations, 1):
        current_marker = " (ç•¶å‰é…ç½®)" if dim == 384 else ""
        print(f"\n{i}. {dim} ç¶­åº¦{current_marker}")
        print(f"   é©ç”¨: {scenario}")
        print(f"   ç‰¹é»: {desc}")
        if dim in performance_analysis:
            perf = performance_analysis[dim]
            print(f"   æ€§èƒ½: æŸ¥è©¢{perf['query_time']:.1f}ms | æº–ç¢ºæ€§{perf['accuracy']:.1f}% | å­˜å„²{perf['index_size']:.1f}KB")
    
    print(f"\nğŸ”§ é…ç½®è®Šæ›´æŒ‡å—:")
    print(f"   1. ä¿®æ”¹ .env æ–‡ä»¶ä¸­çš„ ELASTICSEARCH_VECTOR_DIMENSION")
    print(f"   2. é‡å•Ÿ Elasticsearch æœå‹™")
    print(f"   3. é‡æ–°å‰µå»ºç´¢å¼•ï¼ˆæœƒè§¸ç™¼è‡ªå‹• mapping å‰µå»ºï¼‰")
    print(f"   4. é‡æ–°ç´¢å¼•æ‰€æœ‰æ–‡æª”")
    
    print(f"\nâš ï¸ é‡è¦æé†’:")
    print(f"   - ä¸åŒç¶­åº¦çš„åµŒå…¥å‘é‡ä¸å…¼å®¹")
    print(f"   - è®Šæ›´ç¶­åº¦éœ€è¦å®Œå…¨é‡å»ºç´¢å¼•")
    print(f"   - å»ºè­°åœ¨ç¶­è­·çª—å£æœŸé–“é€²è¡Œè®Šæ›´")
    print(f"   - å¯ä»¥å…ˆåœ¨æ¸¬è©¦ç’°å¢ƒé©—è­‰æ•ˆæœ")
    
    # æœ€çµ‚æ¨è–¦
    print(f"\nğŸ¯ æœ€çµ‚æ¨è–¦: {sorted_performance[0][0]} ç¶­åº¦")
    final_perf = performance_analysis[sorted_performance[0][0]]
    print(f"   ç†ç”±: ç¶œåˆè€ƒæ…®æº–ç¢ºæ€§ã€é€Ÿåº¦å’Œå­˜å„²çš„æœ€ä½³å¹³è¡¡")
    print(f"   é æœŸæ•ˆæœ:")
    print(f"     â€¢ æŸ¥è©¢å»¶é²: {final_perf['query_time']:.1f}ms")
    print(f"     â€¢ æª¢ç´¢æº–ç¢ºæ€§: {final_perf['accuracy']:.1f}%")
    print(f"     â€¢ å­˜å„²ç¯€çœ: {final_perf['storage_efficiency']:.1f}%")
    
    # å¦‚æœç•¶å‰ä¸æ˜¯æœ€ä½³é…ç½®ï¼Œæä¾›å‡ç´šå»ºè­°
    if 384 != sorted_performance[0][0]:
        print(f"\nğŸ“ˆ å‡ç´šå»ºè­°:")
        print(f"   ç•¶å‰ 384 ç¶­åº¦ â†’ æ¨è–¦ {sorted_performance[0][0]} ç¶­åº¦")
        current_perf = performance_analysis[384]
        best_perf = performance_analysis[sorted_performance[0][0]]
        
        query_improvement = current_perf['query_time'] - best_perf['query_time']
        storage_improvement = best_perf['storage_efficiency'] - current_perf['storage_efficiency']
        
        if query_improvement > 0:
            print(f"   æŸ¥è©¢é€Ÿåº¦æå‡: {query_improvement:.1f}ms")
        if storage_improvement > 0:
            print(f"   å­˜å„²æ•ˆç‡æå‡: {storage_improvement:.1f}%")

if __name__ == "__main__":
    analyze_complete_results()