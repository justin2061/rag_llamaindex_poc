"""
Multi-Embedding Manager
å¤šEmbeddingæ¨¡å‹ç®¡ç†å™¨ï¼Œæ”¯æ´ä¸åŒå ´æ™¯çš„æœ€ä½³embeddingé¸æ“‡
"""

import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from abc import ABC, abstractmethod
import numpy as np

# é…ç½®logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class EmbeddingModelConfig:
    """Embeddingæ¨¡å‹é…ç½®"""
    model_name: str
    model_type: str  # general, domain, sentence, keyword
    dimension: int
    strengths: List[str]  # å„ªå‹¢å ´æ™¯
    use_cases: List[str]  # é©ç”¨æƒ…æ³
    weight: float = 1.0

class BaseEmbeddingModel(ABC):
    """æŠ½è±¡Embeddingæ¨¡å‹åŸºé¡"""
    
    def __init__(self, config: EmbeddingModelConfig):
        self.config = config
        self.model = None
    
    @abstractmethod
    def load_model(self):
        """è¼‰å…¥æ¨¡å‹"""
        pass
    
    @abstractmethod
    def embed_text(self, text: str) -> List[float]:
        """æ–‡æœ¬embedding"""
        pass
    
    @abstractmethod
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        """æ‰¹é‡embedding"""
        pass

class JinaEmbeddingModel(BaseEmbeddingModel):
    """Jina Embeddingæ¨¡å‹"""
    
    def load_model(self):
        try:
            from llama_index.core import Settings
            self.model = Settings.embed_model
            logger.info(f"âœ… è¼‰å…¥Jinaæ¨¡å‹: {self.config.model_name}")
        except Exception as e:
            logger.error(f"âŒ Jinaæ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def embed_text(self, text: str) -> List[float]:
        if not self.model:
            self.load_model()
        return self.model.get_text_embedding(text)
    
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        if not self.model:
            self.load_model()
        return [self.embed_text(text) for text in texts]

class HuggingFaceEmbeddingModel(BaseEmbeddingModel):
    """HuggingFace Embeddingæ¨¡å‹"""
    
    def load_model(self):
        try:
            from sentence_transformers import SentenceTransformer
            self.model = SentenceTransformer(self.config.model_name)
            logger.info(f"âœ… è¼‰å…¥HuggingFaceæ¨¡å‹: {self.config.model_name}")
        except ImportError:
            logger.warning("âš ï¸ sentence-transformers æœªå®‰è£ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ")
            self.load_model = self._load_backup_model
        except Exception as e:
            logger.error(f"âŒ HuggingFaceæ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
    
    def _load_backup_model(self):
        """å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨Jinaæ¨¡å‹"""
        from llama_index.core import Settings
        self.model = Settings.embed_model
        logger.info("ğŸ”„ ä½¿ç”¨Jinaæ¨¡å‹ä½œç‚ºå‚™ç”¨")
    
    def embed_text(self, text: str) -> List[float]:
        if not self.model:
            self.load_model()
        
        try:
            if hasattr(self.model, 'encode'):
                # SentenceTransformeræ¨¡å‹
                embedding = self.model.encode([text])[0]
                return embedding.tolist() if hasattr(embedding, 'tolist') else list(embedding)
            else:
                # å‚™ç”¨Jinaæ¨¡å‹
                return self.model.get_text_embedding(text)
        except Exception as e:
            logger.error(f"âŒ embeddingç”Ÿæˆå¤±æ•—: {e}")
            return [0.0] * self.config.dimension
    
    def embed_batch(self, texts: List[str]) -> List[List[float]]:
        if not self.model:
            self.load_model()
        
        try:
            if hasattr(self.model, 'encode'):
                embeddings = self.model.encode(texts)
                return [emb.tolist() if hasattr(emb, 'tolist') else list(emb) for emb in embeddings]
            else:
                return [self.embed_text(text) for text in texts]
        except Exception as e:
            logger.error(f"âŒ æ‰¹é‡embeddingç”Ÿæˆå¤±æ•—: {e}")
            return [[0.0] * self.config.dimension for _ in texts]

class MultiEmbeddingManager:
    """å¤šEmbeddingæ¨¡å‹ç®¡ç†å™¨"""
    
    def __init__(self, enable_multi_embedding: bool = True):
        self.enable_multi_embedding = enable_multi_embedding
        self.models: Dict[str, BaseEmbeddingModel] = {}
        self.model_configs = self._get_default_configs()
        
        # åˆå§‹åŒ–æ¨¡å‹
        self._initialize_models()
        
        logger.info(f"ğŸ¯ MultiEmbeddingManager åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - å•Ÿç”¨å¤šæ¨¡å‹: {enable_multi_embedding}")
        logger.info(f"   - å¯ç”¨æ¨¡å‹: {list(self.models.keys())}")
    
    def _get_default_configs(self) -> Dict[str, EmbeddingModelConfig]:
        """ç²å–é è¨­æ¨¡å‹é…ç½®"""
        return {
            "general": EmbeddingModelConfig(
                model_name="jina-embeddings-v3",
                model_type="general",
                dimension=1024,
                strengths=["é€šç”¨æ–‡æœ¬", "å¤šèªè¨€", "å¹³è¡¡æ€§èƒ½"],
                use_cases=["æ—¥å¸¸æŸ¥è©¢", "é€šç”¨æª¢ç´¢", "åŸºç¤ç›¸ä¼¼åº¦"],
                weight=1.0
            ),
            "domain": EmbeddingModelConfig(
                model_name="BAAI/bge-base-zh-v1.5",
                model_type="domain",
                dimension=768,
                strengths=["ä¸­æ–‡å„ªåŒ–", "é ˜åŸŸç‰¹å®š", "èªç¾©ç†è§£"],
                use_cases=["å°ˆæ¥­æ–‡æª”", "æŠ€è¡“å…§å®¹", "ä¸­æ–‡æŸ¥è©¢"],
                weight=0.8
            ),
            "sentence": EmbeddingModelConfig(
                model_name="sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
                model_type="sentence",
                dimension=384,
                strengths=["å¥å­ç´šç›¸ä¼¼åº¦", "èªç¾©åŒ¹é…", "å¿«é€Ÿæ¨ç†"],
                use_cases=["å¥å­æ¯”å°", "å•ç­”åŒ¹é…", "å¿«é€Ÿæª¢ç´¢"],
                weight=0.7
            ),
            "keyword": EmbeddingModelConfig(
                model_name="keyword-embedding-custom",
                model_type="keyword",
                dimension=256,
                strengths=["é—œéµè©æŠ½å–", "ä¸»é¡Œè­˜åˆ¥", "ç¨€ç–è¡¨ç¤º"],
                use_cases=["é—œéµè©æœç´¢", "ä¸»é¡Œåˆ†æ", "æ¨™ç±¤åŒ¹é…"],
                weight=0.5
            )
        }
    
    def _initialize_models(self):
        """åˆå§‹åŒ–æ‰€æœ‰æ¨¡å‹"""
        for model_name, config in self.model_configs.items():
            try:
                if model_name == "general":
                    # ä½¿ç”¨Jinaä½œç‚ºé€šç”¨æ¨¡å‹
                    model = JinaEmbeddingModel(config)
                elif model_name in ["domain", "sentence"]:
                    # ä½¿ç”¨HuggingFaceæ¨¡å‹
                    model = HuggingFaceEmbeddingModel(config)
                else:
                    # é—œéµè©æ¨¡å‹ä½¿ç”¨ç°¡åŒ–ç‰ˆå¯¦ç¾
                    model = self._create_keyword_model(config)
                
                model.load_model()
                self.models[model_name] = model
                
            except Exception as e:
                logger.warning(f"âš ï¸ æ¨¡å‹ {model_name} åˆå§‹åŒ–å¤±æ•—: {e}")
                # ä½¿ç”¨é€šç”¨æ¨¡å‹ä½œç‚ºå‚™ç”¨
                if model_name != "general":
                    self.models[model_name] = self.models.get("general")
    
    def _create_keyword_model(self, config: EmbeddingModelConfig) -> BaseEmbeddingModel:
        """å‰µå»ºé—œéµè©æ¨¡å‹ï¼ˆç°¡åŒ–ç‰ˆå¯¦ç¾ï¼‰"""
        class KeywordEmbeddingModel(BaseEmbeddingModel):
            def load_model(self):
                # é—œéµè©æ¨¡å‹ä¸éœ€è¦è¼‰å…¥ï¼Œç›´æ¥æ¨™è¨˜ç‚ºå·²è¼‰å…¥
                self.model = "keyword_model_placeholder"
            
            def embed_text(self, text: str) -> List[float]:
                # ç°¡åŒ–ç‰ˆé—œéµè©embeddingï¼šåŸºæ–¼TF-IDFçš„å‘é‡è¡¨ç¤º
                return self._simple_keyword_embedding(text)
            
            def embed_batch(self, texts: List[str]) -> List[List[float]]:
                return [self.embed_text(text) for text in texts]
            
            def _simple_keyword_embedding(self, text: str) -> List[float]:
                """ç°¡åŒ–ç‰ˆé—œéµè©embedding"""
                # é€™è£¡å¯¦ç¾ä¸€å€‹åŸºç¤çš„TF-IDFé¢¨æ ¼çš„å‘é‡
                words = text.lower().split()
                
                # é å®šç¾©çš„é—œéµè©è©å…¸ï¼ˆå¯¦éš›æ‡‰ç”¨ä¸­æ‡‰è©²æ›´å¤§æ›´å®Œæ•´ï¼‰
                keyword_dict = {
                    "æ©Ÿå™¨å­¸ç¿’": 1, "æ·±åº¦å­¸ç¿’": 2, "äººå·¥æ™ºèƒ½": 3, "æ¼”ç®—æ³•": 4,
                    "æ¨¡å‹": 5, "è¨“ç·´": 6, "é æ¸¬": 7, "æ•¸æ“š": 8, "ç‰¹å¾µ": 9, "åˆ†é¡": 10
                }
                
                # å‰µå»ºå›ºå®šç¶­åº¦çš„å‘é‡
                vector = [0.0] * self.config.dimension
                
                for word in words:
                    if word in keyword_dict:
                        idx = keyword_dict[word] % self.config.dimension
                        vector[idx] += 1.0
                
                # æ­£è¦åŒ–
                norm = sum(x*x for x in vector) ** 0.5
                if norm > 0:
                    vector = [x/norm for x in vector]
                
                return vector
        
        return KeywordEmbeddingModel(config)
    
    def get_best_model_for_content(self, content: str, content_type: str = "paragraph") -> str:
        """æ ¹æ“šå…§å®¹é¸æ“‡æœ€ä½³æ¨¡å‹"""
        
        if not self.enable_multi_embedding:
            return "general"
        
        # æ ¹æ“šå…§å®¹é¡å‹é¸æ“‡æ¨¡å‹
        if content_type == "title":
            return "sentence"  # æ¨™é¡Œä½¿ç”¨å¥å­æ¨¡å‹
        elif content_type == "keyword" or len(content.split()) < 5:
            return "keyword"   # çŸ­æ–‡æœ¬ä½¿ç”¨é—œéµè©æ¨¡å‹
        elif self._is_technical_content(content):
            return "domain"    # æŠ€è¡“å…§å®¹ä½¿ç”¨é ˜åŸŸæ¨¡å‹
        else:
            return "general"   # é è¨­ä½¿ç”¨é€šç”¨æ¨¡å‹
    
    def _is_technical_content(self, content: str) -> bool:
        """åˆ¤æ–·æ˜¯å¦ç‚ºæŠ€è¡“å…§å®¹"""
        tech_keywords = [
            "ç®—æ³•", "æ¨¡å‹", "è¨“ç·´", "é æ¸¬", "æ©Ÿå™¨å­¸ç¿’", "æ·±åº¦å­¸ç¿’", 
            "äººå·¥æ™ºèƒ½", "æ•¸æ“š", "ç‰¹å¾µ", "åˆ†é¡", "å›æ­¸", "ç¥ç¶“ç¶²è·¯"
        ]
        
        content_lower = content.lower()
        tech_count = sum(1 for keyword in tech_keywords if keyword in content_lower)
        
        # å¦‚æœåŒ…å«2å€‹ä»¥ä¸ŠæŠ€è¡“é—œéµè©ï¼Œèªç‚ºæ˜¯æŠ€è¡“å…§å®¹
        return tech_count >= 2
    
    def embed_with_multiple_models(
        self, 
        text: str, 
        model_names: List[str] = None
    ) -> Dict[str, List[float]]:
        """ä½¿ç”¨å¤šå€‹æ¨¡å‹ç”Ÿæˆembedding"""
        
        if not self.enable_multi_embedding:
            # åªä½¿ç”¨é€šç”¨æ¨¡å‹
            general_embedding = self.models["general"].embed_text(text)
            return {"general": general_embedding}
        
        if model_names is None:
            model_names = list(self.models.keys())
        
        embeddings = {}
        
        for model_name in model_names:
            if model_name in self.models:
                try:
                    embedding = self.models[model_name].embed_text(text)
                    embeddings[model_name] = embedding
                except Exception as e:
                    logger.warning(f"âš ï¸ æ¨¡å‹ {model_name} embeddingå¤±æ•—: {e}")
                    # ä½¿ç”¨é€šç”¨æ¨¡å‹ä½œç‚ºå‚™ç”¨
                    if "general" in self.models and model_name != "general":
                        embeddings[model_name] = self.models["general"].embed_text(text)
        
        return embeddings
    
    def get_adaptive_embedding(self, text: str, query_context: Dict[str, Any] = None) -> List[float]:
        """è‡ªé©æ‡‰embeddingï¼šæ ¹æ“šä¸Šä¸‹æ–‡é¸æ“‡æœ€ä½³ç­–ç•¥"""
        
        # åˆ†ææŸ¥è©¢ä¸Šä¸‹æ–‡
        content_type = "paragraph"
        if query_context:
            content_type = query_context.get("content_type", "paragraph")
            search_intent = query_context.get("search_intent", "general")
        
        # é¸æ“‡æœ€ä½³æ¨¡å‹
        best_model = self.get_best_model_for_content(text, content_type)
        
        # ç”Ÿæˆembedding
        if best_model in self.models:
            return self.models[best_model].embed_text(text)
        else:
            # å‚™ç”¨æ–¹æ¡ˆ
            return self.models["general"].embed_text(text)
    
    def compute_ensemble_embedding(
        self, 
        text: str, 
        model_weights: Dict[str, float] = None
    ) -> List[float]:
        """è¨ˆç®—é›†æˆembedding"""
        
        if not self.enable_multi_embedding:
            return self.models["general"].embed_text(text)
        
        # ä½¿ç”¨é è¨­æ¬Šé‡
        if model_weights is None:
            model_weights = {name: config.weight for name, config in self.model_configs.items()}
        
        # ç²å–æ‰€æœ‰æ¨¡å‹çš„embedding
        all_embeddings = self.embed_with_multiple_models(text)
        
        if not all_embeddings:
            logger.warning("âš ï¸ æ‰€æœ‰æ¨¡å‹embeddingå¤±æ•—ï¼Œä½¿ç”¨é›¶å‘é‡")
            return [0.0] * 512
        
        # è¨ˆç®—åŠ æ¬Šå¹³å‡
        ensemble_embedding = None
        total_weight = 0.0
        
        for model_name, embedding in all_embeddings.items():
            weight = model_weights.get(model_name, 0.0)
            if weight > 0:
                embedding_array = np.array(embedding)
                
                if ensemble_embedding is None:
                    ensemble_embedding = weight * embedding_array
                else:
                    # è™•ç†ä¸åŒç¶­åº¦çš„embedding
                    if len(embedding_array) != len(ensemble_embedding):
                        # èª¿æ•´åˆ°ç›¸åŒç¶­åº¦ï¼ˆå–è¼ƒå°è€…ï¼‰
                        min_dim = min(len(embedding_array), len(ensemble_embedding))
                        embedding_array = embedding_array[:min_dim]
                        ensemble_embedding = ensemble_embedding[:min_dim]
                    
                    ensemble_embedding += weight * embedding_array
                
                total_weight += weight
        
        # æ­£è¦åŒ–
        if total_weight > 0 and ensemble_embedding is not None:
            ensemble_embedding = ensemble_embedding / total_weight
            return ensemble_embedding.tolist()
        else:
            # å‚™ç”¨æ–¹æ¡ˆï¼šè¿”å›é€šç”¨æ¨¡å‹çš„embedding
            return self.models["general"].embed_text(text)
    
    def get_model_info(self) -> Dict[str, Dict[str, Any]]:
        """ç²å–æ‰€æœ‰æ¨¡å‹ä¿¡æ¯"""
        model_info = {}
        
        for name, config in self.model_configs.items():
            model_info[name] = {
                "model_name": config.model_name,
                "model_type": config.model_type,
                "dimension": config.dimension,
                "strengths": config.strengths,
                "use_cases": config.use_cases,
                "weight": config.weight,
                "loaded": name in self.models and self.models[name].model is not None
            }
        
        return model_info
    
    def benchmark_models(self, test_texts: List[str]) -> Dict[str, Dict[str, float]]:
        """åŸºæº–æ¸¬è©¦æ‰€æœ‰æ¨¡å‹"""
        import time
        
        results = {}
        
        for model_name, model in self.models.items():
            if model.model is None:
                continue
            
            start_time = time.time()
            
            try:
                # æ¸¬è©¦å–®å€‹æ–‡æœ¬embedding
                single_time_start = time.time()
                model.embed_text(test_texts[0])
                single_time = time.time() - single_time_start
                
                # æ¸¬è©¦æ‰¹é‡embedding
                batch_time_start = time.time()
                model.embed_batch(test_texts[:5])  # æ¸¬è©¦5å€‹æ–‡æœ¬
                batch_time = (time.time() - batch_time_start) / 5
                
                total_time = time.time() - start_time
                
                results[model_name] = {
                    "single_embedding_time": single_time,
                    "batch_embedding_time": batch_time,
                    "total_time": total_time,
                    "dimension": self.model_configs[model_name].dimension
                }
                
            except Exception as e:
                logger.error(f"âŒ æ¨¡å‹ {model_name} åŸºæº–æ¸¬è©¦å¤±æ•—: {e}")
                results[model_name] = {
                    "error": str(e)
                }
        
        return results