"""
Enhanced Document Processor
å¢å¼·çš„æ–‡æª”è™•ç†å™¨ï¼Œå¯¦ç¾æ™ºèƒ½åˆ‡å‰²å’Œçµæ§‹è­˜åˆ¥
"""

import re
import os
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
from llama_index.core import Document
from llama_index.core.node_parser import SimpleNodeParser
import logging

# é…ç½®logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class DocumentStructure:
    """æ–‡æª”çµæ§‹ä¿¡æ¯"""
    content_type: str  # title, paragraph, list, table, etc.
    semantic_level: int  # 1=æ¨™é¡Œ, 2=æ®µè½, 3=å¥å­
    chapter: Optional[str] = None
    section: Optional[str] = None
    subsection: Optional[str] = None
    hierarchy_path: Optional[str] = None

@dataclass
class ChunkInfo:
    """åˆ‡å‰²å¡Šä¿¡æ¯"""
    content: str
    structure: DocumentStructure
    chunk_index: int
    total_chunks: int
    strategy_type: str
    chunk_size: int
    chunk_overlap: int
    parent_chunk_id: Optional[str] = None

class EnhancedDocumentProcessor:
    """å¢å¼·çš„æ–‡æª”è™•ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any] = None):
        self.config = config or {}
        
        # å¾é…ç½®å°å…¥è¨­å®š
        from config.config import (
            CHUNK_SIZE, CHUNK_OVERLAP, 
            ENABLE_HIERARCHICAL_CHUNKING,
            ENABLE_DOCUMENT_STRUCTURE_DETECTION,
            CHUNK_STRATEGIES
        )
        
        self.chunk_size = CHUNK_SIZE
        self.chunk_overlap = CHUNK_OVERLAP
        self.enable_hierarchical = ENABLE_HIERARCHICAL_CHUNKING
        self.enable_structure_detection = ENABLE_DOCUMENT_STRUCTURE_DETECTION
        self.chunk_strategies = CHUNK_STRATEGIES
        
        # æ–‡æª”çµæ§‹è­˜åˆ¥æ­£å‰‡è¡¨é”å¼
        self.structure_patterns = {
            'chapter': [
                r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« [ï¼š:\s]',
                r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç¯‡[ï¼š:\s]',
                r'^Chapter\s*\d+',
                r'^\d+\.\s*[^\d]',
            ],
            'section': [
                r'^\d+\.\d+\s*[^\d]',
                r'^ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç¯€[ï¼š:\s]',
                r'^Â§\s*\d+',
            ],
            'subsection': [
                r'^\d+\.\d+\.\d+\s*[^\d]',
                r'^\([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+\)',
                r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€',
            ],
            'list_item': [
                r'^[â€¢\-\*]\s+',
                r'^\d+\)\s+',
                r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€',
            ],
            'table': [
                r'\|.*\|.*\|',
                r'[\u4e00-\u9fff\w\s]*\t+[\u4e00-\u9fff\w\s]*',
            ]
        }
        
        logger.info(f"ğŸ”§ EnhancedDocumentProcessor åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - åŸºç¤chunk_size: {self.chunk_size}")
        logger.info(f"   - chunk_overlap: {self.chunk_overlap}")
        logger.info(f"   - å•Ÿç”¨éšå±¤åˆ‡å‰²: {self.enable_hierarchical}")
        logger.info(f"   - å•Ÿç”¨çµæ§‹è­˜åˆ¥: {self.enable_structure_detection}")
    
    def detect_document_structure(self, text: str) -> List[Tuple[str, DocumentStructure]]:
        """
        æª¢æ¸¬æ–‡æª”çµæ§‹
        
        Returns:
            List of (text_segment, structure_info)
        """
        if not self.enable_structure_detection:
            return [(text, DocumentStructure(content_type="paragraph", semantic_level=2))]
        
        segments = []
        lines = text.split('\n')
        current_chapter = None
        current_section = None
        current_subsection = None
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
            
            structure = self._analyze_line_structure(line)
            
            # æ›´æ–°å±¤ç´šä¿¡æ¯
            if structure.content_type == 'title':
                if structure.semantic_level == 1:  # ç« ç¯€
                    current_chapter = line
                    current_section = None
                    current_subsection = None
                elif structure.semantic_level == 2:  # ç¯€
                    current_section = line
                    current_subsection = None
                elif structure.semantic_level == 3:  # å­ç¯€
                    current_subsection = line
            
            # è¨­å®šå±¤ç´šè·¯å¾‘
            structure.chapter = current_chapter
            structure.section = current_section
            structure.subsection = current_subsection
            structure.hierarchy_path = self._build_hierarchy_path(
                current_chapter, current_section, current_subsection
            )
            
            segments.append((line, structure))
        
        logger.info(f"ğŸ“‹ æª¢æ¸¬åˆ° {len(segments)} å€‹æ–‡æª”æ®µè½")
        return segments
    
    def _analyze_line_structure(self, line: str) -> DocumentStructure:
        """åˆ†æå–®è¡Œçš„çµæ§‹é¡å‹"""
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç« ç¯€æ¨™é¡Œ
        for pattern in self.structure_patterns['chapter']:
            if re.match(pattern, line):
                return DocumentStructure(content_type="title", semantic_level=1)
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºç¯€æ¨™é¡Œ
        for pattern in self.structure_patterns['section']:
            if re.match(pattern, line):
                return DocumentStructure(content_type="title", semantic_level=2)
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºå­ç¯€æ¨™é¡Œ
        for pattern in self.structure_patterns['subsection']:
            if re.match(pattern, line):
                return DocumentStructure(content_type="title", semantic_level=3)
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºåˆ—è¡¨é …ç›®
        for pattern in self.structure_patterns['list_item']:
            if re.match(pattern, line):
                return DocumentStructure(content_type="list", semantic_level=2)
        
        # æª¢æŸ¥æ˜¯å¦ç‚ºè¡¨æ ¼
        for pattern in self.structure_patterns['table']:
            if re.match(pattern, line):
                return DocumentStructure(content_type="table", semantic_level=2)
        
        # é è¨­ç‚ºæ®µè½
        return DocumentStructure(content_type="paragraph", semantic_level=2)
    
    def _build_hierarchy_path(self, chapter: str, section: str, subsection: str) -> str:
        """æ§‹å»ºå±¤ç´šè·¯å¾‘"""
        path_parts = []
        if chapter:
            path_parts.append(chapter[:20])  # é™åˆ¶é•·åº¦
        if section:
            path_parts.append(section[:20])
        if subsection:
            path_parts.append(subsection[:20])
        
        return " / ".join(path_parts) if path_parts else "æ ¹ç›®éŒ„"
    
    def hierarchical_chunk(self, document: Document) -> List[ChunkInfo]:
        """
        éšå±¤å¼æ–‡æª”åˆ‡å‰²
        """
        if not self.enable_hierarchical:
            return self._simple_chunk(document)
        
        text = document.text
        segments = self.detect_document_structure(text)
        
        all_chunks = []
        chunk_id = 0
        
        # æŒ‰ä¸åŒç­–ç•¥åˆ‡å‰²
        for strategy_name, strategy_config in self.chunk_strategies.items():
            strategy_chunks = self._chunk_by_strategy(
                segments, strategy_name, strategy_config, chunk_id
            )
            all_chunks.extend(strategy_chunks)
            chunk_id += len(strategy_chunks)
        
        logger.info(f"ğŸ”„ éšå±¤åˆ‡å‰²å®Œæˆï¼Œç¸½å…±ç”¢ç”Ÿ {len(all_chunks)} å€‹chunks")
        return all_chunks
    
    def _chunk_by_strategy(
        self, 
        segments: List[Tuple[str, DocumentStructure]], 
        strategy_name: str, 
        strategy_config: Dict[str, int],
        start_chunk_id: int
    ) -> List[ChunkInfo]:
        """æŒ‰ç‰¹å®šç­–ç•¥åˆ‡å‰²"""
        
        chunk_size = strategy_config['size']
        chunk_overlap = strategy_config['overlap']
        
        chunks = []
        current_chunk = ""
        current_structure = None
        chunk_index = 0
        
        for text_segment, structure in segments:
            # å¦‚æœæ˜¯æ¨™é¡Œä¸”ç•¶å‰chunkä¸ç‚ºç©ºï¼Œå…ˆä¿å­˜ç•¶å‰chunk
            if (structure.content_type == "title" and 
                current_chunk.strip() and 
                len(current_chunk) > chunk_overlap):
                
                chunks.append(ChunkInfo(
                    content=current_chunk.strip(),
                    structure=current_structure or structure,
                    chunk_index=start_chunk_id + chunk_index,
                    total_chunks=0,  # ç¨å¾Œæ›´æ–°
                    strategy_type=strategy_name,
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap
                ))
                chunk_index += 1
                current_chunk = ""
            
            # æ·»åŠ æ–°å…§å®¹
            if current_chunk:
                current_chunk += "\n" + text_segment
            else:
                current_chunk = text_segment
                current_structure = structure
            
            # å¦‚æœè¶…échunkå¤§å°ï¼Œé€²è¡Œåˆ‡å‰²
            if len(current_chunk) >= chunk_size:
                # æ‰¾åˆ°åˆé©çš„åˆ‡å‰²é»
                split_point = self._find_split_point(current_chunk, chunk_size, chunk_overlap)
                
                chunk_content = current_chunk[:split_point]
                remaining_content = current_chunk[split_point - chunk_overlap:]
                
                chunks.append(ChunkInfo(
                    content=chunk_content.strip(),
                    structure=current_structure or structure,
                    chunk_index=start_chunk_id + chunk_index,
                    total_chunks=0,
                    strategy_type=strategy_name,
                    chunk_size=chunk_size,
                    chunk_overlap=chunk_overlap
                ))
                chunk_index += 1
                current_chunk = remaining_content
        
        # è™•ç†æœ€å¾Œä¸€å€‹chunk
        if current_chunk.strip():
            chunks.append(ChunkInfo(
                content=current_chunk.strip(),
                structure=current_structure or DocumentStructure(content_type="paragraph", semantic_level=2),
                chunk_index=start_chunk_id + chunk_index,
                total_chunks=0,
                strategy_type=strategy_name,
                chunk_size=chunk_size,
                chunk_overlap=chunk_overlap
            ))
        
        # æ›´æ–°total_chunks
        for chunk in chunks:
            chunk.total_chunks = len(chunks)
        
        logger.info(f"ğŸ“¦ {strategy_name} ç­–ç•¥ç”¢ç”Ÿ {len(chunks)} å€‹chunks")
        return chunks
    
    def _find_split_point(self, text: str, target_size: int, overlap: int) -> int:
        """æ‰¾åˆ°æœ€ä½³åˆ‡å‰²é»ï¼ˆå„ªå…ˆåœ¨å¥è™Ÿã€æ®µè½é‚Šç•Œç­‰ä½ç½®åˆ‡å‰²ï¼‰"""
        
        if len(text) <= target_size:
            return len(text)
        
        # å„ªå…ˆåœ¨å¥è™Ÿè™•åˆ‡å‰²
        sentence_endings = ['.', 'ã€‚', 'ï¼', 'ï¼Ÿ', '!', '?']
        for i in range(target_size, overlap, -1):
            if i < len(text) and text[i] in sentence_endings:
                return min(i + 1, len(text))
        
        # å…¶æ¬¡åœ¨æ›è¡Œè™•åˆ‡å‰²
        for i in range(target_size, overlap, -1):
            if i < len(text) and text[i] == '\n':
                return i
        
        # æœ€å¾Œåœ¨ç©ºæ ¼è™•åˆ‡å‰²
        for i in range(target_size, overlap, -1):
            if i < len(text) and text[i] == ' ':
                return i
        
        # å¯¦åœ¨æ‰¾ä¸åˆ°åˆé©ä½ç½®ï¼Œå°±ç¡¬åˆ‡å‰²
        return target_size
    
    def _simple_chunk(self, document: Document) -> List[ChunkInfo]:
        """ç°¡å–®åˆ‡å‰²æ–¹å¼ï¼ˆå¾Œå‚™æ–¹æ¡ˆï¼‰"""
        text = document.text
        parser = SimpleNodeParser.from_defaults(
            chunk_size=self.chunk_size,
            chunk_overlap=self.chunk_overlap
        )
        
        nodes = parser.get_nodes_from_documents([document])
        chunks = []
        
        for i, node in enumerate(nodes):
            structure = DocumentStructure(content_type="paragraph", semantic_level=2)
            chunks.append(ChunkInfo(
                content=node.text,
                structure=structure,
                chunk_index=i,
                total_chunks=len(nodes),
                strategy_type="simple",
                chunk_size=self.chunk_size,
                chunk_overlap=self.chunk_overlap
            ))
        
        return chunks
    
    def create_enhanced_documents(self, chunk_infos: List[ChunkInfo], original_document: Document) -> List[Document]:
        """
        å‰µå»ºå¢å¼·çš„Documentå°è±¡ï¼ŒåŒ…å«æ‰€æœ‰å…ƒæ•¸æ“š
        """
        enhanced_docs = []
        
        for chunk_info in chunk_infos:
            # å‰µå»ºå¢å¼·çš„å…ƒæ•¸æ“š
            enhanced_metadata = {
                **original_document.metadata,
                
                # æ–‡æª”çµæ§‹ä¿¡æ¯
                "document_structure": {
                    "chapter": chunk_info.structure.chapter,
                    "section": chunk_info.structure.section,
                    "subsection": chunk_info.structure.subsection,
                    "content_type": chunk_info.structure.content_type,
                    "semantic_level": chunk_info.structure.semantic_level,
                    "hierarchy_path": chunk_info.structure.hierarchy_path
                },
                
                # åˆ‡å‰²ç­–ç•¥ä¿¡æ¯
                "chunking_strategy": {
                    "strategy_type": chunk_info.strategy_type,
                    "chunk_size": chunk_info.chunk_size,
                    "chunk_overlap": chunk_info.chunk_overlap,
                    "chunk_index": chunk_info.chunk_index,
                    "total_chunks": chunk_info.total_chunks,
                    "parent_chunk_id": chunk_info.parent_chunk_id
                },
                
                # è™•ç†ä¿¡æ¯
                "processing_info": {
                    "processed_at": datetime.now().isoformat(),
                    "processor_version": "enhanced_v2.0",
                    "extraction_method": "hierarchical_chunking"
                }
            }
            
            # å‰µå»ºDocumentå°è±¡
            doc = Document(
                text=chunk_info.content,
                metadata=enhanced_metadata
            )
            
            enhanced_docs.append(doc)
        
        logger.info(f"ğŸ“„ å‰µå»ºäº† {len(enhanced_docs)} å€‹å¢å¼·Documentå°è±¡")
        return enhanced_docs
    
    def process_document(self, document: Document) -> List[Document]:
        """
        å®Œæ•´çš„æ–‡æª”è™•ç†æµç¨‹
        """
        logger.info(f"ğŸ”„ é–‹å§‹è™•ç†æ–‡æª”: {document.metadata.get('source', 'unknown')}")
        
        # 1. éšå±¤å¼åˆ‡å‰²
        chunk_infos = self.hierarchical_chunk(document)
        
        # 2. å‰µå»ºå¢å¼·çš„Documentå°è±¡
        enhanced_docs = self.create_enhanced_documents(chunk_infos, document)
        
        logger.info(f"âœ… æ–‡æª”è™•ç†å®Œæˆï¼Œç”¢ç”Ÿ {len(enhanced_docs)} å€‹chunks")
        return enhanced_docs