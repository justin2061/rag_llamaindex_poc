"""
Contextual Reranker System
ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‡æ’åºç³»çµ±ï¼ŒåŸºæ–¼å°è©±æ­·å²å’Œèªç¾©ç›¸é—œæ€§é‡æ–°æ’åºæª¢ç´¢çµæœ
"""

import logging
import re
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime
import numpy as np
from llama_index.core.schema import NodeWithScore
from llama_index.core import Settings

# é…ç½®logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class RerankingContext:
    """é‡æ’åºä¸Šä¸‹æ–‡"""
    query: str
    conversation_history: List[Dict[str, str]]
    user_preferences: Dict[str, Any]
    domain_context: str
    search_intent: str  # informational, navigational, transactional

@dataclass
class RerankingFeatures:
    """é‡æ’åºç‰¹å¾µ"""
    semantic_similarity: float
    keyword_overlap: float
    context_relevance: float
    freshness_score: float
    authority_score: float
    user_preference_score: float
    diversity_penalty: float
    final_score: float

class SemanticAnalyzer:
    """èªç¾©åˆ†æå™¨"""
    
    def __init__(self):
        self.llm_model = Settings.llm
    
    def compute_semantic_similarity(self, query: str, content: str) -> float:
        """è¨ˆç®—èªç¾©ç›¸ä¼¼åº¦"""
        try:
            # ç°¡åŒ–ç‰ˆèªç¾©ç›¸ä¼¼åº¦è¨ˆç®—
            # å¯¦éš›æ‡‰ç”¨ä¸­å¯ä½¿ç”¨æ›´è¤‡é›œçš„æ¨¡å‹
            
            # 1. é—œéµè©é‡ç–Šåº¦
            query_words = set(query.lower().split())
            content_words = set(content.lower().split())
            
            if not query_words:
                return 0.0
            
            overlap = len(query_words.intersection(content_words))
            keyword_sim = overlap / len(query_words)
            
            # 2. èªç¾©æ¦‚å¿µåŒ¹é…
            semantic_sim = self._compute_concept_similarity(query, content)
            
            # 3. åŠ æ¬Šå¹³å‡
            final_sim = 0.6 * keyword_sim + 0.4 * semantic_sim
            
            return min(final_sim, 1.0)
            
        except Exception as e:
            logger.warning(f"âš ï¸ èªç¾©ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            return 0.0
    
    def _compute_concept_similarity(self, query: str, content: str) -> float:
        """è¨ˆç®—æ¦‚å¿µç›¸ä¼¼åº¦"""
        # å®šç¾©æ¦‚å¿µåŒç¾©è©çµ„
        concept_groups = {
            "learning": ["å­¸ç¿’", "è¨“ç·´", "æ•™è‚²", "åŸ¹è¨“", "é€²ä¿®"],
            "artificial_intelligence": ["äººå·¥æ™ºèƒ½", "AI", "æ©Ÿå™¨å­¸ç¿’", "æ·±åº¦å­¸ç¿’", "æ™ºèƒ½ç³»çµ±"],
            "algorithm": ["æ¼”ç®—æ³•", "ç®—æ³•", "æ–¹æ³•", "æŠ€è¡“", "ç­–ç•¥"],
            "data": ["æ•¸æ“š", "è³‡æ–™", "ä¿¡æ¯", "è³‡è¨Š", "æ•¸æ“šé›†"],
            "model": ["æ¨¡å‹", "æ¡†æ¶", "ç³»çµ±", "æ¶æ§‹", "çµæ§‹"]
        }
        
        query_concepts = self._extract_concepts(query, concept_groups)
        content_concepts = self._extract_concepts(content, concept_groups)
        
        if not query_concepts:
            return 0.0
        
        # è¨ˆç®—æ¦‚å¿µé‡ç–Š
        overlap = len(query_concepts.intersection(content_concepts))
        return overlap / len(query_concepts)
    
    def _extract_concepts(self, text: str, concept_groups: Dict[str, List[str]]) -> set:
        """æå–æ–‡æœ¬ä¸­çš„æ¦‚å¿µ"""
        concepts = set()
        text_lower = text.lower()
        
        for concept, keywords in concept_groups.items():
            if any(keyword in text_lower for keyword in keywords):
                concepts.add(concept)
        
        return concepts
    
    def analyze_search_intent(self, query: str) -> str:
        """åˆ†ææœç´¢æ„åœ–"""
        query_lower = query.lower()
        
        # ä¿¡æ¯å‹æŸ¥è©¢
        if any(word in query_lower for word in ["ä»€éº¼", "å¦‚ä½•", "ç‚ºä»€éº¼", "æ€éº¼", "ä»‹ç´¹"]):
            return "informational"
        
        # å°èˆªå‹æŸ¥è©¢
        if any(word in query_lower for word in ["æ‰¾", "æœç´¢", "ä½ç½®", "åœ¨å“ª"]):
            return "navigational"
        
        # äº‹å‹™å‹æŸ¥è©¢
        if any(word in query_lower for word in ["ä¸‹è¼‰", "è³¼è²·", "è¨»å†Š", "ç”³è«‹"]):
            return "transactional"
        
        return "informational"  # é è¨­ç‚ºä¿¡æ¯å‹

class ContextualReranker:
    """ä¸Šä¸‹æ–‡æ„ŸçŸ¥é‡æ’åºå™¨"""
    
    def __init__(self, enable_contextual_reranking: bool = True):
        self.enable_contextual_reranking = enable_contextual_reranking
        self.semantic_analyzer = SemanticAnalyzer()
        
        # ç‰¹å¾µæ¬Šé‡é…ç½®
        self.feature_weights = {
            "semantic_similarity": 0.35,
            "keyword_overlap": 0.20,
            "context_relevance": 0.25,
            "freshness_score": 0.05,
            "authority_score": 0.10,
            "user_preference_score": 0.05
        }
        
        logger.info(f"ğŸ¯ ContextualReranker åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - å•Ÿç”¨ä¸Šä¸‹æ–‡é‡æ’åº: {enable_contextual_reranking}")
    
    def rerank_results(
        self, 
        results: List[NodeWithScore],
        reranking_context: RerankingContext
    ) -> List[NodeWithScore]:
        """é‡æ–°æ’åºæª¢ç´¢çµæœ"""
        
        if not self.enable_contextual_reranking or not results:
            return results
        
        logger.info(f"ğŸ”„ é–‹å§‹é‡æ’åºï¼Œå€™é¸çµæœ: {len(results)}")
        
        # 1. æå–é‡æ’åºç‰¹å¾µ
        features_list = []
        for result in results:
            features = self._extract_reranking_features(result, reranking_context)
            features_list.append(features)
        
        # 2. å¤šæ¨£æ€§è™•ç†
        features_list = self._apply_diversity_penalty(features_list, results)
        
        # 3. è¨ˆç®—æœ€çµ‚åˆ†æ•¸
        for i, features in enumerate(features_list):
            final_score = self._compute_final_score(features)
            features.final_score = final_score
            
            # æ›´æ–°NodeWithScoreçš„åˆ†æ•¸
            results[i].score = final_score
        
        # 4. æŒ‰æœ€çµ‚åˆ†æ•¸æ’åº
        reranked_results = sorted(
            zip(results, features_list), 
            key=lambda x: x[1].final_score, 
            reverse=True
        )
        
        final_results = [result for result, _ in reranked_results]
        
        logger.info(f"âœ… é‡æ’åºå®Œæˆï¼Œè¿”å› {len(final_results)} å€‹çµæœ")
        return final_results
    
    def _extract_reranking_features(
        self, 
        result: NodeWithScore, 
        context: RerankingContext
    ) -> RerankingFeatures:
        """æå–é‡æ’åºç‰¹å¾µ"""
        
        content = result.node.text
        metadata = result.node.metadata
        
        # 1. èªç¾©ç›¸ä¼¼åº¦
        semantic_sim = self.semantic_analyzer.compute_semantic_similarity(
            context.query, content
        )
        
        # 2. é—œéµè©é‡ç–Šåº¦
        keyword_overlap = self._compute_keyword_overlap(context.query, content)
        
        # 3. ä¸Šä¸‹æ–‡ç›¸é—œæ€§
        context_relevance = self._compute_context_relevance(
            content, context.conversation_history
        )
        
        # 4. æ™‚æ–°æ€§åˆ†æ•¸
        freshness_score = self._compute_freshness_score(metadata)
        
        # 5. æ¬Šå¨æ€§åˆ†æ•¸
        authority_score = self._compute_authority_score(metadata)
        
        # 6. ç”¨æˆ¶åå¥½åˆ†æ•¸
        user_preference_score = self._compute_user_preference_score(
            content, metadata, context.user_preferences
        )
        
        return RerankingFeatures(
            semantic_similarity=semantic_sim,
            keyword_overlap=keyword_overlap,
            context_relevance=context_relevance,
            freshness_score=freshness_score,
            authority_score=authority_score,
            user_preference_score=user_preference_score,
            diversity_penalty=0.0,  # ç¨å¾Œè¨ˆç®—
            final_score=0.0        # ç¨å¾Œè¨ˆç®—
        )
    
    def _compute_keyword_overlap(self, query: str, content: str) -> float:
        """è¨ˆç®—é—œéµè©é‡ç–Šåº¦"""
        query_words = set(query.lower().split())
        content_words = set(content.lower().split())
        
        if not query_words:
            return 0.0
        
        overlap = len(query_words.intersection(content_words))
        return overlap / len(query_words)
    
    def _compute_context_relevance(
        self, 
        content: str, 
        conversation_history: List[Dict[str, str]]
    ) -> float:
        """è¨ˆç®—ä¸Šä¸‹æ–‡ç›¸é—œæ€§"""
        
        if not conversation_history:
            return 0.0
        
        # ç²å–æœ€è¿‘çš„å°è©±å…§å®¹
        recent_messages = conversation_history[-3:]  # æœ€è¿‘3è¼ªå°è©±
        context_text = " ".join([
            msg.get("content", "") 
            for msg in recent_messages 
            if msg.get("role") == "user"
        ])
        
        if not context_text.strip():
            return 0.0
        
        # è¨ˆç®—å…§å®¹èˆ‡å°è©±æ­·å²çš„ç›¸ä¼¼åº¦
        return self.semantic_analyzer.compute_semantic_similarity(
            context_text, content
        )
    
    def _compute_freshness_score(self, metadata: Dict[str, Any]) -> float:
        """è¨ˆç®—æ™‚æ–°æ€§åˆ†æ•¸"""
        try:
            # æª¢æŸ¥è™•ç†æ™‚é–“
            processed_at = metadata.get("processing_info", {}).get("processed_at")
            if processed_at:
                from datetime import datetime
                processed_time = datetime.fromisoformat(processed_at.replace('Z', '+00:00'))
                days_ago = (datetime.now() - processed_time.replace(tzinfo=None)).days
                
                # è¶Šæ–°çš„å…§å®¹åˆ†æ•¸è¶Šé«˜
                if days_ago <= 1:
                    return 1.0
                elif days_ago <= 7:
                    return 0.8
                elif days_ago <= 30:
                    return 0.6
                else:
                    return 0.4
            
            return 0.5  # é è¨­åˆ†æ•¸
            
        except Exception as e:
            logger.debug(f"æ™‚æ–°æ€§è¨ˆç®—å¤±æ•—: {e}")
            return 0.5
    
    def _compute_authority_score(self, metadata: Dict[str, Any]) -> float:
        """è¨ˆç®—æ¬Šå¨æ€§åˆ†æ•¸"""
        
        score = 0.5  # åŸºç¤åˆ†æ•¸
        
        # æ ¹æ“šä¾†æºé¡å‹èª¿æ•´æ¬Šå¨æ€§
        source = metadata.get("source", "").lower()
        
        if any(domain in source for domain in [".edu", ".gov", ".org"]):
            score += 0.3  # æ•™è‚²ã€æ”¿åºœã€çµ„ç¹”ç¶²ç«™
        elif any(domain in source for domain in [".pdf", "paper", "journal"]):
            score += 0.2  # å­¸è¡“æ–‡ä»¶
        elif "wiki" in source:
            score += 0.1  # ç¶­åŸºç™¾ç§‘
        
        # æ ¹æ“šæ–‡æª”çµæ§‹èª¿æ•´
        doc_structure = metadata.get("document_structure", {})
        if doc_structure.get("content_type") == "title":
            score += 0.1  # æ¨™é¡Œå…§å®¹é€šå¸¸æ›´é‡è¦
        
        return min(score, 1.0)
    
    def _compute_user_preference_score(
        self, 
        content: str, 
        metadata: Dict[str, Any], 
        user_preferences: Dict[str, Any]
    ) -> float:
        """è¨ˆç®—ç”¨æˆ¶åå¥½åˆ†æ•¸"""
        
        if not user_preferences:
            return 0.5
        
        score = 0.5
        
        # åå¥½çš„å…§å®¹é¡å‹
        preferred_types = user_preferences.get("content_types", [])
        content_type = metadata.get("document_structure", {}).get("content_type", "")
        if content_type in preferred_types:
            score += 0.2
        
        # åå¥½çš„ä¸»é¡Œ
        preferred_topics = user_preferences.get("topics", [])
        for topic in preferred_topics:
            if topic.lower() in content.lower():
                score += 0.1
                break
        
        # åå¥½çš„æ–‡æª”é•·åº¦
        preferred_length = user_preferences.get("preferred_length", "medium")
        content_length = len(content)
        
        if preferred_length == "short" and content_length < 500:
            score += 0.1
        elif preferred_length == "medium" and 500 <= content_length <= 1500:
            score += 0.1
        elif preferred_length == "long" and content_length > 1500:
            score += 0.1
        
        return min(score, 1.0)
    
    def _apply_diversity_penalty(
        self, 
        features_list: List[RerankingFeatures], 
        results: List[NodeWithScore]
    ) -> List[RerankingFeatures]:
        """æ‡‰ç”¨å¤šæ¨£æ€§æ‡²ç½°"""
        
        # ç°¡åŒ–ç‰ˆå¤šæ¨£æ€§æª¢æ¸¬ï¼šæª¢æŸ¥å…§å®¹ç›¸ä¼¼åº¦
        for i, features_i in enumerate(features_list):
            penalty = 0.0
            content_i = results[i].node.text
            
            for j, features_j in enumerate(features_list[:i]):  # åªæª¢æŸ¥å‰é¢çš„çµæœ
                content_j = results[j].node.text
                
                # è¨ˆç®—å…§å®¹ç›¸ä¼¼åº¦
                similarity = self._compute_content_similarity(content_i, content_j)
                
                if similarity > 0.8:  # é«˜ç›¸ä¼¼åº¦
                    penalty += 0.2
                elif similarity > 0.6:  # ä¸­ç­‰ç›¸ä¼¼åº¦
                    penalty += 0.1
            
            features_i.diversity_penalty = min(penalty, 0.5)  # é™åˆ¶æœ€å¤§æ‡²ç½°
        
        return features_list
    
    def _compute_content_similarity(self, content1: str, content2: str) -> float:
        """è¨ˆç®—å…§å®¹ç›¸ä¼¼åº¦"""
        # ç°¡åŒ–ç‰ˆï¼šåŸºæ–¼å…±åŒè©å½™æ¯”ä¾‹
        words1 = set(content1.lower().split())
        words2 = set(content2.lower().split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = len(words1.intersection(words2))
        union = len(words1.union(words2))
        
        return intersection / union if union > 0 else 0.0
    
    def _compute_final_score(self, features: RerankingFeatures) -> float:
        """è¨ˆç®—æœ€çµ‚åˆ†æ•¸"""
        
        score = (
            self.feature_weights["semantic_similarity"] * features.semantic_similarity +
            self.feature_weights["keyword_overlap"] * features.keyword_overlap +
            self.feature_weights["context_relevance"] * features.context_relevance +
            self.feature_weights["freshness_score"] * features.freshness_score +
            self.feature_weights["authority_score"] * features.authority_score +
            self.feature_weights["user_preference_score"] * features.user_preference_score
        )
        
        # æ‡‰ç”¨å¤šæ¨£æ€§æ‡²ç½°
        score = max(0.0, score - features.diversity_penalty)
        
        return score
    
    def get_reranking_explanation(
        self, 
        result: NodeWithScore, 
        features: RerankingFeatures
    ) -> Dict[str, Any]:
        """ç²å–é‡æ’åºè§£é‡‹"""
        
        return {
            "final_score": features.final_score,
            "feature_breakdown": {
                "semantic_similarity": {
                    "value": features.semantic_similarity,
                    "weight": self.feature_weights["semantic_similarity"],
                    "contribution": features.semantic_similarity * self.feature_weights["semantic_similarity"]
                },
                "keyword_overlap": {
                    "value": features.keyword_overlap,
                    "weight": self.feature_weights["keyword_overlap"],
                    "contribution": features.keyword_overlap * self.feature_weights["keyword_overlap"]
                },
                "context_relevance": {
                    "value": features.context_relevance,
                    "weight": self.feature_weights["context_relevance"],
                    "contribution": features.context_relevance * self.feature_weights["context_relevance"]
                },
                "freshness_score": {
                    "value": features.freshness_score,
                    "weight": self.feature_weights["freshness_score"],
                    "contribution": features.freshness_score * self.feature_weights["freshness_score"]
                },
                "authority_score": {
                    "value": features.authority_score,
                    "weight": self.feature_weights["authority_score"],
                    "contribution": features.authority_score * self.feature_weights["authority_score"]
                },
                "user_preference_score": {
                    "value": features.user_preference_score,
                    "weight": self.feature_weights["user_preference_score"],
                    "contribution": features.user_preference_score * self.feature_weights["user_preference_score"]
                }
            },
            "diversity_penalty": features.diversity_penalty,
            "content_preview": result.node.text[:200] + "..." if len(result.node.text) > 200 else result.node.text
        }
    
    def update_feature_weights(self, new_weights: Dict[str, float]):
        """æ›´æ–°ç‰¹å¾µæ¬Šé‡"""
        
        # ç¢ºä¿æ¬Šé‡ç¸½å’Œç‚º1
        total_weight = sum(new_weights.values())
        if total_weight > 0:
            normalized_weights = {k: v/total_weight for k, v in new_weights.items()}
            self.feature_weights.update(normalized_weights)
            logger.info(f"ğŸ”§ ç‰¹å¾µæ¬Šé‡å·²æ›´æ–°: {self.feature_weights}")
        else:
            logger.warning("âš ï¸ æ¬Šé‡ç¸½å’Œç‚º0ï¼Œä¿æŒåŸæœ‰æ¬Šé‡")
    
    def analyze_reranking_performance(
        self, 
        original_results: List[NodeWithScore],
        reranked_results: List[NodeWithScore],
        ground_truth_relevance: List[float] = None
    ) -> Dict[str, Any]:
        """åˆ†æé‡æ’åºæ€§èƒ½"""
        
        analysis = {
            "original_count": len(original_results),
            "reranked_count": len(reranked_results),
            "score_changes": [],
            "rank_changes": []
        }
        
        # åˆ†æåˆ†æ•¸è®ŠåŒ–
        for i, (orig, reranked) in enumerate(zip(original_results, reranked_results)):
            score_change = reranked.score - orig.score
            analysis["score_changes"].append({
                "index": i,
                "original_score": orig.score,
                "reranked_score": reranked.score,
                "score_change": score_change
            })
        
        # è¨ˆç®—çµ±è¨ˆæŒ‡æ¨™
        score_changes = [item["score_change"] for item in analysis["score_changes"]]
        analysis["statistics"] = {
            "mean_score_change": np.mean(score_changes) if score_changes else 0,
            "std_score_change": np.std(score_changes) if score_changes else 0,
            "improved_results": sum(1 for change in score_changes if change > 0),
            "degraded_results": sum(1 for change in score_changes if change < 0)
        }
        
        return analysis