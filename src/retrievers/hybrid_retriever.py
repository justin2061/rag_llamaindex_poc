"""
Hybrid Retriever System
æ··åˆæª¢ç´¢ç³»çµ±ï¼Œçµåˆå‘é‡æœç´¢ã€é—œéµå­—æœç´¢å’Œèªç¾©æœç´¢
"""

import json
import logging
from typing import List, Dict, Any, Optional, Tuple
from dataclasses import dataclass
from elasticsearch import Elasticsearch
import numpy as np
from llama_index.core.schema import NodeWithScore, QueryBundle
from llama_index.core.retrievers import BaseRetriever
from llama_index.core import Settings

# é…ç½®logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """æœç´¢çµæœ"""
    content: str
    score: float
    source: str
    metadata: Dict[str, Any]
    search_type: str  # vector, keyword, semantic, structural
    
@dataclass 
class HybridSearchConfig:
    """æ··åˆæœç´¢é…ç½®"""
    vector_weight: float = 0.6
    keyword_weight: float = 0.3
    semantic_weight: float = 0.1
    structural_weight: float = 0.0
    top_k: int = 10
    rerank_top_k: int = 20

class QueryRewriter:
    """æŸ¥è©¢æ”¹å¯«å™¨"""
    
    def __init__(self, llm_model=None):
        self.llm_model = llm_model or Settings.llm
    
    def rewrite_query(self, original_query: str, conversation_history: List[str] = None) -> List[str]:
        """
        æŸ¥è©¢æ”¹å¯«ï¼Œç”Ÿæˆå¤šå€‹è®Šé«”æŸ¥è©¢
        """
        rewritten_queries = [original_query]
        
        try:
            # 1. åŒç¾©è©æ“´å±•
            synonym_query = self._expand_synonyms(original_query)
            if synonym_query != original_query:
                rewritten_queries.append(synonym_query)
            
            # 2. å¯¦é«”æå–æŸ¥è©¢
            entity_query = self._extract_key_entities(original_query)
            if entity_query:
                rewritten_queries.append(entity_query)
            
            # 3. ä¸Šä¸‹æ–‡ç›¸é—œæŸ¥è©¢ï¼ˆå¦‚æœæœ‰å°è©±æ­·å²ï¼‰
            if conversation_history:
                context_query = self._generate_contextual_query(original_query, conversation_history)
                if context_query:
                    rewritten_queries.append(context_query)
            
            # 4. èªç¾©ç›¸é—œå•é¡Œ
            related_queries = self._generate_related_queries(original_query)
            rewritten_queries.extend(related_queries)
            
            logger.info(f"ğŸ”„ æŸ¥è©¢æ”¹å¯«å®Œæˆï¼ŒåŸå§‹æŸ¥è©¢: {original_query}")
            logger.info(f"   ç”Ÿæˆ {len(rewritten_queries)} å€‹è®Šé«”æŸ¥è©¢")
            
        except Exception as e:
            logger.warning(f"âš ï¸ æŸ¥è©¢æ”¹å¯«å¤±æ•—: {e}")
        
        return list(set(rewritten_queries))  # å»é‡
    
    def _expand_synonyms(self, query: str) -> str:
        """åŒç¾©è©æ“´å±•"""
        synonym_map = {
            "æ©Ÿå™¨å­¸ç¿’": ["ML", "machine learning", "äººå·¥æ™ºæ…§å­¸ç¿’"],
            "äººå·¥æ™ºèƒ½": ["AI", "artificial intelligence", "äººå·¥æ™ºæ…§"],
            "æ·±åº¦å­¸ç¿’": ["DL", "deep learning", "ç¥ç¶“ç¶²è·¯å­¸ç¿’"],
            "æ¼”ç®—æ³•": ["algorithm", "ç®—æ³•", "é‹ç®—æ³•"],
            "è³‡æ–™": ["æ•¸æ“š", "data", "æ•¸æ“šè³‡æ–™"],
            "æ¨¡å‹": ["model", "æ¨¡å‹ç³»çµ±", "æ¼”ç®—æ¨¡å‹"]
        }
        
        expanded_query = query
        for term, synonyms in synonym_map.items():
            if term in query:
                expanded_query += " " + " ".join(synonyms[:2])  # åªå–å‰2å€‹åŒç¾©è©
        
        return expanded_query
    
    def _extract_key_entities(self, query: str) -> str:
        """æå–é—œéµå¯¦é«”"""
        # ç°¡åŒ–ç‰ˆå¯¦é«”æå–ï¼Œå¯¦éš›æ‡‰ç”¨ä¸­å¯ç”¨NERæ¨¡å‹
        entities = []
        
        # æª¢æ¸¬æŠ€è¡“è¡“èª
        tech_terms = ["æ©Ÿå™¨å­¸ç¿’", "æ·±åº¦å­¸ç¿’", "äººå·¥æ™ºèƒ½", "æ¼”ç®—æ³•", "æ¨¡å‹", "è¨“ç·´", "é æ¸¬"]
        for term in tech_terms:
            if term in query:
                entities.append(term)
        
        # æª¢æ¸¬æ•¸å­—å’Œæ™‚é–“
        import re
        numbers = re.findall(r'\d+', query)
        entities.extend(numbers)
        
        return " ".join(entities) if entities else ""
    
    def _generate_contextual_query(self, query: str, history: List[str]) -> str:
        """åŸºæ–¼å°è©±æ­·å²ç”Ÿæˆä¸Šä¸‹æ–‡æŸ¥è©¢"""
        if not history:
            return ""
        
        # ç°¡åŒ–ç‰ˆï¼šå°‡æœ€è¿‘çš„å°è©±å…§å®¹åŠ å…¥æŸ¥è©¢
        recent_context = " ".join(history[-2:])  # å–æœ€è¿‘2è¼ªå°è©±
        return f"{query} {recent_context}"
    
    def _generate_related_queries(self, query: str) -> List[str]:
        """ç”Ÿæˆç›¸é—œæŸ¥è©¢"""
        related = []
        
        # åŸºæ–¼æŸ¥è©¢å…§å®¹ç”Ÿæˆç›¸é—œå•é¡Œ
        if "ä»€éº¼æ˜¯" in query or "æ˜¯ä»€éº¼" in query:
            # å¦‚æœå•çš„æ˜¯å®šç¾©ï¼Œå¯èƒ½é‚„æƒ³çŸ¥é“æ‡‰ç”¨
            topic = query.replace("ä»€éº¼æ˜¯", "").replace("æ˜¯ä»€éº¼", "").strip()
            related.append(f"{topic}çš„æ‡‰ç”¨")
            related.append(f"å¦‚ä½•ä½¿ç”¨{topic}")
        
        if "å¦‚ä½•" in query or "æ€éº¼" in query:
            # å¦‚æœå•çš„æ˜¯æ–¹æ³•ï¼Œå¯èƒ½é‚„æƒ³çŸ¥é“åŸç†
            topic = query.replace("å¦‚ä½•", "").replace("æ€éº¼", "").strip()
            related.append(f"{topic}çš„åŸç†")
            related.append(f"{topic}çš„å„ªç¼ºé»")
        
        return related[:2]  # é™åˆ¶æ•¸é‡

class HybridRetriever(BaseRetriever):
    """æ··åˆæª¢ç´¢å™¨"""
    
    def __init__(
        self, 
        elasticsearch_client: Elasticsearch,
        index_name: str,
        config: HybridSearchConfig = None,
        embedding_model = None
    ):
        super().__init__()
        self.es_client = elasticsearch_client
        self.index_name = index_name
        self.config = config or HybridSearchConfig()
        self.embedding_model = embedding_model or Settings.embed_model
        self.query_rewriter = QueryRewriter()
        
        logger.info(f"ğŸ”§ HybridRetriever åˆå§‹åŒ–å®Œæˆ")
        logger.info(f"   - ç´¢å¼•åç¨±: {index_name}")
        logger.info(f"   - å‘é‡æ¬Šé‡: {self.config.vector_weight}")
        logger.info(f"   - é—œéµå­—æ¬Šé‡: {self.config.keyword_weight}")
        logger.info(f"   - èªç¾©æ¬Šé‡: {self.config.semantic_weight}")
    
    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:
        """åŸ·è¡Œæ··åˆæª¢ç´¢"""
        query = query_bundle.query_str
        
        logger.info(f"ğŸ” é–‹å§‹æ··åˆæª¢ç´¢: {query}")
        
        # 1. æŸ¥è©¢æ”¹å¯«
        rewritten_queries = self.query_rewriter.rewrite_query(query)
        
        # 2. å¤šç¨®æª¢ç´¢ç­–ç•¥
        all_results = []
        
        for search_query in rewritten_queries:
            # å‘é‡æœç´¢
            vector_results = self._vector_search(search_query)
            all_results.extend([(r, "vector") for r in vector_results])
            
            # é—œéµå­—æœç´¢ 
            keyword_results = self._keyword_search(search_query)
            all_results.extend([(r, "keyword") for r in keyword_results])
            
            # èªç¾©æœç´¢
            semantic_results = self._semantic_search(search_query)
            all_results.extend([(r, "semantic") for r in semantic_results])
            
            # çµæ§‹åŒ–æœç´¢
            structural_results = self._structural_search(search_query)
            all_results.extend([(r, "structural") for r in structural_results])
        
        # 3. çµæœèåˆå’Œé‡æ’åº
        fused_results = self._fusion_ranking(all_results, query)
        
        # 4. è½‰æ›ç‚ºNodeWithScoreæ ¼å¼
        nodes_with_scores = self._convert_to_nodes(fused_results)
        
        logger.info(f"âœ… æ··åˆæª¢ç´¢å®Œæˆï¼Œè¿”å› {len(nodes_with_scores)} å€‹çµæœ")
        return nodes_with_scores[:self.config.top_k]
    
    def _vector_search(self, query: str) -> List[SearchResult]:
        """å‘é‡ç›¸ä¼¼åº¦æœç´¢"""
        try:
            # ç”ŸæˆæŸ¥è©¢å‘é‡
            query_embedding = self.embedding_model.get_text_embedding(query)
            
            search_body = {
                "knn": {
                    "field": "embedding",
                    "query_vector": query_embedding,
                    "k": self.config.rerank_top_k,
                    "num_candidates": self.config.rerank_top_k * 2
                }
            }
            
            response = self.es_client.search(
                index=self.index_name,
                body=search_body,
                size=self.config.rerank_top_k
            )
            
            results = []
            for hit in response['hits']['hits']:
                result = SearchResult(
                    content=hit['_source']['content'],
                    score=hit['_score'],
                    source=hit['_source'].get('metadata', {}).get('source', 'unknown'),
                    metadata=hit['_source'].get('metadata', {}),
                    search_type="vector"
                )
                results.append(result)
            
            logger.info(f"ğŸ¯ å‘é‡æœç´¢æ‰¾åˆ° {len(results)} å€‹çµæœ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ å‘é‡æœç´¢å¤±æ•—: {e}")
            return []
    
    def _keyword_search(self, query: str) -> List[SearchResult]:
        """BM25é—œéµå­—æœç´¢"""
        try:
            search_body = {
                "query": {
                    "bool": {
                        "should": [
                            {
                                "match": {
                                    "content": {
                                        "query": query,
                                        "boost": 2.0
                                    }
                                }
                            },
                            {
                                "match": {
                                    "bm25_content": {
                                        "query": query,
                                        "boost": 1.5
                                    }
                                }
                            },
                            {
                                "match_phrase": {
                                    "content": {
                                        "query": query,
                                        "boost": 3.0
                                    }
                                }
                            }
                        ]
                    }
                }
            }
            
            response = self.es_client.search(
                index=self.index_name,
                body=search_body,
                size=self.config.rerank_top_k
            )
            
            results = []
            for hit in response['hits']['hits']:
                result = SearchResult(
                    content=hit['_source']['content'],
                    score=hit['_score'],
                    source=hit['_source'].get('metadata', {}).get('source', 'unknown'),
                    metadata=hit['_source'].get('metadata', {}),
                    search_type="keyword"
                )
                results.append(result)
            
            logger.info(f"ğŸ”‘ é—œéµå­—æœç´¢æ‰¾åˆ° {len(results)} å€‹çµæœ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ é—œéµå­—æœç´¢å¤±æ•—: {e}")
            return []
    
    def _semantic_search(self, query: str) -> List[SearchResult]:
        """èªç¾©æœç´¢ï¼ˆåŸºæ–¼å…§å®¹èªç¾©ï¼‰"""
        try:
            search_body = {
                "query": {
                    "bool": {
                        "should": [
                            {
                                "match": {
                                    "content.ngram": {
                                        "query": query,
                                        "boost": 1.5
                                    }
                                }
                            },
                            {
                                "terms": {
                                    "metadata.semantic_info.keywords": query.split(),
                                    "boost": 2.0
                                }
                            },
                            {
                                "terms": {
                                    "metadata.semantic_info.entities": query.split(),
                                    "boost": 2.5
                                }
                            }
                        ]
                    }
                }
            }
            
            response = self.es_client.search(
                index=self.index_name,
                body=search_body,
                size=self.config.rerank_top_k
            )
            
            results = []
            for hit in response['hits']['hits']:
                result = SearchResult(
                    content=hit['_source']['content'],
                    score=hit['_score'],
                    source=hit['_source'].get('metadata', {}).get('source', 'unknown'),
                    metadata=hit['_source'].get('metadata', {}),
                    search_type="semantic"
                )
                results.append(result)
            
            logger.info(f"ğŸ§  èªç¾©æœç´¢æ‰¾åˆ° {len(results)} å€‹çµæœ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ èªç¾©æœç´¢å¤±æ•—: {e}")
            return []
    
    def _structural_search(self, query: str) -> List[SearchResult]:
        """çµæ§‹åŒ–æœç´¢ï¼ˆåŸºæ–¼æ–‡æª”çµæ§‹ï¼‰"""
        try:
            search_body = {
                "query": {
                    "bool": {
                        "should": [
                            # åœ¨æ¨™é¡Œä¸­æœç´¢
                            {
                                "match": {
                                    "title": {
                                        "query": query,
                                        "boost": 3.0
                                    }
                                }
                            },
                            # åœ¨ç« ç¯€ä¸­æœç´¢
                            {
                                "match": {
                                    "metadata.document_structure.chapter": {
                                        "query": query,
                                        "boost": 2.5
                                    }
                                }
                            },
                            # åœ¨ç¯€ä¸­æœç´¢
                            {
                                "match": {
                                    "metadata.document_structure.section": {
                                        "query": query,
                                        "boost": 2.0
                                    }
                                }
                            },
                            # æŒ‰å…§å®¹é¡å‹éæ¿¾
                            {
                                "bool": {
                                    "must": [
                                        {"match": {"content": query}},
                                        {"term": {"metadata.document_structure.content_type": "title"}}
                                    ],
                                    "boost": 2.0
                                }
                            }
                        ]
                    }
                }
            }
            
            response = self.es_client.search(
                index=self.index_name,
                body=search_body,
                size=self.config.rerank_top_k
            )
            
            results = []
            for hit in response['hits']['hits']:
                result = SearchResult(
                    content=hit['_source']['content'],
                    score=hit['_score'],
                    source=hit['_source'].get('metadata', {}).get('source', 'unknown'),
                    metadata=hit['_source'].get('metadata', {}),
                    search_type="structural"
                )
                results.append(result)
            
            logger.info(f"ğŸ—ï¸ çµæ§‹åŒ–æœç´¢æ‰¾åˆ° {len(results)} å€‹çµæœ")
            return results
            
        except Exception as e:
            logger.error(f"âŒ çµæ§‹åŒ–æœç´¢å¤±æ•—: {e}")
            return []
    
    def _fusion_ranking(self, results: List[Tuple[SearchResult, str]], query: str) -> List[SearchResult]:
        """èåˆæ’åº"""
        
        if not results:
            return []
        
        # æŒ‰å…§å®¹å»é‡
        seen_content = set()
        unique_results = []
        for result, search_type in results:
            content_hash = hash(result.content[:100])  # ä½¿ç”¨å‰100å­—ç¬¦åšå»é‡
            if content_hash not in seen_content:
                seen_content.add(content_hash)
                result.search_type = search_type  # æ›´æ–°æœç´¢é¡å‹
                unique_results.append(result)
        
        # è¨ˆç®—èåˆåˆ†æ•¸
        for result in unique_results:
            fusion_score = self._calculate_fusion_score(result, query)
            result.score = fusion_score
        
        # æŒ‰èåˆåˆ†æ•¸æ’åº
        ranked_results = sorted(unique_results, key=lambda x: x.score, reverse=True)
        
        logger.info(f"ğŸ”€ èåˆæ’åºå®Œæˆï¼Œå»é‡å¾Œå‰©é¤˜ {len(ranked_results)} å€‹çµæœ")
        return ranked_results
    
    def _calculate_fusion_score(self, result: SearchResult, query: str) -> float:
        """è¨ˆç®—èåˆåˆ†æ•¸"""
        base_score = result.score
        
        # æ ¹æ“šæœç´¢é¡å‹åŠ æ¬Š
        weight = {
            "vector": self.config.vector_weight,
            "keyword": self.config.keyword_weight,
            "semantic": self.config.semantic_weight,
            "structural": self.config.structural_weight
        }.get(result.search_type, 0.1)
        
        # é¡å¤–çš„ä¿¡è™Ÿ
        bonus = 0.0
        
        # å…§å®¹é•·åº¦çå‹µï¼ˆé©ä¸­é•·åº¦æ›´å¥½ï¼‰
        content_length = len(result.content)
        if 200 <= content_length <= 1500:
            bonus += 0.1
        
        # çµæ§‹åŒ–å…§å®¹çå‹µ
        if result.metadata.get('document_structure', {}).get('content_type') == 'title':
            bonus += 0.2
        
        # æŸ¥è©¢è©å®Œå…¨åŒ¹é…çå‹µ
        if query.lower() in result.content.lower():
            bonus += 0.15
        
        final_score = base_score * weight + bonus
        return final_score
    
    def _convert_to_nodes(self, results: List[SearchResult]) -> List[NodeWithScore]:
        """è½‰æ›ç‚ºNodeWithScoreæ ¼å¼"""
        from llama_index.core.schema import TextNode
        
        nodes_with_scores = []
        for result in results:
            node = TextNode(
                text=result.content,
                metadata={
                    **result.metadata,
                    "search_type": result.search_type,
                    "fusion_score": result.score
                }
            )
            
            node_with_score = NodeWithScore(
                node=node,
                score=result.score
            )
            nodes_with_scores.append(node_with_score)
        
        return nodes_with_scores