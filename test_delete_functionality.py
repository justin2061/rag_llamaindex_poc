#!/usr/bin/env python3
"""
æ¸¬è©¦æ–‡ä»¶åˆªé™¤åŠŸèƒ½
"""

import sys
import os
from pathlib import Path
import requests

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ° Python è·¯å¾‘
project_root = Path(__file__).parent
sys.path.append(str(project_root))

def check_es_documents():
    """æª¢æŸ¥ESä¸­çš„æ–‡æª”æ•¸é‡"""
    try:
        response = requests.get("http://elasticsearch:9200/rag_intelligent_assistant/_count", timeout=5)
        if response.status_code == 200:
            count = response.json().get('count', 0)
            print(f"ğŸ“Š ESä¸­ç•¶å‰æ–‡æª”æ•¸é‡: {count}")
            return count
        else:
            print(f"âŒ ç„¡æ³•ç²å–ESæ–‡æª”æ•¸é‡ï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return -1
    except Exception as e:
        print(f"âŒ æª¢æŸ¥ESæ–‡æª”æ•¸é‡å¤±æ•—: {e}")
        return -1

def get_document_sources():
    """ç²å–ESä¸­çš„æ–‡æª”ä¾†æº"""
    try:
        query = {
            "size": 0,
            "aggs": {
                "sources": {
                    "terms": {
                        "field": "metadata.source.keyword",
                        "size": 100
                    }
                }
            }
        }
        
        response = requests.post(
            "http://elasticsearch:9200/rag_intelligent_assistant/_search",
            json=query,
            headers={"Content-Type": "application/json"},
            timeout=5
        )
        
        if response.status_code == 200:
            buckets = response.json().get('aggregations', {}).get('sources', {}).get('buckets', [])
            sources = [(bucket['key'], bucket['doc_count']) for bucket in buckets]
            print(f"ğŸ“‹ æ–‡æª”ä¾†æº:")
            for source, count in sources:
                print(f"   - {source}: {count} å€‹æ–‡æª”")
            return sources
        else:
            print(f"âŒ ç„¡æ³•ç²å–æ–‡æª”ä¾†æºï¼Œç‹€æ…‹ç¢¼: {response.status_code}")
            return []
    except Exception as e:
        print(f"âŒ ç²å–æ–‡æª”ä¾†æºå¤±æ•—: {e}")
        return []

def test_delete_single_file():
    """æ¸¬è©¦åˆªé™¤å–®å€‹æ–‡ä»¶"""
    print("\nğŸ”„ æ¸¬è©¦åˆªé™¤å–®å€‹æ–‡ä»¶åŠŸèƒ½")
    print("=" * 50)
    
    try:
        from src.rag_system.elasticsearch_rag_system import ElasticsearchRAGSystem
        
        # åˆå§‹åŒ–RAGç³»çµ±
        rag_system = ElasticsearchRAGSystem()
        
        # æª¢æŸ¥åˆå§‹ç‹€æ…‹
        print("ğŸ“Š åˆªé™¤å‰ç‹€æ…‹:")
        initial_count = check_es_documents()
        sources = get_document_sources()
        
        if not sources:
            print("âš ï¸ æ²’æœ‰æ–‡æª”å¯ä»¥åˆªé™¤")
            return False
        
        # é¸æ“‡ç¬¬ä¸€å€‹ä¾†æºé€²è¡Œåˆªé™¤
        target_source = sources[0][0]
        print(f"\nğŸ¯ å˜—è©¦åˆªé™¤æ–‡ä»¶: {target_source}")
        
        # åŸ·è¡Œåˆªé™¤
        success = rag_system.delete_file_from_knowledge_base(target_source)
        
        if success:
            print(f"âœ… åˆªé™¤æ–‡ä»¶ {target_source} æˆåŠŸ")
        else:
            print(f"âŒ åˆªé™¤æ–‡ä»¶ {target_source} å¤±æ•—")
            return False
        
        # æª¢æŸ¥åˆªé™¤å¾Œç‹€æ…‹
        print("\nğŸ“Š åˆªé™¤å¾Œç‹€æ…‹:")
        final_count = check_es_documents()
        get_document_sources()
        
        deleted_count = initial_count - final_count
        print(f"\nğŸ“ˆ åˆªé™¤çµæœ: {deleted_count} å€‹æ–‡æª”è¢«åˆªé™¤")
        
        return deleted_count > 0
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦åˆªé™¤å–®å€‹æ–‡ä»¶å¤±æ•—: {e}")
        import traceback
        print(f"   è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return False

def test_clear_knowledge_base():
    """æ¸¬è©¦æ¸…ç©ºçŸ¥è­˜åº«åŠŸèƒ½"""
    print("\nğŸ”„ æ¸¬è©¦æ¸…ç©ºçŸ¥è­˜åº«åŠŸèƒ½")
    print("=" * 50)
    
    try:
        from src.rag_system.elasticsearch_rag_system import ElasticsearchRAGSystem
        
        # åˆå§‹åŒ–RAGç³»çµ±
        rag_system = ElasticsearchRAGSystem()
        
        # æª¢æŸ¥åˆå§‹ç‹€æ…‹
        print("ğŸ“Š æ¸…ç©ºå‰ç‹€æ…‹:")
        initial_count = check_es_documents()
        get_document_sources()
        
        if initial_count == 0:
            print("âš ï¸ çŸ¥è­˜åº«å·²ç¶“ç‚ºç©º")
            return True
        
        print(f"\nğŸ¯ å˜—è©¦æ¸…ç©ºçŸ¥è­˜åº«")
        
        # åŸ·è¡Œæ¸…ç©º
        success = rag_system.clear_knowledge_base()
        
        if success:
            print(f"âœ… æ¸…ç©ºçŸ¥è­˜åº«æˆåŠŸ")
        else:
            print(f"âŒ æ¸…ç©ºçŸ¥è­˜åº«å¤±æ•—")
            return False
        
        # æª¢æŸ¥æ¸…ç©ºå¾Œç‹€æ…‹
        print("\nğŸ“Š æ¸…ç©ºå¾Œç‹€æ…‹:")
        final_count = check_es_documents()
        get_document_sources()
        
        print(f"\nğŸ“ˆ æ¸…ç©ºçµæœ: å¾ {initial_count} å€‹æ–‡æª”æ¸…ç©ºåˆ° {final_count} å€‹æ–‡æª”")
        
        return final_count == 0
        
    except Exception as e:
        print(f"âŒ æ¸¬è©¦æ¸…ç©ºçŸ¥è­˜åº«å¤±æ•—: {e}")
        import traceback
        print(f"   è©³ç´°éŒ¯èª¤: {traceback.format_exc()}")
        return False

def main():
    """ä¸»å‡½æ•¸"""
    print("ğŸ§ª æ–‡ä»¶åˆªé™¤åŠŸèƒ½æ¸¬è©¦")
    print("=" * 60)
    
    # æª¢æŸ¥åˆå§‹ç‹€æ…‹
    print("ğŸ“Š æ¸¬è©¦é–‹å§‹å‰çš„ESç‹€æ…‹:")
    check_es_documents()
    get_document_sources()
    
    # æ¸¬è©¦å–®å€‹æ–‡ä»¶åˆªé™¤
    single_delete_success = test_delete_single_file()
    
    # å¦‚æœé‚„æœ‰å‰©é¤˜æ–‡æª”ï¼Œæ¸¬è©¦æ¸…ç©ºåŠŸèƒ½
    remaining_count = check_es_documents()
    if remaining_count > 0:
        clear_success = test_clear_knowledge_base()
    else:
        print("\nâš ï¸ æ²’æœ‰å‰©é¤˜æ–‡æª”ï¼Œè·³éæ¸…ç©ºæ¸¬è©¦")
        clear_success = True
    
    # æœ€çµ‚ç¸½çµ
    print("\n" + "=" * 60)
    print("ğŸ¯ æ¸¬è©¦çµæœç¸½çµ:")
    print(f"   å–®å€‹æ–‡ä»¶åˆªé™¤: {'âœ… æˆåŠŸ' if single_delete_success else 'âŒ å¤±æ•—'}")
    print(f"   æ¸…ç©ºçŸ¥è­˜åº«: {'âœ… æˆåŠŸ' if clear_success else 'âŒ å¤±æ•—'}")
    
    if single_delete_success and clear_success:
        print("\nğŸ‰ æ‰€æœ‰åˆªé™¤åŠŸèƒ½æ¸¬è©¦é€šéï¼")
        return 0
    else:
        print("\nğŸ’¥ éƒ¨åˆ†åˆªé™¤åŠŸèƒ½æ¸¬è©¦å¤±æ•—ï¼")
        return 1

if __name__ == "__main__":
    sys.exit(main())