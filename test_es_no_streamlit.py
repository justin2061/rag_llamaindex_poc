#!/usr/bin/env python3
"""
æ¸¬è©¦ Elasticsearch RAG ç³»çµ± - ä¸ä½¿ç”¨ Streamlit
"""

import sys
import os
sys.path.append('/app')

from custom_elasticsearch_store import CustomElasticsearchStore
from elasticsearch import Elasticsearch
from llama_index.core import Document, VectorStoreIndex, StorageContext, Settings
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.core.retrievers import VectorIndexRetriever  
from llama_index.core.query_engine import RetrieverQueryEngine
from llama_index.core.postprocessor import SimilarityPostprocessor
from datetime import datetime

def test_full_system():
    """æ¸¬è©¦å®Œæ•´çš„ ElasticsearchRAG ç³»çµ±åŠŸèƒ½"""
    print("ğŸ”§ åˆå§‹åŒ– Elasticsearch å®¢æˆ¶ç«¯...")
    
    # 1. è¨­ç½® ES å®¢æˆ¶ç«¯
    es = Elasticsearch(['http://elasticsearch:9200'], request_timeout=30)
    if not es.ping():
        print("âŒ Elasticsearch é€£æ¥å¤±æ•—")
        return False
    print("âœ… Elasticsearch é€£æ¥æˆåŠŸ")
    
    # 2. è¨­ç½®åµŒå…¥æ¨¡å‹
    print("ğŸ”§ è¼‰å…¥åµŒå…¥æ¨¡å‹...")
    embed_model = HuggingFaceEmbedding(model_name='sentence-transformers/all-MiniLM-L6-v2')
    Settings.embed_model = embed_model
    print("âœ… åµŒå…¥æ¨¡å‹è¼‰å…¥å®Œæˆ")
    
    # 3. å‰µå»ºç´¢å¼•æ˜ å°„
    print("ğŸ”§ å‰µå»º Elasticsearch ç´¢å¼•...")
    index_name = "full_test_es"
    
    # ç°¡å–®çš„ç´¢å¼•æ˜ å°„
    index_mapping = {
        "settings": {
            "number_of_shards": 1,
            "number_of_replicas": 0
        },
        "mappings": {
            "properties": {
                "content": {"type": "text"},
                "embedding": {
                    "type": "dense_vector",
                    "dims": 384,
                    "index": True,
                    "similarity": "cosine"
                },
                "metadata": {"type": "object"}
            }
        }
    }
    
    try:
        if es.indices.exists(index=index_name):
            es.indices.delete(index=index_name)
            
        response = es.indices.create(index=index_name, body=index_mapping)
        print("âœ… Elasticsearch ç´¢å¼•å‰µå»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç´¢å¼•å‰µå»ºå¤±æ•—: {e}")
        return False
    
    # 4. å‰µå»ºè‡ªå®šç¾©å‘é‡å­˜å„²
    print("ğŸ”§ å‰µå»ºè‡ªå®šç¾©å‘é‡å­˜å„²...")
    vector_store = CustomElasticsearchStore(
        es_client=es,
        index_name=index_name,
        text_field='content',
        vector_field='embedding'
    )
    print("âœ… è‡ªå®šç¾©å‘é‡å­˜å„²å‰µå»ºå®Œæˆ")
    
    # 5. å‰µå»ºå­˜å„²ä¸Šä¸‹æ–‡
    storage_context = StorageContext.from_defaults(vector_store=vector_store)
    
    # 6. æº–å‚™æ¸¬è©¦æ–‡æª”
    documents = [
        Document(
            text="Machine learning is a subset of artificial intelligence that focuses on algorithms.",
            metadata={"source": "ml_doc", "category": "technology", "timestamp": datetime.now().isoformat()}
        ),
        Document(
            text="Natural language processing helps computers understand human language.",
            metadata={"source": "nlp_doc", "category": "ai", "timestamp": datetime.now().isoformat()}
        ),
        Document(
            text="Deep learning uses neural networks with multiple layers to process data.",
            metadata={"source": "dl_doc", "category": "deep_learning", "timestamp": datetime.now().isoformat()}
        )
    ]
    
    print(f"ğŸ”§ æº–å‚™ç´¢å¼• {len(documents)} å€‹æ–‡æª”...")
    
    # 7. å‰µå»ºç´¢å¼•
    try:
        index = VectorStoreIndex.from_documents(
            documents,
            storage_context=storage_context,
            embed_model=embed_model
        )
        print("âœ… VectorStoreIndex å‰µå»ºæˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç´¢å¼•å‰µå»ºå¤±æ•—: {e}")
        return False
    
    # 8. é©—è­‰æ–‡æª”æ˜¯å¦å·²ç´¢å¼•
    try:
        count_response = es.count(index=index_name)
        doc_count = count_response['count']
        print(f"âœ… å·²ç´¢å¼• {doc_count} å€‹æ–‡æª”")
        
        if doc_count == 0:
            print("âŒ æ²’æœ‰æ–‡æª”è¢«ç´¢å¼•")
            return False
            
    except Exception as e:
        print(f"âŒ æ–‡æª”è¨ˆæ•¸å¤±æ•—: {e}")
        return False
    
    # 9. å‰µå»ºæŸ¥è©¢å¼•æ“
    print("ğŸ”§ å‰µå»ºæŸ¥è©¢å¼•æ“...")
    try:
        retriever = VectorIndexRetriever(
            index=index,
            similarity_top_k=5
        )
        
        postprocessor = SimilarityPostprocessor(similarity_cutoff=0.7)
        
        query_engine = RetrieverQueryEngine(
            retriever=retriever,
            node_postprocessors=[postprocessor]
        )
        print("âœ… æŸ¥è©¢å¼•æ“å‰µå»ºå®Œæˆ")
    except Exception as e:
        print(f"âŒ æŸ¥è©¢å¼•æ“å‰µå»ºå¤±æ•—: {e}")
        return False
    
    # 10. æ¸¬è©¦æŸ¥è©¢
    print("ğŸ”§ æ¸¬è©¦æŸ¥è©¢...")
    test_queries = [
        "What is machine learning?",
        "Tell me about neural networks",
        "How does NLP work?"
    ]
    
    for i, query in enumerate(test_queries, 1):
        try:
            print(f"\næŸ¥è©¢ {i}: {query}")
            response = query_engine.query(query)
            print(f"å›ç­”: {str(response)[:200]}...")
            
        except Exception as e:
            print(f"âŒ æŸ¥è©¢å¤±æ•—: {e}")
            return False
    
    print("\nğŸ‰ æ‰€æœ‰æ¸¬è©¦é€šéï¼Elasticsearch RAG ç³»çµ±å·¥ä½œæ­£å¸¸ã€‚")
    return True

if __name__ == "__main__":
    print("ğŸ§ª é–‹å§‹å®Œæ•´ Elasticsearch RAG ç³»çµ±æ¸¬è©¦")
    print("=" * 70)
    
    success = test_full_system()
    
    print("=" * 70)
    if success:
        print("âœ… æ¸¬è©¦æˆåŠŸï¼ç³»çµ±å·²æº–å‚™å°±ç·’ã€‚")
    else:
        print("âŒ æ¸¬è©¦å¤±æ•—ï¼")
        
    sys.exit(0 if success else 1)